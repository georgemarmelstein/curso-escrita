0:00	Olá, aqui George Mestein e eu já adianto que esse vídeo vai ser bem longo, ele vai
0:05	ser um vídeo intimista, reflexivo. Eu vou fazer algumas reflexões em voz altas, apresentar aqui algumas
0:11	inquietações que estão remoendo aqui os meus pensamentos, mas eu garanto para você que vai ser um vídeo extremamente
0:18	importante. É um vídeo de conscientização, é um vídeo de tentativa
0:23	de mostrar um desenho que eu tenho visto se desenrolar e que eu vou pretender
0:30	aqui apresentar com algumas ideias que eu anotei para que a gente possa ter uma clareza maior do estado que a gente tá
0:36	hoje. Esse vídeo vai ajudar você a definir os seus próximos passos com o
0:41	uso da inteligência artificial generativa, seja em questões simples, como por exemplo, escolhas de
0:47	ferramentas, qual ferramenta usar, seja para estabelecer o seu nível de
0:54	comprometimento com o aprendizado de inteligência artificial generativa. Esse
0:59	vídeo ele nasce de uma inquietação ou de uma constatação de que a gente tá
1:05	passando por uma transformação, uma nova onda ou uma nova revolução da IA
1:10	Generativa, que é a passagem do mundo dos assistentes que a gente tinha antes
1:16	para o mundo dos agentes, né? O modo agêntico de usar os LLMs. No mundo dos
1:21	assistentes, as nossas interações eram comunicacionais com uma ferramenta única. De certo modo, era como se a
1:28	gente tivesse trabalhando com uma máquina de calcular. No mundo dos agentes, a gente trabalha
1:34	com a multiplicidade de eh ferramentas trabalhando em rede de modo orquestrado.
1:40	Isso muda completamente a nossa forma de se comunicar, de interagir e de
1:46	trabalhar com a inteligência artificial. Então é isso que a gente vai apresentar aqui. Eu trouxe o mapa mental para me
1:53	ajudar aqui a não perder as nossas ideias. Esse vídeo ele é destinado para
1:58	todos os públicos, né? Eu vou falar muitos conceitos avançados, mas eu quero dar alguns passos para trás até para
2:05	falar um pouquinho da minha eh da minha percepção sobre esse mundo, né? Eu eu
2:10	estou no mundo da EA Generativa de modo hiper focado, né? de modo imersivo desde
2:17	fevereiro de 2023, que praticamente eu uso todos os dias, eh, para entender,
2:23	para saber como usar no direito e e eu tenho acompanhado toda a evolução. E aí
2:28	eu vou tentar passar um pouquinho porque eu acho que que esse vídeo ele tem essa importância também de eh de fazer um
2:34	pouco de registo histórico, né, do que a gente tá vivendo. E por isso esse vídeo ele também tem uma pretensão de ser
2:41	datado. Nós estamos em outubro de 2025. Eh, eu acredito que daqui a um mês,
2:47	daqui a dois meses, eh, muitas ideias que eu vou falar aqui, elas já estarão de certo modo defasadas, como é no mundo
2:54	da IA. no mundo da Iá, né? algo que a gente fala hoje, amanhã já não vale mais ou já tem alguma novidade. Eh, mas a
3:01	minha ideia aqui, a minha esperança é que esse vídeo funcione como um registro histórico da minha percepção do estado
3:08	atual da da IA Generativa. Então, eu acredito que nós estamos hoje vivendo mais um ponto de inflexão. O primeiro
3:16	ponto de inflexão ocorreu em 2023, quando surgiram, né, os os LLMs, o
3:21	chatpt em particular como hype ali, como popular, né, como ferramenta popular. E nós estamos passando dessa era dos
3:28	assistentes simples, né, para a era dos agentes. A partir de 2025, a gente
3:34	começou a ter algumas sinalizações já com humanos, eh, já com o Deep Research,
3:41	mas agora já está praticamente consagrado em praticamente todos os modelos, estão atuando de algum modo,
3:48	com mais ou menos nível de sofisticação no modo agêntico. E o modo agênico, ele
3:54	é caracterizado justamente por ser uma situação em que a ao invés de haver uma
4:00	conversa entre usuário e um LLM, é uma conversa entre usuário e uma máquina que
4:06	tem um conjunto de habilidades, um conjunto de recursos, um conjunto de ferramentas que vão eh ajudar na na no
4:14	cumprimento daquela tarefa, né? Isso muda bastante a nossa a nossa percepção.
4:20	Isso que eu vou falar aqui das das inquietações que você vai ouvir e das
4:27	minhas visões sobre essa revolução, ela vai ajudar muito você a escolher
4:34	ferramentas, né, a estabelecer eh qual ferramenta usar para qual atividade,
4:39	porque eh cada vez eh eu percebo que as empresas estão caminhando, trilhando por
4:46	eh por cbusiness, por por núcleo de negócio eh diferentes. Eh, e aí,
4:52	portanto, e é necessário que a gente compreenda qual é o propósito de cada empresa, porque elas estão investindo
4:59	dinheiro, recursos para desenvolver produtos para esse propósito. E a gente vai ver que há dois, há uma bifurcação,
5:06	né, nesse ramo, em que algumas ferramentas estão sendo destinadas para um uso mais casual, no sentido de uso
5:14	ordinário cotidiano, como se fosse uma plataforma eh universal para que toda
5:19	pessoa possa ter acesso ao mundo da IA e se comunicar com o mundo externo através dessa interface, né, como é o chatpt,
5:27	como é o Perplex, como é o Gemini. E temos algumas ferramentas como cloud que
5:33	estão caminhando para uma especialização em tarefas mais complexas, não
5:39	necessariamente corporativas, não necessariamente de trabalho, mas tarefas que exigem cognição mais profunda.
5:45	Então, a gente tá, a gente vai ver, né, que há uma há uma uma linha, né, de
5:52	estratégia dessas empresas entre amplitude, ou seja, alcançar o maior público para realização do maior da
5:59	maior quantidade de tarefas possível para uma uma profundidade, amplitude
6:06	versus profundidade para eh você eh coloca uma ferramenta menos acessível
6:12	para o grande público, mas com eh habilidade es de fazer tarefas mais específico. Eh, e portanto, né, a a
6:20	escolha da ferramenta vai depender da tarefa que você faz. Muitas vezes nós nós não temos tarefas únicas, né? Eh,
6:27	nós usamos eh hoje em dia inteligência artificial para tarefas simples, como
6:32	fazer uma imagem, fazer um um e-mail, alguma coisa bem bem básica, até tarefas
6:38	mais complexas, como fazer uma análise probatória, como fazer uma análise FIRAC de um processo, né, um um um uma análise
6:46	de dados mais eh mais robusta. Então, nós temos tarefas diferentes e essa e e
6:53	a gente vai caminhar para um momento em que a gente vai ter que saber qual é o modelo que a gente vai utilizar para cada tarefa, porque para as tarefas mais
7:00	complexas eh tá havendo um aumento de complexidade, um aumento de custo, né, e
7:06	também de curva de aprendizagem, né, para para desenvolver essas ferramentas. Então, a gente precisa ter essa
7:11	conscientização. Eh, em relação a ao à curva de aprendizagem, a gente vai ver que as habilidades mudam, né? Uma coisa é você
7:19	usar uma ferramenta para fazer uma imagem, um meme, né, para brincar ali no grupo da família. Outra coisa é você
7:25	fazer um workflow complexo com multietapas, em que existem eh
7:31	perspectivas estratégicas, eh, compreensões mais profundas para que você direcione a máquina. Então, a gente
7:39	vai ter que ter a consciência de que, né, você pode trabalhar de modo simples com paint, né, com paint brush, né, uma
7:46	ferramenta de desenho bem básica, mas se você quiser trabalhar de nível profissional, você vai precisar de
7:52	ferramentas mais caras, como Photoshop, por exemplo. Claro que aqui é uma metáfora, uma analogia. Eh, o próprio
7:58	Photoshop hoje em dia tá já está perdendo o espaço. Eh, e você vai ter que ter também um um dispêndio de
8:05	investimento de tempo para aprender a dominar essa ferramenta, né? E aí e cada vez tá mais claro isso. A gente tem
8:12	ferramentas básicas simples de usar para tarefas mais ordinárias, mais eh
8:17	ocasionais. Porém, quando a gente começa a aumentar o nível de exigência profissional, o nível de exigência
8:24	estratégica, a gente vai caminhando para ferramentas mais caras, mais robustas e
8:30	mais complexas, que exigem mais domínio de mais habilidades para além da da
8:36	engenharia de prompt, por exemplo. Então, eh na era dos assistentes era como eh nós éramos como se fossem
8:43	maestro regendo um músico único, né? nós conversávamos com a máquina como se a gente tivesse tocando o violão, né? Eh,
8:50	e aí, portanto, era mais simples dominar a ferramenta, porque basicamente era o dominar aquela ferramenta para conseguir
8:57	tocar o violão bem feito. Na era dos agentes, nós vamos trabalhar com uma orquestra em que a gente tá regendo
9:03	vários músicos ao mesmo tempo. Então, eh, a gente tem que entender essa visão
9:09	multistep consiga dominar essas ferramentas. Ponto importante é que o modo agêntico, por
9:15	definição, ele dá autonomia à máquina, né? Essa autonomia pode ser maior ou
9:21	menor, dependendo do seu domínio sobre a máquina. Se você não domina a máquina, você dá um comando e a máquina vai fazer
9:28	tudo sozinho. Muitas vezes vai funcionar, vai funcionar bem porque a máquina tá treinada para fazer essa
9:33	tarefa, mas você vai perder o controle, vai ser, você vai ser um botão da máquina, né? Quando você domina eh
9:41	workflow, né? a a o fluxo de trabalho, as ferramentas que funcionam dentro dessa orquestra e consegue criar prompts
9:49	e comandos para que a máquina cumpra exatamente o passo a passo que você está estabelecendo. Você se mantém no
9:55	controle, inclusive estabelecendo checkpints desses ódios que você que vai ter que eh tomar para se manter no
10:02	controle e não ser não se transformar no mero botão da máquina. Então esse é o ponto que a gente vai defender, o ponto
10:08	de consciência que eu quero trazer é para que a gente pense nos LLMs como
10:13	agora, né, o modo agêntico como orquestra e no nosso papel como um maestro, nós vamos dirigir essa
10:20	orquestra, nós vamos dar os comandos, vamos criar promptes mais complexos, vamos ter mais elementos de domínio do
10:27	contexto, engenharia de contexto, né, de pensamento estratégico, de metacognição para conseguir trabalhar melhor para que
10:35	a gente entenda entenda tudo isso, eu vou voltar atrás, né? E aí, portanto, eh, como eu falei, meu objetivo é que
10:41	esse vídeo alcance tanto os iniciados, né, no mundo da IA, aqueles que já estão
10:49	surfando a primeira onda da IA, eh, e a segunda também, né, a segunda onda da
10:55	IA, que é justamente a onda, eh, mais recente, né, eh, dos GPTs e algo assim.
11:00	Eh, mas eu quero também colocar aqueles que sequer entraram no mundo da IA. E aí, por isso eu vou fazer esse
11:07	retrospecto aqui, começando de fevereiro de 2023, que foi a minha primeira
11:13	interação com a máquina. Eu comecei a usar o chat EPT ali, vi, vi o potencial naquele mês,
11:20	por coincidência, tinha acabado de ser lançado o plano pago e eu resolvi assinar. Eh, eu já comecei usando ali,
11:27	eu tava usando a a versão gratuita, né? surgiu a possibilidade de assinar e aí
11:32	no momento que eu tava usando deu deu, né, o limite de uso. Eu falei: "E vou pagar aqui para usar". Desde então não
11:37	parei mais de usar, né? Ou seja, eu sou assinante do Chat PT desde o primeiro momento em que a plataforma se tornou,
11:44	teve a opção paga, né? E naquele momento, né, quando eu comecei a usar as ferramentas, né? Ah, o meu objetivo era
11:51	entender o fundamento, né, que continua sendo uma das habilidades mais básicas, né, para você conversar com as máquinas.
11:57	E eu percebi que a qualidade da resposta dependia da forma como a gente se
12:03	comunicava. A máquina se regula pelo nível de linguagem usada pelo usuário, né? E, portanto, se o usuário conseguir
12:10	elevar o nível da comunicação através de técnicas de ingé de prompt mais sofisticadas, ele consegue respostas
12:16	melhores. Inputs nobres geram outputs nobres. Então, naquele momento, eu já tinha percebido, né, que eh para essa
12:24	ferramenta conseguir entrar no uso comum, pelo menos no uso profissional do direito, que era o meu foco, eu tinha
12:30	que entender os fundamentos do LLM, saber como ela produz o texto, de onde é que ela tira conhecimento, quais são os
12:37	limites, por que ela alucina, o que que ela pode fazer, o que que ela não pode, quando a gente pode confiar e quando não
12:42	pode, né? e como controlar a máquina, como conseguir fazer com que ela cumpra nosso estilo, o que dependeria, nesse
12:48	caso de engenharia de prompt. E aí eu comecei a desenvolver isso, foi quando eu comecei também a lançar os primeiros
12:54	cursos de escrita jurídica com o chatpt, né, porque tinha como foco esse domínio
12:59	de usar a ferramenta para escrita jurídica, né, com esses dois focos principais, fundamentos dos LLMs e
13:06	engenharia de prompt. Eh, em novembro de 2023, nós tivemos o primeiro grande salto aqui de evolução
13:14	dessas ferramentas e a primeira percepção que eu tive do propósito de
13:20	negócio de cada empresa. Eh, a Openei, que é a empresa que criou o chatpt,
13:25	lançou os chamados GPTs customizados naquele momento, eh, em novembro de 2023. E já naquela ocasião, eu dizia que
13:33	ali era uma mudança clara de de orientação do negócio, porque até então
13:38	o chatpt era uma plataforma bem bem simples, bem tossica, com poucos elementos e poucos recursos e que a
13:46	partir dali, né, a gente viu que a pretensão da Opena era se tornar uma espécie de hub universal de acesso a
13:53	serviços, né, como hoje eh foi reforçado, né, na no último lançamento da da OpenI, em que ela quer, por
14:00	exemplo, que você tenha uma plataforma em que se o usuário quiser fazer uma reserva de um hotel no booking, ao invés
14:07	de ela ir no site do booking, ela faz a pesquisa dentro do chat EPT, vai ter as opções, né, de acordo com os critérios
14:14	que o usuário vai sugerir e ele pode fazer a reserva a partir dali dentro do site. Eh, lá no GPTs customizados, eh, a
14:21	ideia era essa. Vamos criar uma loja, um GPT Store, que as pessoas vão poder criar seus GPTs customizados e a partir
14:28	daí todo mundo vai entrar dentro da plataforma para usar, para usar os GPTs, para fazer aquelas tarefas específicas.
14:35	Isso, né? Um aspecto interessante do ponto de vista de você permitir a o compartilhamento de GPTS, mas isso é
14:43	inviável do ponto de vista de um negócio se você quiser criar GPTs de alta complexidade, de alta capacidade. Tanto
14:49	que até hoje, passados muito mais de um ano e de lançamento dos GPTs, quase 2
14:54	anos, né, do lançamento do GPTs, nós ainda temos a mesma limitação de prompt de sistema. Dentro dele a gente só tem
15:01	um limite de 8.000 1000 caracteres, que é mínimo. Hoje em dia os nossos prompts têm 10 vezes mais do que isso de
15:08	tamanho, né? Então, a gente não vai conseguir usar a GPT customizado para as tarefas complexas, porque não funciona
15:14	com promp complexo, só funciona com promp muito simples, portanto para tarefas mais simples. É por isso, né,
15:20	que a gente percebeu que o core business da Openial
15:30	seja voltada para tarefas robustas. Até que temos como fazer isso, mas nós não conseguimos fazer isso nesse modo
15:36	acessível, nesse modo gratuito, nesse modo GPT customizado, né? Tem que ir para as ferramentas mais eh caras, né?
15:45	Que a o próprio GPT prova, né? Que é que que é um custo bem elevado, 200 para
15:50	você ter acesso ao a um poder maior de interação com a máquina. Eh, mas o que ela queria era justamente
15:56	isso, era que você quando fosse entrar na internet, ao invés de ir pro Google, você fosse pro chat EPT e as suas
16:03	perguntas e e comunicação se tornassem ali naquele momento. O Cloud, ele usou
16:09	uma aposta diferente, né, já desde o início. Eu também sou assinante do do Clud desde julho de 2020
16:19	3, né, julho, primeiro de julho de 2023. Eu sei disso porque eu fiz uma pergunta
16:24	pro Clud sobre qual foi a primeira conversa que eu tive com ele. Deixa eu mostrar aqui que is até um recurso novo
16:30	do Clud, é bem legal. Eh, qual foi a primeira conversa que nós tivemos
16:38	e quando foi? Eu vou fazer essa pergunta porque ele tem agora essa possibilidade
16:44	de fazer uma consulta nas bases de conversas antigas que é muito poderosa, é muito boa. Eh, e aí, portanto, ele
16:51	traz aqui a primeira conversa que eu tive com ele foi 1eo de julho, data do meu aniversário. E, eh, nós estávamos
16:59	discutindo uma frase da Maricurri, que é uma frase que me impacta, me impactava
17:04	já desde aquela época, mas que eu acho muito relevante. Nada na vida deve ser temido, somente compreendido. Agora é
17:12	hora de compreender para temer menos, né? Compreender mais para terer menos. Então essa foi a minha primeira conversa
17:18	que eu tive para que eh o Cláudio desenvolvesse essa essa frase. E desde
17:25	então tivemos várias conversas sobre temas jurídicos, direitos humanos, análise de casos e outras questões
17:31	relacionadas ao direito e outros tópicos também. Mas eh
17:36	eu quero dizer, né, que eu comecei a usar o Cloud eh desde então, desde primeiro de julho, né, de 2023 e me
17:43	tornei um fã da Antropic, né? Eu passei a ser e eh o o Cláudio, ele se tornou a
17:51	minha ferramenta de trabalho favorita desde outubro, mais ou menos de 2023, substituindo o chatpt, né? Mas eu
17:58	mantive o curso de escrita jurídica com o chatpt, porque o Cláudio ele só se tornou disponível no Brasil em agosto de
18:05	2024, tá? Então, portanto, anos depois que eu comecei a usar, é que ele e entrou no Brasil, mostrando mais uma vez
18:11	que o objetivo do cloud não é criar uma ferramenta universal, né? É criar uma
18:16	ferramenta mais voltada para tarefas mais inteligentes, mais sofisticadas,
18:22	né? E aí, portanto, ele apostou mais, né, em trabalhos que implica contextos
18:27	longos, janela de contextos maiores e mais e mais profundas, com análises mais
18:33	profundas, porque muit eh a gente vai ver que posteriormente o Geminai ele
18:38	apostou também em janela de contexto longa, mas é uma janela de contexto longo sem profundidade. Ele usa uma
18:44	técnica de atenção espaçada que faz com que ele consiga olhar mais textos, só
18:51	que com menos detalhes, perdendo nuances importantes dentro dessa janela de contexto longa, né? Ou seja, eh, apesar
18:59	do Gemini, né, hoje ter uma janela de contexto superior à do Cloud, a análise do Cloud é superior porque ela é mais
19:06	profunda, ela focou em conseguir ter mais poder computacional dentro daquela
19:12	janela de contexto que ela consegue trabalhar com eficiência, né? Poderia ampliar isso, né? Eh, criando técnicas
19:18	para que eh a máquina conseguisse prestar atenção em em partes eh do texto
19:24	e aí, portanto, perdendo o nuance. Isso é uma questão técnica, né? Eh, tô falando aqui, mas basta dizer o
19:29	seguinte, né? Você tem no cloud uma ferramenta que hoje consegue trabalhar
19:34	com qualidade com 100, 200 páginas de uma só vez, né? ele consegue enxergar
19:40	100, 200 páginas, 200 páginas, né, com extrema qualidade. Ele olha e consegue extrair dali informações de qualidade,
19:47	enquanto o o Jemini consegue olhar, né, uma janela, talvez 1000 páginas, né, só
19:53	que eh com menos qualidade, né, ele vai perder ele. É o que a gente chama de degradação do contexto. Quanto maior o
20:00	contexto, mais vai havendo degradação. Claude, ele consegue manter qualidade
20:06	naquilo que ele promete em termos de de contexto. E, enfim, isso é um um paralelo, mas só para dizer que a essa
20:13	aposta do cloud em janelas de contexto longos, em análise de documentos, em trabalhar com textos, né, sem
20:20	multimodalidade, que é um ponto que a gente vai destacar também, faz com que ele se torne uma ferramenta para um uso
20:26	mais profissional, não para um uso casual, não para fazer memes, não para
20:32	diversão, entretenimento. ela é uma ferramenta mais voltada para trabalho, né, e e pensamento e e pensamento
20:38	complexo. Eh, e também isso é bem demonstrado quando a gente interage com Cloud,
20:45	percebe que ele é mais acadêmico. Ele, a, a base dele de treinamento, ela é
20:51	muito sofisticada. São livros de altíssima qualidade que foram usadas no treinamento, extraídas da Libidentes.
20:57	Tem um processo judicial que mostra todos os livros, né, que é a base de livros que ela comprou pirateado, né? E,
21:05	e aí, portanto, ela tem esses livros de qualidade que funcionaram, né, como principal, eh, conhecimento da máquina,
21:12	diferente dos outros modelos que usaram eh por exemplo, o Google, né, usa bases do do eh do YouTube, né, usa
21:21	eh fórums, Wikipedia, e aí, portanto, é um conhecimento menos sofisticado. Eh, nesse mesmo momento, novembro de 2023, a
21:29	gente via o o Google para trás. Ele ele tava com medo de perder a sua hegemonia
21:35	no sistema de busca. Ele via o Perplexity eh surgindo como ferramenta
21:41	excepcional para busca, melhor do que as outras até hoje, né? E eh tentou criar o
21:47	Bard, que seria ali uma forma de ter um concorrente para de inteligência
21:54	artificial para esses modelos. E o Bard foi um fracasso total porque era muito ruim, né? O Google não conseguiu captar
22:01	a naquele momento qual era a importância da dos do que tava surgindo ali daquele
22:07	daquela ferramenta. Tava perdido, o Google estava perdido. Esse é o fato. Aí nós chegamos no ano de 2024.
22:15	2024 é que a gente vê que eh o mundo da IA não tem mais volta. As empresas
22:20	passaram a investir muito dinheiro nessa área, né? Recursos quase ilimitados, mas
22:26	ainda assim escassos, né? Limitados. E nesse momento a gente começa a
22:31	perceber o eh o surgimento de novas empresas com qualidade, né, com
22:36	capacidade de concorrer com a Openi, concorrer com a Antropic, que eram duas únicas que tinham ali na até 2023, eh,
22:45	algum tipo de qualidade, né, e de produto que pudesse ser admirado, né?
22:50	Mas em 2024 a gente vê surgir também o Gemini, né, o o Grock, né, da da Shik,
22:58	né, que foi desenvolvido logo logo em seguida. E essas empresas elas
23:03	mantiveram aquela ideia de negócio de ser a empresa de acesso popular, de
23:09	acesso universal, uma empresa eh uma ferramenta que a pessoa vai entrar e
23:15	vai, né, conseguir fazer uma imagem, conseguir fazer um vídeo e vai conseguir conversar, vai conseguir ouvir. É o que
23:21	a gente chama de eh multimodalidade tudo em um, né, all. Então você tem o mesmo
23:28	modelo que faz tudo. E, portanto, veja do ponto de vista de negócio, se você
23:33	tem recursos limitados, pessoal limitado, GPUs limitadas para treinar
23:39	modelos, você tem que ser muito seletivo naquilo que você aposta, porque se você
23:44	colocar as melhores mentes para fazer vídeos, a parte de texto vai ficar em prejuízo. Se você coloca as melhores
23:51	mentes para fazer imagens, né, a parte de análise de dados, de codificação, vai
23:58	ficar prejudicada. Então você precisa ter uma estratégia de de priorização. E
24:03	a priorização da OpenI Grock e Google, na minha ótica, foi criar uma espécie de
24:10	apostar em todo toda a linha de frente. Eles querem criar a AGI, a inteligência artificial geral, que é uma plataforma
24:16	que faz tudo, né? E um canivete suíço que faz tudo, né? com alguma qualidade,
24:21	mas não tão eh bom quanto um uma precisão de um cirurgia de um de um
24:28	bistui cirúrgico, né? Eh, teve um um fato, né, que para mim é é marcante
24:35	porque muda também a lógica da própria Google, que foi o lançamento em 2024 do
24:40	Notebook LM, né? Eu também comecei a usar desde o comecinho, assim que lançou, tava disponível só nos Estados
24:45	Unidos. Eu também testei e já percebi que eles tinham captado a partir dali a mudança, né, que é o fato, né, de que eh
24:54	até então eh esses modelos eh o Google, o a o próprio chatpt, eles não estavam
25:00	investindo tanto em em usuário, né, em domínio do usuário, usuário no controle.
25:06	Eles estava eles estavam querendo espécie de oráculo que o usuário fazia uma pergunta e a máquina respondia, né?
25:11	eles queriam essa essa interação de um oráculo com todas as respostas
25:18	e eh através do notebook LM, algo que o Clud já fazia antes, apostou muito na
25:25	curadoria do conhecimento, que é a ideia de que o usuário vai ter o poder de inserir as bases de conhecimento que
25:31	serão usadas para dar resposta. Então, o notebook LM é essa ferramenta que
25:37	permite que a gente eh selecione o documento, o conhecimento, o livro, né,
25:42	o vídeo, a aula que a gente quer que eh aprender, né, e vai eh usar ali como o a
25:50	fonte da resposta da máquina, né? Então, essa é a lógica. E aí vem talvez a
25:55	primeira também sacada dos modos multiagentes, bem antes do manos, bem
26:01	antes do deep research, o Gemini, né, o Google, na verdade, né, criou o notebook LM, que já tinha um modelo de certo modo
26:08	multiagente, porque você poderia colocar lá, né, 50 livros ou na versão paga 300
26:15	documentos e rapidamente vários modelos conseguiriam extrair informações desses
26:22	desses esses documentos todos desses eh eh anexos que o usuário colocou lá e dar
26:29	resposta com base nisso. Então, já eram modelos aqui, né, uma primeira ideia de um modelo multiagente, trabalhando em
26:35	paralelo para conseguir cumprir uma tarefa com extrema qualidade e extrema velocidade. Quando você tem vários
26:42	modelos, analisando vários documentos, ao mesmo tempo, você reduz aquela aquele problema da limitação da janela de
26:48	contexto, porque você consegue fazer com que cada modelo preste atenção em partes específicas do documento. E aí,
26:54	portanto, você consegue ter uma resposta com muito mais eh precisão e qualidade, juntando tudo isso em uma resposta
27:01	única. Paralelamente a tudo isso, a Antropic, a Antropic, que é a empresa
27:07	que criou o Cloud, ela estabeleceu que não iria apostar em multimodalidade, ela
27:13	iria apostar em tarefas eh mais sofisticadas, em tarefas mais
27:18	profissionais, envolvendo essencialmente textos, não só textos de linguagem natural, mas também códigos, né, e eh eh
27:28	e eh e e enfim, a a trabalhar com textos trabalhar com análise de dados, né, trabalhar com números, né, com com
27:35	ferramentas de de análise de dados, de criação de códigos, né? Então essa é uma
27:41	uma característica que a gente vai notando já, a diferença de ferramentas que enquanto as outras vão pra
27:47	multimodalidade, para um acesso mais universal, a antrópica ela começa a trabalhar numa visão mais para quem
27:54	trabalha com textos, para quem quer respostas profundas, para quem faz análise de dados, para quem precisa pensamento eh estratégico, nós temos
28:01	aqui um lugar para você que eh que é o clot e e ao mesmo tempo começa a criar
28:07	criar dentro dele alguma complexa alguma uma algum nível de complexidade para
28:12	otimizar o fluxo de trabalho, né, com os projects, né, que tem lá toda uma lógica e os estilos personalizados. Hoje muito
28:20	mais recursos, mas naquele momento, basicamente só isso. Eh, os projects eh
28:26	são são semelhantes aos GPTs customizados, mas com uma diferença importante. Eles não são feitos para uso
28:33	público, né? Você não cria um project para outras pessoas, você cria para você, no máximo pra sua equipe, se você
28:38	tiver um plano team, né, um plano de equipe. É. E aí, por que que isso é é
28:44	diferente? Porque se eu crio um GPT customizado gratuito para todo mundo, a
28:49	Open vai ter que pagar dinheiro, né, para as pessoas usarem, né, gratuitamente o que eu fiz, né? Então,
28:55	as pessoas vão usar a Open sem que sem assinar. E aí, portanto, ela estabelece
29:01	aquela limitação de de profundidade e de poder dos GPTs customizados, porque
29:06	pretende ser um acesso universal, enquanto que o o Cloud disse: "Não, o meu prod é individual, você cria o seu e
29:14	você usa". E, portanto, eu vou lhe dar o poder de você criar projects muito mais poderosos, né? Você pode criar aqui um
29:21	prompt de 20 páginas e dentro do seu projectear a tarefa complexa com extrema qualidade.
29:29	Então já vai notando aí a diferença de propostas. Na terceira onda, é a que a
29:35	gente está agora, é a revolução dos agentes, que o grande impacto surge com
29:40	humanos, né? Antes disso tinha um modo agente do chattem eh nem tô lembrando o nome, mas que não pegou, era ruim, eh
29:48	operator, né? tinha um operator do chatt que foi o primeiro agente assim mais popular, mas era péssimo, mas vê humanos
29:54	e conseguiu eh popularizar a ideia de um modelo multiagente, que é basicamente
30:00	uma ferramenta que trabalha de modo encadeado em sequência automatizado, né?
30:06	O usuário dá uma solicitação, a ferramenta, né, o modelo, por exemplo, eh crie um site sobre eh engenharia de
30:15	prompt. Então a ferramenta ela vai primeiro fazer uma curadoria de conhecimento para colher o maior
30:21	material possível sobre engenharia de prompt. Depois ela vai criar um plano de execução do site, vai criar o código do
30:29	site e vai fazer o deploy, né, o lançamento desse site. E ela faz isso
30:34	tudo automaticamente em cadeia. você vai faz, você vai vendo ela trabalhar o que que ela tá fazendo. E aí o usuário tem
30:40	um controle apenas de dar o primeiro comando. E a partir daí ela trabalha sozinha, ela escolhe as ferramentas, ela escolhe o o eh o tamanho, ela escolhe
30:49	tudo. Ela vai definindo qual é o qual é o passo a passo que ela vai dar, né, para que cumpra aquela tarefa.
30:55	Semelhante deep research, n é o deep research, né, que começou com chat EPT e depois se ampliou pros outros. é uma
31:01	ferramenta de pesquisa que pode ser pesquisa externa, ou seja, na internet, na web, mas também pode ser pesquisa
31:07	interna, como era no no notebook LM, nos documentos que o usuário anexa, que
31:12	permite eh que a ferramenta eh eh estabeleça um plano de pesquisa validado
31:19	pelo usuário, eh inicie aí uma busca de informação com vários modelos
31:25	trabalhando em paralelo para conseguir consultar centenas, milhares de fontes.
31:31	ao mesmo tempo consegue fazer, né, uma coleta de conteúdo de alta qualidade e
31:37	uma outra equipe vai ser responsável por criar e estruturar a o formato de resposta, o relatório de de resposta,
31:43	que pode ser de 10 páginas, pode ser de 20, pode ser de 100 páginas. Então, eh, esse é o Deep Research, uma das
31:50	ferramentas mais incríveis que já mostrava também esse modelo multiagente trabalhando por conta própria. E aí
31:57	tivemos duas grandes mudanças agora recente em setembro de 2025 e outubro de
32:04	2025, que é onde a gente vai destacar eh as transformações que ocorreram.
32:10	Eh, o chat aptado e ele foi considerado um fracasso total e o chat apto,
32:18	multiagente dentro da ferramenta, né, que já já era automático. Eh, ou seja, o
32:24	Deep Research era uma ferramenta específica de de pesquisa, né, humanos
32:29	também, mas o chat PT transformou quase tudo em um em um orquestrador, né? Eh, e
32:37	aí, qual foi o grande erro do chat EPT? Como ele quer criar essa tal de AGI, ou
32:43	seja, ele quer criar um modo agêntico em que o agente é autônomo, ele tirou o poder do usuário. Então, o usuário que
32:50	estava acostumado com interações simples, com assistente simples, passou a ter uma fricção na conversa com a
32:56	máquina. Porque ao invés de você conversar com a máquina, você estava conversando com uma equipe em que eh
33:04	você não tinha controle sobre o que a máquina ia fazer, você não tinha previsibilidade, você não tinha eh eh
33:12	uma padronização de de fluxo de trabalho, porque você não controlava isso. Então, por exemplo, eu vou fazer
33:18	aqui um exemplo bem simples, só para que a gente veja eh o tamanho da loucura, né? Eu vou colocar aqui no Pro que é o é
33:25	a versão que funciona de modo agêntico por padrão, né? Ou seja, ele necessariamente por uma escolha que eu
33:31	fiz aqui, ele vai ativar o modo agêntico e e a gente vai ver como a resposta não tem sentido. Se eu pergunto aqui, ó,
33:38	qual a capital da França? Né? Qualquer modelo assistente simples
33:45	responderia rapidamente Paris, né? Eh, o modo agêntico ele para refletir, para
33:53	ver o que é que eu perguntei. Eh, eh, ativa o modo de deliberação para saber
33:58	quais ferramentas ele vai ativar. Se ele entender que é razoável ativar a ferramenta de busca, ele vai ativar a
34:04	ferramenta de busca, vai pesquisar qual é e a capital da França e talvez ali 5
34:11	minutos depois vai me dar uma resposta. Então não tem sentido esse modo agêntico
34:16	desse jeito. É claro que esse modelo aqui eh eh e no começo tava assim,
34:21	praticamente toda vez que você fazer uma pergunta, ele criava esse fluxo aí maluco de ativação de agentes e que todo
34:29	mundo odiou, ninguém gostou. Até que ele mudou a lógica, né? Eu vou vou até abrir aqui uma nova conversa para estabelecer
34:36	um modo alto, né? que se eu perguntar qual é a capital
34:42	de da França, aí nesse modo automático ele vai definir se vai para um pensamento prolongado ou se vai dar uma
34:48	resposta mais rápida. E aqui ele rapidamente ele pensa eh eu consigo fazer sem precisar pesquisar. Se eu
34:54	colocar aqui eh uma pergunta eh
35:01	quanto foi o jogo do Ceará eh o último vou colocar ontem
35:10	aí nesse caso, ele ativa a ferramenta e vai fazer a pesquisa, né, de de na
35:17	internet para dar essa resposta, porque ele sabe que essa resposta ele não tem no conhecimento parametrizado, vai
35:22	necessariamente ter que buscar uma fonte atual. atualizada e a web é que fornece essa fonte. E veja que ele resolveu
35:28	pesquisar só duas fontes, encontrou e já deu a resposta. Se eu perguntasse aqui, né, eh,
35:36	quais são os últimos precedentes do STF em matéria de saúde?
35:44	Aí, nesse caso, o módulo agêntico dele vai perceber que essa pergunta exige mais profundidade, né? E aí, portanto,
35:50	vai trazer mais fontes, né? Então, ele pesquisou aí muito mais fontes do que
35:56	aquela outra. Não foram só duas, foram várias fontes. E aí ele a gente vê quais são as fontes que ele que ele olhou.
36:02	Então, o modo agêntico ele tem esse poder de deliberação, o que é bom por um lado, né? Mas por outro lado torna a a
36:10	comunicação com a máquina muito mais difícil, porque você não sabe se ela vai para um campo de pesquisa longa,
36:15	profunda, ou se vai dar uma resposta mais clara. Então o modo agêntico do chatpt, ele foi um fracasso porque não
36:21	permitiu, não permite ainda hoje o controle do usuário é ativado de modo automático, não dar transparência sobre
36:27	o que ele tá fazendo. Então, muitas vezes você usa o chattando o anexo e ele
36:33	dá uma resposta sem constar o anexo e ele não diz que ele não consultou o anexo, ele não diz e qual é a fonte. Eh,
36:41	ele não coloca mais aquele analisando o documento, ele simplesmente responde e aí tira do usuário o controle para saber
36:48	se ele cumpriu a tarefa corretamente. Então isso é péssimo, você não ter controle e não ter transparência do que
36:54	ele tá fazendo. E, né, como eu mostrei, eh, respostas lentas, comportamento
36:59	imprevisível e irreplicável. Em alguns momentos ele vai ativar um recurso, em outros não, e a gente não tem um
37:04	controle. E aí eu acho que o chatpt deu um tiro no pé com o lançamento do chatt
37:10	conta desses problemas. E isso faz parte do core da empresa, que é criar um
37:15	agente autônomo. Ele quer isso, ele quer uma ferramenta que você faça uma pergunta simples e ele decida se vai
37:22	precisar e eh melhorar a sua pergunta, se vai fazer o modo fing, né? Se se vai fazer o pensamento estendido, eh se vai
37:29	precisar de um cadeia de pensamento, se não vai. ele ele toma a deliberação sobre como responder a sua questão do
37:35	jeito que ele entender melhor. Aí surge em outubro de 2025 a grande transformação, que é a transformação que
37:43	veio através do Cloud, a antropic começou a lançar de modo extremamente
37:49	eh discreto, né, silencioso, sem tanto estardalhaço. Vários e vários recursos, o Sonet 4.5,
37:58	que se tornou o Opus 4.1, um o modelo mais poderoso que tem, mais
38:03	recentemente, o Haiku 4.5, que eh muda o modo multiagente, porque a partir de
38:11	agora o usuário tem mais controle, o usuário pode fazer a escolha de qual
38:17	recurso que vai ser ativado ou não. Então eu tenho o poder de ativar ou não busca na web, eu tenho o poder de ativar
38:24	ou não buscas nas conversas passadas, os resources que ele vai usar, né? ativação de skills. É, é, o processo de trabalho
38:32	dele é todo transparente. Ele vai narrando o que ele tá fazendo de modo muito claro. Ele ele publiciza o promp
38:40	sistema. A documentação do Cloud é muito mais explícita sobre o que ele faz. Eh,
38:46	e portanto nós temos mais controle e ao ter mais controle, nós usuários temos mais poder, mais poder em engenharia de
38:55	prompt que o o que o chatpt não quer, ele não quer que o usuário comum trabalhe com engenharia de prompt,
39:01	porque o prompt, o modelo dele já tem internamente os prompts eh potencializados pelas técnicas internas
39:08	dele, que não funcionam bem, enquanto que o Cloud, ele também tem essas técnicas avançadas de área de promp
39:15	interna dele. Mas ele garante ao usuário mais dirigibilidade, mais poder de controle, tanto controle de eh de
39:22	direcionamento, de contexto, né, de de engenharia de prompt, quanto para o contexto, para o conhecimento, conteúdo.
39:29	E o que a gente nota agora, que é onde eu vou definir a questão do core business, é que o cloud ele pretende se
39:37	tornar uma estação de trabalho, né? Não necessariamente uma estação de trabalho
39:42	é para você só trabalhar, né? É uma estação de trabalho, estação cognitiva, uma estação em que você senta na frente
39:49	dele, consegue fazer suas tarefas, consegue publicar seu PDF, consegue
39:55	fazer sua apresentação em PowerPoint, consegue fazer sua análise de dados com gráficos sem precisar ir para outras
40:01	ferramentas. Ou seja, você consegue dentro da plataforma Cloud trabalhar
40:06	como se fosse uma estação de trabalho com múltiplas ferramentas acopladas, em
40:11	que eu consigo criar documentos estilizados usando as skills, PowerPoints com minhas imagens, eu
40:18	consigo estabelecer templates de PowerPoints e de reportes, né, de relatórios para que saia exatamente no
40:24	formato que eu deseje. Tudo isso é, são as novidades de outubro de 2025 dentro
40:31	do Cloud, novidades silenciosas que é começam a ser exploradas e que pra
40:37	minha, na minha perspectiva, vai transformar tudo. E eu vou fazer algumas apresentações aqui para que a gente veja
40:43	isso em ação. Eh, então isso é incrível, né? O que o que ocorreu em outubro de 2025 é uma grande transformação e isso
40:51	nos mostra aquela aquela bifurcação que eu falei. As grandes empresas que estão
40:56	eh apostando em multimodalidade, apostando no uso universal, eh estão
41:01	querendo amplitude, o máximo de usuários possível e, portanto,
41:07	baixo custo. Elas estão trabalhando no negativo, elas estão tendo prejuízo no
41:12	seu funcionamento porque elas querem gerar dependência, elas querem que o usuário use e ela vão e ela vai ter
41:19	outras formas de monetizar aquele uso, como são as redes sociais, né? ou com os dados do usuário, ou com publicidade, ou
41:27	com algum tipo de técnica de obtenção de recursos de pago ali, eh
41:35	enfim, técnica de monetização. Já o o a Antropic, ela tá apostando em
41:41	profundidade, em tarefas para quem precisa fazer tarefas profundas. Eh, e
41:46	aí, portanto, num uso mais sofisticado, mais complexo e mais caro, né? Essa é a
41:53	grande verdade, né? A Opena, e Google, Grock, Perplex e outras e várias outras
42:00	querem ser porta de entrada para o mundo da IA. Eles apostam no uso popular, né, no uso dos memes ali, nos recursos Nano
42:07	Banana, no Nelo, né, no Sora como rede social, né, eh trabalham eh conversões
42:15	gratuitas que já são muito boas, né, justamente porque tentam eh mirar em
42:20	outras formas de monetização. Eh, para mim ficou muito claro a a parceria que a
42:27	OpenI fez com Booking é muito claro isso, né? Porque acredito eu que se você
42:33	tem o booking a ativado ali dentro do chat EPT, você consegue fazer uma
42:38	reserva de do booking usando o chat EPT, acredito eu que no futuro vai ter algum
42:43	tipo de comissão, é, que o chatpt vai ganhar ou talvez até no presente já exista isso, né? Eh, permitindo que
42:51	tenha outras fontes além disso. Outra, né? Imagine que você tem uma ferramenta de busca, né, como perplex, em que eu
42:57	pergunte qual é o melhor restaurante de Fortaleza. A ferramenta hoje ela vai buscar na internet e vai dar uma
43:02	resposta objetiva de acordo com os critérios que ela tem lá de busca, né? No futuro ou talvez até já no presente,
43:10	eh a IA vai estar eh desenhada para beneficiar em termos de de
43:17	hierarquia aquelas empresas que pagam, aquelas empresas que patrocinam, como é hoje na no Google Pesquisa, em que os
43:24	primeiros resultados são os patrocinados. Então são formas diferentes de monetização que não
43:30	precisam que o usuário pague diretamente ali pelo uso. Eh, e também a gente nota
43:36	eh cada vez mais o desenvolvimento de ferramentas para entretenimento, para diversão de imagens, de memes, de vídeos
43:42	e e aí, portanto, para aquelas interações que o usuário pede uma coisa e se diverte e riração.
43:50	Eh, você não vê o cloud, a antropic desenvolvendo esses produtos. você não vê o cloud desenvolvendo ferramentas de
43:57	imagem, ferramenta, eles está, eles estão focados no corpo de textos, né? Eh, e portanto, eh, para mim é muito
44:04	claro, né, essa essa bifurcação entre propósitos das empresas. Isso também fica bem claro quando o Grock ou o a
44:12	Openai eh usam eh possibilidades provocativas, como por exemplo, a OpenI
44:18	eh divulgou que pretende lançar um chat EPT 18 mais para adultos, né, que
44:24	permita eh provavelmente imagens sensuais, criação de imagens e vídeos sensuais, eh ou até eh algum tipo de
44:34	algo mais pornográfico mesmo para permitir eh uma uma uma uma interação
44:39	adulta, né, com público que tenha 18 anos, algo que eu não imagino a antropic
44:45	fazendo. O Grock também tem isso. A ferramenta do gropo de de imagem já permite que você crie imagens sensuais e
44:51	tem e modos de conversação conspiracionista, satírico, arrogante, eh humorado, eh
45:00	tudo isso é sensual, tudo isso já tem hoje na plataforma Grock mostrando que a
45:06	a a empresa aposta num popular, no uso eh eh como ferramenta de entretenimento.
45:13	O Claud, ele vai para um caminho diverso, apostando em tarefas que exigem profundidade cognitiva.
45:19	e, tem desenvolvido recursos que são claramente mais difíceis de trabalhar porque visam tarefas que são dentro de
45:26	workflow, dentro de fluxo de trabalho, né, como skills, né, eh, skill é um recurso novo, né, pretendo também e
45:33	gravar vídeos e aulas sobre isso, mas que permite que a gente eh ative uma um
45:39	um uma habilidade que naquela interação, naquela conversa, o modelo vai conseguir
45:46	trabalhar. É como se fosse o NO no Matrix que recebia lá aquele aplicativo,
45:52	né, aquele software para ter habilidade de luta, né? Então você dá aquela habilidade e ele quando entra na Matrix,
45:58	ele se torna um lutador hábil. Então você coloca dentro do daquele GPT a
46:04	habilidade de fazer PowerPoint num formato com identidade visual que você ensinou para ele, que você estabeleceu.
46:11	E aí ele vai ativar aquela habilidade e vai conseguir criar o PowerPoint exatamente com aquela habilidade, com
46:16	aquele modelo, com aquele com aquelas instruções que você criou dentro da
46:21	skills. É, temos os artefatos, resources, MCP, são várias técnicas que
46:27	são mais complexas, mas que mostram um uso profissional, um uso para tarefas mais complexas, eh, e, portanto, com
46:34	maior custo. Eh, tem uma questão, eh, tem uma questão importante. Muita gente
46:40	reclama do cloud porque, eh, ele esgota rápido, né, o o uso mesmo na versão
46:45	paga, mas a diferença é essa. A a a a Antropic, ela não está investindo em
46:52	monetizações alternativas, é, em que o usuário vai pagar e eh vai
46:58	receber de graça o serviço e vai pagar de outras formas, com dados, com eh com
47:05	eh comissões ou algo do tipo. E ele simplesmente diz: "Olha, nós nós nós temos que ter lucro. Eh, o seu uso aqui
47:13	é por tokens. Se você usar o modelo OPS, você vai gastar, sei lá, eh, 10 centavos
47:20	por interação, portanto, por 1000 tokens, ele vai colocar um custo lá e
47:25	que de acordo com o que você assinou, você tem direito a usar um determinado limite. Se passou desse limite, a fique
47:30	de castigo, a gente só vai liberar daqui algumas horas. Então isso tem gerado, né, uma uma uma raiva de certo modo ou
47:38	uma um descontentamento com Cloud, mas é uma opção de negócio que mira justamente
47:44	dizer isso. O nosso a nossa forma de monetização é pelo uso. Se você está
47:49	usando muito e no direito a gente precisa de muito porque os nossos contextos são longos, a gente acaba
47:55	tendo que pagar mais, né? Essa é a é a é a lógica do modelo de negócio cloud. Eh,
48:01	e aqui a gente começa a ter uma visão mais prática do que do que tá se desenhando, que é o fato de que a partir
48:07	de agora a gente tem que perceber que não adianta usar uma ferramenta única para tudo, né? Porque cada ferramenta
48:15	vai ter a sua utilidade, a sua função. Nós temos praticamente três modos de uso. O uso casual do dia a dia, né?
48:23	Traduza isso para mim, me diga qual é o melhor restaurante de Fortaleza. eh, faço um roteiro de viagem. Esses
48:30	usos básicos do dia a dia de diversão podem ser feitos por qualquer pessoa,
48:37	né? Não precisa de habilidades especiais e quase todas as ferramentas hoje são eh
48:44	ajudam nisso. Eh, se for uma pesquisa mais sofisticada, o perplex gratuito é
48:50	muito bom, né? Se você quiser pesquisar coisas no YouTube, o Gemini é muito bom.
48:56	Se você quiser pesquisar coisas no X, no Twitter, o Grock é muito bom, né? Então, essas ferramentas de entrada, se você
49:02	quiser uma multimodalidade com imagens, o chat EPT fornece, né? Então, essas essas esse uso de pouco risco, né, que
49:10	que não tem o erro, não custa caro, ele pode ser feito de modo gratuito por
49:15	qualquer ferramenta. Eh, eh, algumas melhores do que a outra. Eh, a metáfora
49:21	que eu coloco aqui é como se tivesse o Spotify e vou solicitar uma música.
49:26	Então, qualquer pessoa consegue fazer isso. Basta baixar o aplicativo, encontrar a música e clicar play, né?
49:31	Clicar no botão. Eh, então, portanto, é e é é esse esse é o modo que as as a
49:37	maiores essas empresas estão querendo focar no modo casual. Nós temos o segundo uso, que é o segundo que a gente
49:44	eh hoje, né, ensina, né, que é o uso profissional. É quando a gente começa a
49:49	trabalhar para uma análise jurídica, as tarefas têm uma média ou alta complexidade cognitiva.
49:55	A tarefa exige precisão, ou seja, o erro tem um custo. Eu não posso, né, usar o modelo gratuito para fazer uma análise
50:02	processual, porque isso é um desastre. Eh, eu eu estou colocando uma tarefa super importante, que é fazer uma
50:07	análise jurídica nas mãos de uma ferramenta que é limitada, é uma ferramenta que tem problemas. Então a
50:14	gente precisa, né, saber que se a gente tiver usando profissional tem que buscar ferramentas profissionais. E hoje eu
50:20	diria que tirando Gemini, a única ferramenta eh eh que é a única
50:25	ferramenta gratuita que dá para usar de modo profissional, eh tirando o GBNI, todas as outras tem que ser versão paga.
50:32	Chat PT tem que ser pago, Perplex tem que ser pago, Grock tem que ser pago, eh
50:38	o Cloud tem que ser pago, né? o uso profissional, tirando, a única ferramenta que permite um uso eh
50:44	gratuito de modo profissional é o Google de Mini, mas eu acredito que cada vez mais isso vai ser eh eh restringido,
50:52	porque o uso profissional ele pressupõe muito poder computacional. O o o uso
50:57	profissional pressupõe eh contexto, pressupõe que você coloque um documento lá de 100, 200 páginas e a máquina vai
51:04	ter que fazer um processamento muito caro para conseguir cumprir a tarefa, sobretudo se for uma tarefa mais
51:10	complexa. Então, eh, quando você tiver trabalhando com com tarefa que exige
51:16	qualidade, precisão, rigor, tem que necessariamente ir para versões pagas,
51:21	né? Uma análise de um processo judicial, análise de um contrato, são exemplos. Nesse caso, para além de você ter uma
51:27	ferramenta paga, né? E aí eu coloco essa esse parênteses que de fato o Gemini
51:33	hoje ele dá para trabalhar relativamente bem, né? Não com toda a sua potencialidade, mas para algumas tarefas
51:40	profissionais a gente consegue trabalhar bem com o Gemini. As outras tem que tem que ir na versão paga, ainda que seja
51:45	básica. Eh, e aí para para você trabalhar não basta ter a ferramenta, você tem que ter agora no uso
51:52	profissional algumas habilidades, conhecer os fundamentos dos LLMs, né? Saber de onde ele tira conhecimento,
51:59	como eles geram texto, eh o que é alucinação. Eh, aqui é o conhecimento
52:05	operacional, né? A gente não precisa saber o conhecimento eh matemático,
52:11	estatístico, a engenharia, física, a arquitetura. por trás dos modelos. Você
52:18	não precisa compreender conceitos complexos de machine learning para usar os LLMs. Não é essa a o conhecimento que
52:25	a gente quer. E talvez aqui seja o maior erro dos cursos de A que tem por aí, porque eles perdem muito tempo na
52:31	história da IA, né, que tem seu valor, mas não é tão relevante para o uso. E
52:37	nas eh na parte mais profunda e complexa do aprendizado de máquina, que também é
52:42	irrelevante pro usuário. O que o usuário precisa saber é o conceito de janela de contexto, como é que é o treinamento da
52:48	máquina para poder, como é que ela prevê, qual como é que é a forma de raciocínio da máquina, da onde é que ela tira conhecimento,
52:55	por que ela alucina, não são os conhecimentos operacionais que que são os fundamentos do usuário que o usuário
53:01	tem que dominar para uso profissional tem que dominar fundamentos e tem que dominar engenharia de prompt. Eh,
53:08	sobretudo quando a gente começar a trabalhar com tarefas complexas, que tem que ter controle da camada de estilo, tem que ter controle do da metodologia
53:15	de análise e aí a gente precisa técnicas para estruturar prompt. é um pouquinho de markdown, um pouquinho de eh eh XML,
53:24	né, de de tags, mas bem bem básico, nada tão complexo. O importante é você ter a
53:30	clareza de pensamento para desenhar um promp de qualidade, né, e conseguir fazer com que ele cumpra a tarefa
53:36	exatamente como você quer. hoje, né, você precisa ter conhecimento de curadoria de conhecimento, entender
53:42	de onde os LLMs tiram conhecimento e direcionar para que você e para que ele tire o conhecimento do lugar certo, ou
53:49	seja, você fornecendo a fonte adequada para que ele trabalhe com aquilo ali,
53:54	seja através dos anexos, seja através de resources que você dá acesso a ele via
54:00	MCP, né, que aí, enfim, é uma técnica que tá cada vez mais simples, é só você habilitar lá o Procure no Google Drive,
54:07	procure no Dropbox, procure procure no meu diretório X e aí você dá acesso a ele, ele vai procurar a informação
54:13	naquela naquela fonte que você colocou. Você precisa saber selecionar a ferramenta, né? Algumas ferramentas como
54:19	chat EPT são boas para geração, persuasão, né? Para ideias. Outras, como
54:25	o Claud são excepcionais para análises sofisticadas, interpretações profundas.
54:31	Eh, outras como o Gemini ou Notebook LM são excelentes para extração de
54:36	documentos mais longos, né, de conseguir eh sem eh ele vai ter perda de qualidade
54:43	em termos de compreensão e até de informação, mas ele consegue ter uma uma possibilidade de você conseguir colocar
54:49	um documento mais longo e ele ter essa resposta. E você precisa saber se comunicar, ter a interação para
54:55	desenvolver os promptos corretos. Eh, o uso profissional como metáfora,
55:00	né? Enquanto que no uso casual você tá usando o Spotify, aperta uma música, ele toca a música. No uso profissional você
55:06	tá tocando o violão, né? A metáfora que a gente faz é essa. Você tem que dominar o a ferramenta, você tem que escolher
55:12	ali, né, o o melhor violão, você tem que saber eh as notas, as habilidades para
55:18	tocar. Eh, e aí, portanto, você tem que ter um pouco de teoria musical e também de prática e de habilidade de
55:24	conhecimento para tocar esse instrumento. É a mesma coisa, assim, o uso profissional, ele tem que ter essa
55:30	curva de aprendizado, eh, para você dominar a ferramenta. E, e nesse caso,
55:35	eh, não só teoria, é teoria e prática, porque você vai aprender usando. E habilidades são desenvolvidas fazendo,
55:42	você não desenvolve habilidades apenas lendo, você tem que praticar para desenvolver. Então, o uso profissional
55:48	pressupõe isso. O o nosso curso de escrita jurídica ele tem por propósito
55:54	habilitar o usuário a dominar isso daqui, a dominar o uso profissional, a trabalhar nesse mundo, conhecer
56:00	engenharia de prometos, fundamentos de LLMs, como usar no direito. Essa é esse é o mote do nosso curso jurídica com IA.
56:08	Agora nós temos um terceiro uso, né, que é um uso muito mais complexo, que é o
56:16	uso estratégico, é o uso que vem com o modo multiagente, eh, que não são mais tarefas meramente
56:24	complexas, são tarefas complexas, encadeadas e com alta
56:30	eh necessidade de confirmação, de validação, ou seja, em que o custo do
56:36	erro é muito alto. Eh, a gente trabalha agora não mais com realização de
56:42	tarefas, mas de multitarefas em etapas, muitas vezes tarefas que têm eh
56:48	ferramentas diferentes de ativação, né, e que precisam de multiplicidade de
56:54	perspectivas. pensamento estratégico é justamente esse, é você perceber que uma solução tem que ser vista em
57:00	multidimensionalidade e que você consegue, né, eh, ativar hoje em dia ferramentas para fazer isso, né, usando
57:07	inteligência artificial. E aí vem um ponto básico, sobretudo para nós do direito, que é a necessidade de a
57:15	gente eh ativar no modo agêntico determinados momentos do fluxo de
57:20	trabalho, porque o fluxo de trabalho é um dominor, é uma rede que vai e encadeando, né, um um bloquinho de
57:28	tijolo que vai sendo construído. Em alguns momentos, alguns pontos, tem que
57:33	dar um stop, né, um checkpoint para que a máquina pare e diga: "Olha, tá aqui o
57:38	que tá produzido, qual é o próximo passo?" Se você não fizer isso, você está primeiro violando a resolução do
57:44	CNJ, como a gente vai falar daqui a pouco, e perdendo a humanidade, se tornando o mero botão da máquina. Então,
57:51	a gente eh esse é o ponto que a gente vai trabalhar aqui, né, para tentar mostrar como é que a gente faz isso na
57:57	prática. Eh, eu trago aqui um exemplo. Eh, esse é um fluxo de trabalho que eu passei a desenvolver essa semana. Eh, a
58:04	uma demanda do da vice-presidência do TRF5, né? a sua amiga, o sea, o colega de
58:10	concurso da da vice-presidente, ela tá com mutirão lá de muitas demandas de saúde represadas porque teve uma
58:16	suspensão de processo, então são milhares de de demandas eh de saúde complexas e e o o passo a passo
58:25	decisório envolve pegar o acórdão e o recurso, os dados do processo, extrair
58:31	as informações relevantes, saber qual é o medicamento, saber qual é a doença, saber quais seus quais foram os
58:36	tratamentos dados. fazer uma pesquisa de conformidade do
58:41	que foi decidido pelo tribunal com base nos precedentes do do STF, sobretudo os
58:48	temas de saúde do STF. Isso é muito complexo. Isso envolve atualizar a
58:54	situação de incorporação ou não do medicamento, se registro, registro na visa, aprovação na CONITEC, preço para
59:00	saber competência, tem é muito complexo, não é simples, é uma pesquisa difícil que tem que ser feita. Eh, e, portanto,
59:07	a pesquisa é uma ferramenta externa. Uma vez que se faz a pesquisa, faz o
59:12	confronto entre o que o estado atual da da da demanda e o que foi decidido no
59:18	passado pelo tribunal, eh, faz uma solução de construções possíveis para aquele caso. E aqui é onde entra a
59:25	tomada de decisão, né? Eh, se você quiser, a máquina decide sozinha e ela vai fazer muito bem, ela vai acertar
59:32	quase sempre. a gente tem mecanismos de de testar para saber se a máquina tá acertando, acertando. Ou seja, a gente
59:39	tem alguns casos de controle, casos difíceis em que a gente submete a máquina e se ela der uma resposta que é
59:44	conforme o gabarito, eh aquele prompt tá validado, né? Não é só um, tem que ser várias vezes. Eh, mas a gente tem a
59:51	possibilidade de criar um um modo agêntico em que você coloca o processo e a máquina faz tudo. Só que a gente
59:58	precisa desse checkpoint. desse checkpoint é justamente eh um momento, e eu vou falar um pouco mais sobre isso
1:00:03	daqui a pouco, é um momento em que a gente vai dizero, agora é você que decide qual é a solução. É isso que a
1:00:09	gente faz em conformidade com a resolução do CNJ. E depois que a eh que se toma a decisão, olha, eu acho que tem
1:00:15	que ser confirmada, eu acho que tem que ser juiz de retratação, negado segmento, admitido segmento. Aí você parte pra
1:00:23	elaboração da minuta, que também pode transferir pra máquina, desde que você indique qual é a solução que tá sendo
1:00:28	dada. Isso tudo no modo simples, né, no modo assistente que a gente tinha antes,
1:00:34	era feito passo a passo. Eu pegava o processo, extraí os dados, aí ia lá no deep research, fazia a pesquisa
1:00:40	profunda, tinha um relatório da pesquisa profunda, colocava num num modo de
1:00:45	análise. Aí no modo de análise ele dizia: "Olha, a solução é essa". Aí ativava um outro promp de escrita, né? E
1:00:51	aí o prom escrita fazia a a a escolha da minuta para poder aplicar o caso. Hoje a
1:00:57	gente não precisa fazer isso. Hoje a gente consegue criar um fluxo de trabalho dentro de uma agente. Eu vou mostrar daqui a pouco em ação, em que
1:01:04	isso tudo é feito ao mesmo tempo. Eh, eu vou mostrar aqui, né, para que a gente não se perca e não fique aqui no mundo
1:01:10	das eh da fantasia, né? Vamos olhar aqui no no
1:01:16	cloud. Eu vou abrir o meu projeto que eu fiz, né, que é um projeto justamente para essas demandas de saúde, né? Eh, eu
1:01:24	vou, eu, eu tava usando os, mas eu vou testar, ver se eu consigo fazer no no
1:01:29	dentro do, do Sonet, né? Eh, o Sonet ele tem ele acaba tendo uma janela de
1:01:36	contexto menor. Não sei exatamente por pelas minhas experiências eu não estava conseguindo realizar com OPS. Só que o
1:01:42	OPS ele ele gera um custo muito alto. É, eu mesmo na versão Max, que é o plano mais caro que tem, né? consome rápido.
1:01:49	Eu consegui consumir todos os créditos que eu tinha do Ops, eh, em basicamente dois dias de uso e fiquei 24 horas de
1:01:56	cartigo não podendo mais usar o OPS desde então. E aí eu tenho testado com outros modelos. Inclusive hoje aqui vem uma dica prática para quem tá
1:02:02	trabalhando com tarefas simples do direito, análise de processo, redação de petição, de minutas, eh eh mesmo que
1:02:10	tenha muito contexto, o ideal é usar o Riku, né? oiku, porque esse esse modelo
1:02:15	é é o é o que consome menos e é mais potente, é mais poderoso do que o Sonic 4. Então, para quem já trabalhava com
1:02:21	Sonet e conseguia boas respostas, pode ir pro Haiku que tá excepcional. Ele é muito bom, ele consegue respostas
1:02:27	incríveis. Mas eu vou colocar aqui o Sonet para que a gente veja essa tarefa em ação. Eu vou colocar aqui o o os
1:02:34	quatro, é o caso complexo, ó. Veja, veja como a tarefa dele aqui vai ser complexa. Eu tenho um acórdão do do
1:02:42	[Música] TRF5 que analisou um caso de saúde. Contra esse acórdo, nós tivemos três
1:02:48	recursos da União, dois da União e um da DPU. A União entrou com recurso extraordinário e com resc e a DPU entrou
1:02:55	com recurso especial. É, acho que é questão de honorados. O que que nós temos aqui? Nós temos uma um promp de
1:03:02	sistema adaptado ao modo agêntico, que estabelece todo o fluxo de trabalho que
1:03:07	ele tem que fazer em cada etapa com determinação do checkpoint, né, do momento em que ele vai parar para dizer:
1:03:14	"Olha, agora você decide". Eh, e a anexação de todos os modelos
1:03:20	possíveis que pra escrita, pra tarefa de escrita. Aqui nós vamos ter basicamente
1:03:26	várias ferramentas em ação. uma ferramenta de pesquisa, uma ferramenta de extração, né? Extrair os dados do
1:03:31	processo, uma ferramenta de pesquisa, né, para pesquisar na internet a conformidade com com os temas, né, com
1:03:39	os critérios que eu estabeleço no prompt, né, os critérios que eu que eu que eu indico como é que vai ter que ser
1:03:45	a pesquisa, né, para cada para cada tarefa, eh, eu digo exatamente qual é as
1:03:50	as ferramentas que ele vai usar, quais são os sites que ele vai usar. Eu tenho que ter o controle disso. Ou seja, se eu
1:03:55	não tiver, ele vai buscar na na revista Veja, que não é uma fonte eh plausível
1:04:01	paraa gente usar no processo judicial. A gente tem que usar nas fontes oficiais. É, portanto, a gente direciona no prompt para ele fazer essa busca direcionada.
1:04:08	Eh, nós vamos ter a ferramenta de checkpoint em que ele vai parar para que eu decida. Depois que eu decidir, ele
1:04:16	vai ter uma ferramenta de deliberação de qual é a minuta cabível e aí vai
1:04:21	escrever, né, uma tarefa de escrita para escrever de acordo com a minuta. Então vou pedir aqui, analise o caso, sabendo
1:04:27	que o prompt oficial mesmo ele tá escondido, né? Ele tá aqui dentro. Eu nem precisava ter
1:04:33	prompt na verdade, né? Eu posso apertar aqui e ele já vai cumprir a tarefa que tá lá guardada no promp sistema. E a
1:04:40	gente vai ver o que é que é o modo agêntico. O modo agêntico ele não para de trabalhar, ele recebe a solicitação.
1:04:48	Antigamente ele dava uma primeira solicitação e parava. Agora ele vai começar a trabalhar ativando várias ferramentas.
1:04:53	Eh, vamos pedir para ele analisar o caso.
1:05:01	Vamos lá. Então, ele vai começar. O que que ele tá dizendo que não tá?
1:05:10	acordo elegível. Por alguma razão ele não juntou o acordo. Bem que eu tentei ler, ele não conseguiu. Vamos juntar de novo aqui,
1:05:17	fazer o anexo novamente. E aí, eh, no no aqui é uma questão
1:05:23	interessante porque quando tem documentação ausente, eh, o acórdão não tá lendo, não tá sendo lido
1:05:30	por alguma razão.
1:05:37	Deixa eu ver se eu consigo achar esse acordão aqui. Eu vou colocar o acordão em PDF. talvez consuma mais tokens,
1:05:47	mas é o jeito, né? Vamos lá, vamos ver se a gente consegue fazer aqui.
1:05:54	Eh, então tem um recurso em TXT e eu vou dizer porque eu coloquei isso, né? Para consumir menos tokens. Já é uma técnica
1:06:00	de engenharia de de contexto, né? Eh, e aí, portanto, ele começa essa tarefa,
1:06:05	né? Eh, e no próprio prompt ele tem essas red flags para dizer, olha, tem informação ausente, eu não posso
1:06:10	continuar a tarefa, né? Então, a ali ele cumpriu bem o meu comando, porque o meu comando é que olha, se não tiver
1:06:16	informação, não invente. E aí, portanto, ele não vai criar isso. Então, ele começou a análise automática. Veja que a
1:06:21	primeira coisa que ele fez, ele extraiu os documentos. Opa,
1:06:32	novamente. Bora ver se vai entrar agora o acórdão.
1:06:38	Se não entrar, eu faço. É, vamos no PDF novamente.
1:06:48	Vamos dar o comando. Vou abrir aqui, aumentar o tamanho para ficar fácil a leitura, né? Vamos ver se
1:06:56	Pronto. E aí, esse é um assistente de de admissibilidade recursal, né? E aí, portanto, ele está fazendo a coleta dos
1:07:03	dados, né? Veja como ele tá. A primeira tarefa é a extração. Então, a gente
1:07:08	consegue ver aqui os dados que ele faz. E aí ele pede a, ele fez um
1:07:16	checkpint, pó, ele fiz a extração, quer que eu continue? Eh, e aí, portanto, vamos lá. Ele vai começar a tarefa aqui
1:07:23	para cumprir o que eu determinei. Tudo isso aqui é o comando que eu dei, né, para sair nesse formato. Começando para
1:07:30	pela tarefa um. Depois que ele fizer essa tarefa um, que é pra gente ter uma visão dos dados do processo, ele
1:07:37	automaticamente colocou o trecho relevante do acordo, voto vencedor, deu provimento, eh ele automaticamente
1:07:43	depois que ele cumprir essa primeira tarefa, ele vai passar paraa tarefa dois, que é a tarefa de pesquisa. Isso
1:07:49	não não era possível antes no modo isso aqui só é possível no modo agêntico, né? Então ele coloca tudo isso, né? Tá
1:07:55	respondendo. Eh, algumas vezes ele vai, ele trava na
1:08:00	pesquisa no modo no no Sonet porque consome muito tokens a pesquisa. Eh, aqui tem um detalhe, né? O cloud, como
1:08:08	eu já falei para vocês, cobra por tokens e tudo que ele produz é token, né? Tudo
1:08:13	eh, token de saída. E quando ele ativa ferramentas, ele também está ativando.
1:08:19	Eh, pronto, ele passa paraa tarefa dois. Aí na tarefa dois, olha, ele vai fazendo as
1:08:24	pesquisas. Isso que ele vai coletando entra no contexto. E aí, portanto, é também consumo de tokens. Então ele tá
1:08:31	pesquisando agora eh a se a medica eh a situação da med do medicamento, eh
1:08:37	questão de todos os os pontos controvertidos é objeto de uma pesquisa específica com 10 com 10 fontes
1:08:45	diferentes. Nesse caso, ele tá indo para cinco fontes, né? Portanto, uma pesquisa muito boa, consolidou todo e a partir de
1:08:51	agora ele vai paraa tarefa de eh estabelecer qual é a situação do medicamento atual, né, que é o é o é o é
1:08:58	é a tarefa dois, ou seja, consolidar a pesquisa que ele fez e criar um relatório para dizer qual é o qual é a
1:09:04	situação do medicamento. Então, o medicamento, né, que é incorporado para
1:09:09	dois tipos de de am, né, eh, is é um caso muito comum, muito frequente, eh, mas não foi incorporado para tipo dois.
1:09:16	no caso concreto não está no PDCT e tal. E aí ele vai fazendo aqui a análise, né? E aí, portanto, tá concluindo a tarefa
1:09:22	de pesquisa, eh, e continuando aqui. Eh, e veja como ele vai criando o relatório, estabelecendo as fontes, né, em que em
1:09:29	que essa informação está. Eh, e uma vez aqui eu quero mostrar o checkpoint,
1:09:34	porque uma vez que ele estabelece a situação do medicamento aqui atualizado, ele vai passar pra tarefa três, que é a
1:09:42	criação do checkpoint. Então veja que ele tá aqui estabelecendo quais são as as os pontos de conformidade e de
1:09:49	inconformidade, né? E aí, portanto, a gente tem aqui todos os elementos necessários paraa
1:09:55	tomada de decisão. Só que ele eu podia pedir para ele tomar a decisão e ele vai tomar e ele acerta, né? Só que como a
1:10:01	gente não pode dar o controle pra máquina, a gente tem que fazer a
1:10:08	eh a tarefa três, que é uma análise multiperspectiva. Ele vai criar três perspectivas. diferentes, eh, três
1:10:15	opções, colocando red flags e pontos positivos e negativos, precedentes favoráveis, pontos fortes, pontos
1:10:21	fracos. Então, primeiro, primeira solução, tarefa, tarefa dois, tarefa três. Isso aqui são boas práticas de de
1:10:29	workflow, né, para o direito, principalmente. A gente coloca o primeiro solução, análise eh
1:10:35	perspectiva, o rigor processual distrito. Se você for cumprir rigorosamente a processual, essa é a
1:10:41	solução, negar segmento, né? Se você for fazer uma casuística
1:10:48	sensível ao caso concreto, é negar seguimento aos dois, né? E no outro
1:10:54	devolver a turma por retratação, equilíbrio institucional, ele vai dizendo os pontos favoráveis e tal e vai
1:11:00	pedir para eu dizer, né? Tá aqui, tá aqui os três pontos. Você pode fazer isso, isso, isso. O que que você quer que fazer? tem isso respeita a autonomia
1:11:07	do ser humano. Então, eh, e aí, portanto, eh, o, o legal aqui é você ver
1:11:13	essa perspectiva multiagêntica. Eu vou colocar a perspectiva três
1:11:20	porque é a melhor só pra gente ver agora.
1:11:29	É, ele atendeu os limites, atingiu os limites, né, de caracteres, né, consumiu todos os tokens, mas eh a gente, mas a
1:11:35	gente consegue fazer isso no Ops. No ops dá certo, né? Não quis gastar meus tokens de ficar só demonstração, mas a
1:11:41	ideia aqui era mostrar isso em ação, é como é que é esse modo múlti com a gente. E aí o que é que a gente percebe
1:11:47	nesse nesse novo modo de uso dos LLMs? que a gente passa até a ter novas
1:11:54	necessidades dentro do do de habilidades para usar corretamente
1:12:01	nesse modo estratégico que é engenharia de workflow. A gente tem que ter uma visão muito clara do processo de
1:12:07	trabalho. O que é que tem que ser feito, quais são as tarefas, quais são as ferramentas, quais são os direcionamentos para cada tarefa, quais
1:12:13	são os checkpoints que a gente tem que estabelecer. Nós temos que ter uma engenharia de prompt muito mais
1:12:18	avançada. Para vocês terem ideia, a o prompt sistema do Cloud Sonet, né, que é
1:12:26	o prompt que a própria Antropic usa para seu guia de de instrução, o guia de
1:12:33	conduta e comportamento do do Sonet e Promptistema
1:12:40	GitHub. colocar aqui pra gente ver esse prompt. Ele tem 115 páginas. Deixa eu ver esse aqui.
1:12:48	Esse aqui é melhor. Eh, não é esse, é esse aqui.
1:12:57	Eh, a gente tem acesso, basta botar prompt system GitHub, vai aparecer várias fontes de conhecimento. E aí é
1:13:03	uma fonte muito boa de aprendizado você estudar isso, né? os prompts feitos pelas empresas, tanto para ver a
1:13:10	formatação, as técnicas que ele usa, mas olha, isso tudo é um prompt que vem antes da
1:13:16	conversa do usuário, isso faz parte da janela de contexto, né? É mais uma razão pela qual o o Cloud consome muitos
1:13:22	tokens. Ele tem um prompto sistema tão longo, sem páginas, que já consome boa parte da da janela de contexto só esse
1:13:29	prompto sistema, né, que ele que indica quais são as habilidades, quais são as técnicas que ele é, qual é o
1:13:35	comportamento, né, o que que ele tem que fazer, quais são as ferramentas. Tudo isso é o promp sistema da da antrópica e
1:13:42	é um prompiagêntico. É esse promp é um promp agêntico. É um promp que vai orientar o agente a
1:13:48	trabalhar. E aí a gente consegue criar prompts também nessa linha para os
1:13:53	nossos agentes, para os nossos nossos prompts multiagentes. Isso vai exigir, portanto, uma engenharia de prompt
1:14:00	sofisticada. Ou seja, o modo agêntico ele não facilita a engenharia de prompt não ser para o uso eh casual, mas para o
1:14:07	uso prof. profional e uso estratégico, você tem que ter mais engenharia de prompt para conseguir dominar e controlar a máquina, estruturar tarefas,
1:14:15	estabelecer critérios eh de ação, identificar as ferramentas que vão ser ativadas, quais são os resources que ele
1:14:20	vai pesquisar, tudo isso a gente tem que ter um uma visão clara dentro do nosso workflow, do nosso fluxo de trabalho
1:14:26	para que se faça, né? Eh, nós temos que ter engenharia de contexto, a chamada curadoria de contexto, curadoria
1:14:32	estratégica. Por quê? Porque se eu coloco muita poluição dentro do meu
1:14:38	prompt agêntico, os tokens vão embora muito rápido. Então eu tenho que trabalhar com curadoria estratégica do
1:14:45	conhecimento relevante. E isso é muito fundamental. São tarefas muito complexas, encadeadas que vão sendo
1:14:51	elaboradas a partir daí. Você tem que saber orquestrar as ferramentas, né? quando usar, em que ordem, quais
1:14:57	ferramentas usar, definição de checkpint estratégicos, metacognição e o pensamento adversarial
1:15:03	para você pegar aquela solução que a deu e criticar, saber o que que ela fez, eh, não aceitar passivamente tudo isso. Isso
1:15:10	vai exigir uma curva de aprendizagem mais elevada, mas não é eh não é tão
1:15:16	diferente do que a gente tá tá acostumado na vida profissional, né? Eu eu dou um exemplo aqui. Eh, eu eu sou
1:15:22	juiz há 25 anos e eu consigo fazer uma análise de um processo do início até a
1:15:28	tomada de decisão. em 10 minutos, por mais complexo, mesmo que ele seja mais
1:15:34	complexo, eu consigo fazer a a análise, eu consigo fazer a pesquisa, eu tenho um fluxo de trabalho já construído há 25
1:15:40	anos que me permite ter essa tomada de decisão eh rápida, porque eu tenho
1:15:46	experiências com processos praçados, eu sei o que olhar dentro de um processo, eu sei que ferramentas eu vou usar para
1:15:51	fazer pesquisa, né? Eu sei quais são os red flags que eu tenho que prestar atenção com mais cuidado. Então, eu
1:15:57	tenho todo esse esse how to do na minha mente já automatizado. E aí, portanto,
1:16:04	eu consigo fazer muito rápido essa análise. Se uma pessoa sem experiência for fazer o mesmo trabalho, ela vai
1:16:10	levar semanas, né, para conseguir cumprir a mesma tarefa. Então isso significa que quando a gente começa a
1:16:16	trabalhar com isso, vai se automatizando, vai ficando mais fácil. Eh, se você trabalha com plan do Excel,
1:16:23	sabe disso. No começo era super difícil entender aquilo ali para fazer uma fórmula simples. Com tempo e com cursos,
1:16:29	né, você vai aprimorando e aprendendo para trabalhar com níveis mais sofisticados.
1:16:34	Eh, e aí, portanto, eh, você vai ter uma curva de aprendizagem mais demorada, mas vale a pena pela pela pelo diferencial
1:16:41	competitivo e pelo ganho de tempo que você ganha, né? Aqui é um ponto, ó. Por exemplo, se eu fosse fazer um trabalho
1:16:47	como esse, né, de fazer um fluxo, né, de análise de um processo como esse, eh,
1:16:52	sem, eu talvez levasse uma hora, né, para fazer a leitura do acórdo, leitura dos dos eh
1:17:02	dos recursos, pesquisa de jurisprudência de e também de atualização da condição
1:17:08	do medicamento. Eh, redação, elaboração, umas duas horas levaria para construir isso. com inteligência artificial eu
1:17:14	consigo fazer em 15 minutos, em 20 minutos, eh, e com a qualidade superior,
1:17:19	porque eu, eh, a máquina consegue extrair os elementos relevantes, me dá um direcionamento estratégico e eu tomar
1:17:25	uma decisão sabendo exatamente quais são os pontos relevantes. Provavelmente eu fazendo uma análise rápida, eu vou
1:17:30	perder coisas importantes do processo, eu não vou conseguir captar tudo que tá nos três recursos, né? E aqui eu consigo
1:17:36	ter essa visão, é, global, é, pra tomada de decisão, é, de modo muito mais eficiente. E, e aí, portanto, é o ganho
1:17:43	de tempo que você tem, é, com isso é imenso. O trabalho que você fazia em 2 horas ou até mais, você vai fazer em 15
1:17:50	minutos. Você ganhou aí 2 horas da sua vida que você tem para se dedicar a outro processo, para se dedicar a um
1:17:57	pensamento até mais profundo dentro do mesmo processo, né? Se a máquina acenderu um red flag ali, olha, tem esse
1:18:03	ponto que vale a pena pesquisar mais profundamente. Você vai pesquisar isso aí mais profundamente e analisar com mais calma, né? E e tudo isso você
1:18:10	controla dentro do prompt, né? Você estabelece que a máquina tem que ter essa visão colaborativa de ativar red
1:18:16	flags para o usuário eh ter também a sua participação na tomada de decisão. E
1:18:22	isso vai ter custo elevado. Eh, essas ferramentas, como eu falei, elas trabalham eh com uso, né? E o uso é
1:18:29	token, é texto, né? Quanto mais eh existe texto, mais consumo tem. E aí
1:18:35	você vai ter uma situação em que o o as ferramentas vão trabalhando junto, vai aumentando o contexto e esse contexto
1:18:42	vai tornando mais caro esse uso. E aí, portanto, você precisa eh ter uma uma
1:18:47	visão muito otimizada eh para saber que vai ter que pagar recurso em algum momento, mas que eh tem que também
1:18:55	otimizar esse recurso escolhendo as melhores ferramentas. e fazendo engenharia de contexto para colocar o conhecimento relevante. Eh, vai, você
1:19:03	vai ter um nível de complexidade de trabalho mais alta, né? Porque você vai precisar desenhar o seu fluxo. Esse
1:19:09	fluxo tem muitas variáveis e você precisa conhecer essas variáveis, mas você vai ter uma vantagem competitiva
1:19:15	exponencial. A metáfora aqui, né, enquanto a do uso casual é a metáfora do Spotify e a metáfora do uso profissional
1:19:22	é a do violão, agora é a metáfora do maestro. você tem uma orquestra a seu
1:19:27	dispor e essa orquestra ela vai ser coordenada por você. Se você souber
1:19:33	coordenar essa orquestra, você consegue estabelecer tudo, né? Eh, intensidade, a música, o ritmo, né? Você tem esse poder
1:19:41	de quais são os instrumentos que vão ser ativados, quais são os que vão ser desativados. Então, eh, a sua
1:19:47	habilidade, a qualidade da da música que vai sair aí vai depender da habilidade que você tem de orquestrar esses vários
1:19:54	instrumentos ao mesmo tempo, né? dominar essa orquestração. Se você não souber
1:19:59	orquestrar, você vai pra plateia, você vai apertar um botão, a a orquestra vai
1:20:05	tocar sozinha, você vai assistir. O resultado vai ser bem legal, vai ser divertido, mas você vai ser apenas um
1:20:12	espectador, sem ter protagonismo naquilo que a máquina tá fazendo. Ou seja, você é descartável, né? Você deixa de ser
1:20:19	relevante para o mundo profissional. Eh, então falamos aqui do modo de uso.
1:20:27	Vamos para uma síntese parcial aqui desse vídeo. Já ainda estamos na metade, mas já tem muita coisa. Eh, então a
1:20:33	gente vê a diferença aí na da era dos assistentes para a era dos agentes. Na era dos assistentes, as principais
1:20:40	habilidades eram eh promp engenharia de prompt. Eh, a conversa é linear, tarefa
1:20:46	por tarefa, passo a passo, né? você controla cada passo e basicamente a
1:20:52	habilidade é saber conversar com a máquina. Na era do agente, né, você tem essa nova eh necessidade que é dominar a
1:21:00	engenharia do workflow, engenharia de contexto, engenharia de prompt e engenharia de workflow. Aumentou a
1:21:05	complexidade, aumentou o nível de exigência de aprendizagem, são mais ferramentas que você vai ter, mais
1:21:10	nomenclaturas e terminologias que você vai ter que se adaptar. Você vai ter que perceber que o modo de trabalho não é
1:21:16	linear, ele é multietapas. né? E até mesmo com bifurcações, com
1:21:21	direcionamentos possíveis, eh, você vai trabalhar como supervisor e como
1:21:29	decisor. A, o trabalho pesado vai ser feito pela IA, né, de extração, de análise, de pesquisa e você vai ser vai
1:21:36	receber, né, o conteúdo paraa tomada de decisão a partir dali, né, e, portanto, precisa ter muito mais habilidades e
1:21:43	competências para orquestrar tudo isso. É, fazendo aqui mais uma uma um
1:21:49	detalhamento dessas competências. Por que que eu tô dizendo isso destacando tanto a questão da competência? Porque o
1:21:55	mundo ele vai ser dividido e entre o grupo que não vai entrar nessa e nova etapa, né? O grupo que vai ser o eh o o
1:22:03	a plateia, né, do da das orquestras e o que vai ser orquestrador, né? o nós
1:22:10	vamos ter essa divisão, né, de de trabalho que serão poucas pessoas que vão dominar a capacidade de orquestrar
1:22:17	esse workflow com máquinas, né? E aí, eh, se você quiser fazer parte desse
1:22:22	mundo, você tem que perceber que tem um custo, custo de tempo de dedicação, custo de investimento financeiro, né? um
1:22:30	custo de eh domínios de complexidades que que vão ser que vão vão demorar, né,
1:22:36	para ser incorporadas na sua na sua mente de modo de modo automatizado. Eh,
1:22:41	no nível funcional, nós continuamos com aquele conhecimento básico que tem que ter, mesmo que você não entre no modo
1:22:47	agêntico. Usar ferramenta de a para o uso profissional pressupõe que você tem que ter domínio dos fundamentos dos LLMs
1:22:54	e também engenharia de prompt. É, são os dois domínios que você tem que ter. E eu deixo aqui o quadro aberto para que
1:23:00	vocês vejam. Eh, no nível intermediário em que a gente começa a trabalhar, né, com tarefas mais complexas, a gente
1:23:08	começa a ter domínio de engenharia de contexto. Que que é engenharia de contexto? É você fazer a curadoria de
1:23:13	conhecimento, fazer uma uma estruturação desse desse organização desse
1:23:19	conhecimento para que não haja distração nem poluição, né? conseguir respostas
1:23:24	mais otimizadas, conseguir economia de tokens, conseguir que a máquina foque
1:23:29	naquilo que é essencialmente relevante. E aí, portanto, eh, a gente tem essa
1:23:34	esse poder através da engenharia de contexto e ativar, né, as ferramentas que vão levar ela a fazer a leitura
1:23:41	desse contexto de modo correto, saber se vai ser uma busca semântica, saber se vai ser uma busca literal, se vai ser
1:23:46	uma busca híbrida, é saber qual é o critério que a máquina vai usar para colher a informação. Em alguns casos for
1:23:53	dados, por exemplo, a literal é a melhor, né? Se for uma questão e aqui um
1:23:59	parêntese, né? O que o que é que é a busca semântica? Eh, se eu se eu vou pesquisar e eh eu tô num num processo
1:24:04	trabalhista e eu quero pesquisar eh quem é o réu da ação, né? Eh, qual é o nome
1:24:11	do empregador, né? Eh, se eu peço eh uma busca literal sobre quem é o empregador,
1:24:18	a máquina vai procurar empregador e vai trazer a resposta quando encontrar a palavra empregador. Se eu peço uma busca
1:24:25	semântica, ela vai para palavras que possam se referir também a empregador,
1:24:30	não só sinônimos, mas palavras que estejam próxima, patrão, eh, empresário,
1:24:37	chefe, tudo isso entraria, né, no conceito e aí, portanto, ele encontraria mais possibilidades dentro do texto se
1:24:43	ele fizesse essa busca semântica, que é uma busca por proximidade eh semântica
1:24:49	entre as palavras. Essa é a lógica, mais ou menos da busca semântica. Então, eh eh hoje eh em alguns contextos, a gente
1:24:55	tem o poder de determinar que seja busca semântica ou busca literal. E para cada
1:25:01	um dos contextos tem a sua vantagem e desvantagem de fazer tudo isso. Além disso, você precisa saber envelopar, ou
1:25:07	seja, eh colocar esse documento de um modo que fique fácil para Iar. Hoje
1:25:12	quase todas as skills, por exemplo, elas são envelopadas no formato específico, né? Elas são zipadas dentro de um pacote
1:25:19	que tem Markdown, tem todo as pastas que você tem que saber envelopar. É possível
1:25:25	criar mecanismo que a propia envelope para você, mas eh tem que entender pelo
1:25:31	menos que tem que precisa ser envelopado e como envelopar, né? eh e conhecer as
1:25:36	ferramentas com seus protocolos de acesso para que esse conhecimento seja acessado e ativado de modo eficiente.
1:25:43	Eh, outro, como já falei, aceleração estratégica de ferramenta, né? Saber qual ferramenta usar para cada tarefa,
1:25:49	inclusive para ter economia, né? Se você tiver trabalhando com Clou, você tem que saber que agora você tem que
1:25:55	necessariamente perceber que o OP é para situações muito raras, tarefas muito
1:26:00	complexas ou então quando você tiver muito recurso para gastar nele, né? É, mas é, geralmente não compensa você usar
1:26:08	o OPS para tarefas simples, porque gasta muito token. É caro o Sonet para algumas
1:26:14	tarefas complexas que exigem muita precisão, mas que eh
1:26:20	que não são tão complexas ao ponto de ser necessário usar o OPS. E a principal hoje vai ser o Haiku, né, para aquela,
1:26:26	pelo menos pro modo, pro modo simples, né, se a gente viver trabalhando com modo agêntico, modo estratégico, talvez
1:26:31	o Sonet seja melhor. Mas o Haiku também funciona muito bem. é mais econômico. Ele tem o mesmo poder do Sonet, até mais
1:26:38	poder do que o Sonet 4, que era o modelo anterior, e consome três vezes menos de tokens do que o Sonet 4.5. Então, vale
1:26:45	muito a pena usar o Haiku para as tarefas jurídicas hoje em dia, para firac, para relatório, para aquelas
1:26:52	tarefas que a gente já fazia de modo profissional. E aqui vem o diferencial, né, para o nível avançado, esse nível estratégico,
1:27:00	que é o nível de que vai fazer o diferencial de mercado, a gente vai começar a ter que ter pensamentos ou
1:27:06	habilidades e conhecimentos diferentes. Eh, a nossa pós-graduação
1:27:12	em inteligência artificial generativa no direito, ela foca nisso. quer levar você
1:27:17	de um nível profissional para o nível avançado, para o nível estratégico, eh, transformar você não só no músico, mas
1:27:24	num maestro, né? Essa é a lógica. Eh, e a gente vai trabalhar muito no modo
1:27:29	agêntico, né? é o modo que vai agora dominar toda a linguagem de comunicação com as máquinas nesse uso mais profundo
1:27:37	é o modo agêntico. E para isso a gente tem que ter metacognição, pensamento
1:27:43	claro, eh pensamento adversarial, pensamento crítico, conhecimento de workflow, desenhar modelos e fluxos de
1:27:50	trabalho, identificar sequências lógicas, estabelecer checkpoints estratégicos, interar, testar, validar o
1:27:56	fluxo. Tudo isso é hoje uma habilidade que tem que ser desenvolvida para quem quer trabalhar nesse novo mundo. Eh, e
1:28:03	aí, portanto, e a lógica aqui é que se você não souber desenhar bom fluxo de
1:28:09	trabalho, o trabalho não vai ser bem feito. a máquina não vai saber fazer alguma coisa específica, como por
1:28:15	exemplo, se eu coloco o processo judicial lá de saúde e peço pra máquina sem prompt, sem nenhum tipo de workflow,
1:28:22	sem nenhum tipo de engenharia de contexto, eh, analisa aí para ver se
1:28:27	qual é a solução desse caso. Ela vai dar soluções completamente aleatórias, completamente erradas, completamente
1:28:33	imprevisíveis, completamente não escaláveis, não reproduzíveis, né, não
1:28:38	transparentes. E aí, portanto, e você vai perder o controle, você vai ser o mero botão da máquina, não? E é isso que
1:28:44	a gente não quer. O nível avançado é o que vai diferenciar o profissional que que faz a diferença.
1:28:52	Eh, eu já falei aqui desse workflow, né? Mas só para tornar aqui a nossa linguagem mais clara, nesse workflow que
1:29:00	eu estou testando, né? Eh, ele tá funcionando já, só que ele tem eh uma
1:29:07	limitação porque, como a gente viu, ele consome muito tokens. Eh, se eu usar no
1:29:13	modo Ops, ele faz a tarefa toda com mesmo complexa. Nesse caso, são três recursos que ele vai ter que analisar ao
1:29:18	mesmo tempo, né? Eu coloquei de propósitos para que vocês vejam o poder do modelo. Eh,
1:29:25	e ele vai fazer muito bem, ele consegue cumprir muito bem, que é esse esse fluxo de trabalho para análise de admissibilidade de recursos em demandas
1:29:32	de saúde. Eh, mas eu poderia fazer tarefa por tarefa, ou seja, começar apenas com um recurso. Ficaria mais
1:29:39	fácil ele conseguiria fazer tudo de uma vez. Eh, mas ele tá funcionando muito bem, mas ele consume muito tokens ainda.
1:29:45	Então, eh, eu tô pensando no fluxo de trabalho para ver como é que a gente consegue tornar isso mais eh mais
1:29:51	prático para não consumir tantos tokens de uma vez. Mas basicamente a gente tem tarefa de extração, tarefa de pesquisa,
1:29:58	tarefa de análise boot perspectival, uma fase de checkpoint humano, que é onde o humano vai olhar o que foi feito
1:30:04	de análise. Olha, tem esses três, essas três possibilidades decisórias que tem aqui os pontos fortes e pontos fracos.
1:30:10	Estão aqui as red flags, né? Você decide, né? Diga qual é a sua solução. O ser humano vai decidir quais são as três
1:30:17	soluções possíveis. A máquina vai a partir daí fazer a redação e a própria
1:30:23	máquina vai estabelecer também um input adversarial, né? Um um uma revisão adversarial para identificar lacunas.
1:30:30	Por quê? Porque a partir daqui a gente tem o poder de pedir para a máquina vai escrever a redação e você pode dizer:
1:30:36	"Olha, eh, imagine que você agora é um advogado e eu quero que você veja se esse aqui tem lacunas para eu entrar com
1:30:42	o embarro de declaração e ela vai analisar o processo e aí a partir daí vai conseguir
1:30:48	eh já corrigir e suprir essas lacunas para antecipar uma possível e e
1:30:54	impetração, uma propositura de embarque de declaração contra a decisão. Então, a gente tem um um roteiro aqui
1:31:00	extremamente complexo, um fluxo que eu criei só um, né, já funcional, já tá
1:31:05	funcionando, que faz isso de modo automático. Se eu quisesse, eu tiraria o checkpoint e a máquina consegue fazer
1:31:11	tudo sem participação humana. Só que isso vai ter um problema que é resolução do CNJ. Resolução do CNJ estabelece que
1:31:19	é proibido fazer isso, né? Nós não podemos criar um fluxo de trabalho que não tenha supervisão humana, que não
1:31:25	tenha em em que toda a tomada de decisão seja feita pela máquina. Então, a criação de checkpoints é um princípio de
1:31:32	cumprimento da resolução e e de cumprimento da reserva de humanidade, da
1:31:37	própria lógica de que nós temos que ter a tomada de decisão. O julgamento é
1:31:43	nosso e não da máquina, né? E aí, portanto, nós temos que fazer esse checkpoint. Eh, eu coloquei aqui, mas
1:31:50	não vou me alongar porque já estamos caminhando aqui para muito tempo de de
1:31:56	vídeo, né, que nós temos vários modelos de de checkpoints que eu tenho desenvolvido, né, e o modelo que eu
1:32:03	tenho eh preferido é o que força a
1:32:08	deliberação, né, o que faz com que a pessoa tenha que pensar alternativas. Eh, muitos modelos que o pessoal tá
1:32:15	fazendo, tá fazendo checkpoints em que a máquina dá uma solução e você tem que dizer, concorda ou não concorda? E 100%
1:32:22	das vezes a pessoa concorda, né? Isso tá errado. Isso tá errado. Isso vai criar um teatro. Isso é uma uma fraude. Tem
1:32:30	que ser um modelo de checkpoints em que a máquina vai dizer: "Olha, tá aqui, tem a solução A, solução B, solução C. Essa
1:32:36	é randômica, não tem hierarquia entre elas. Pontos fortes, pontos fracos, né? Se você quiser eh focar em alguma mais,
1:32:42	a gente pode explicar. E aí, portanto, a gente começa a analisar, é o poder do ser humano tomar a decisão a partir daí.
1:32:48	E aí, uma vez que tem um checkpoint, é que se prossegue pra fase seguinte, que é eh
1:32:56	que é fazer a resposta. E como eu falei, né, é nossos prômitos, a gente tem que
1:33:01	forçar o nosso agente a ser transparente quanto a red flags, quanto a pontos críticos, que tem que ser lacunas,
1:33:08	incertezas, eh eh falhas, né, que t que ser apontadas antes da tomada de
1:33:13	decisão. É, o nosso o nosso
1:33:19	propósito aqui com esse vídeo de conscientização é mostrar que a gente chega num ponto mesmo com os agentes de
1:33:26	risco existencial em termos de substituição. Eu eu acredito, né, que a máquina hoje
1:33:34	ela tem uma capacidade decisória, uma capacidade de raciocínio jurídica com os
1:33:39	promptes certos, com o contexto certo, superior ao ser humano, né? o ser humano, ele eh em certo sentido não
1:33:46	consegue fazer uma deliberação tão boa quanto a máquina. Eh, e aí, portanto,
1:33:52	dentro desse contexto, se nós não assumirmos algumas tarefas e algumas habilidades e algum conhecimento, a
1:34:00	gente vai ter um sério problema de virar um botão da máquina.
1:34:05	Eu vejo para 2026 dois cenários, né? Profissional A e o profissional B.
1:34:11	Profissional A, ele vai ser o mero botão. O profissional B vai ser o maestro, né? É ele que vai orquestrar
1:34:18	essa máquina. No no profissional AR, nós vamos ter fluxos de trabalho construídos em que o
1:34:27	agente, o usuário humano, ele vai dizer: "Olha, analisa esse processo, a máquina vai fazer, vai fazer a minuto, vai fazer
1:34:32	tudo e ele vai publicar, ele vai dizer isso vai
1:34:39	tornar o ser humano irrelevante, né? A pessoa que faz isso é completamente descartável. O profissional B, ele
1:34:45	orquestra e vai ter o checkpoint em que ele vai ter a tomada de decisão. E aqui é o que vai salvar o papel do ser
1:34:53	humano, né? Eh, e aqui é importante porque a máquina, quando a gente estimula a máquina a ter perspectiva,
1:34:59	eh, análise multiperspectiva, ela percebe que vai ter aqui pontos críticos, ela percebe que vai ter ali
1:35:06	situações de tradeoffs que não são claras e que precisa de um ser humano decidindo, né? Vai ter casos que é
1:35:12	simples, são casos que a máquina consegue resolver muito bem, mas tem casos que a máquina não consegue resolver, né, como é difícil até pro ser
1:35:19	humano. Então, o nosso papel, né, e esse é o propósito da nossa pós-graduação em
1:35:25	inteligência artificial, é criar os profissionais B, né, os profissionais que desenvolvem habilidades para
1:35:32	orquestrar esses agentes, né? Nós queremos trabalhar como no controle da
1:35:38	máquina. É isso que nós queremos. a a ancora paro, né, que é a nossa pó, né, o
1:35:44	nosso nosso a nossa incorporação da da pós, ela tem a missão de
1:35:51	treinar e habilidade, conhecimento e propósito. Habilidade, saber dominar a ferramenta, saber usar a ferramenta, né?
1:35:59	Eh, conhecimento, entender o que está acontecendo, entender porque que a máquina tá agindo de tal modo, poder
1:36:05	controlar a máquina e propósito fazer do jeito certo, fazer em benefício da
1:36:10	humanidade, fazer do modo correto, fazer, né, pelas razões certas, com
1:36:16	sentido. E e é isso que a gente quer, né, evitar esse risco existencial.
1:36:21	Eh, e aí hoje, eh, fica, para mim fica muito claro que a gente tá hoje já nesse
1:36:26	momento, né, agora a gente já iniciou nova etapa em que a principal ferramenta de trabalho é o cloud, pelo menos para
1:36:34	esse modo multiagêntico em que nós vamos criar os fluxos. O Cloud nesse momento
1:36:40	atual, eu creio que a em breve, muito em breve, não vai ser mais assim, eh, mas
1:36:45	nesse momento, outubro de 2025, o Cloud é o único que consegue fazer essa tarefa
1:36:50	multiagêntica de modo muito com muita qualidade, com estima precisão. Eh, e
1:36:56	ele tá funcionando hoje, né, a pretensão da Antropic é transformar o cloud na estação de trabalho em que você não
1:37:02	precise sair para nenhuma outra ferramenta para trabalhar, né, ou para exercer tarefas complexas. Você consegue
1:37:08	fazer análise, pesquisa, você consegue fazer relatórios, reports, tudo isso sem
1:37:13	sair do cloud, é dentro do cloud, né? Eh, você vai ter problemas de custo
1:37:19	financeiro, né? O cloud cada vez entrega os melhores resultados, só que há um custo muito mais alto. Os modelos do
1:37:26	cloud estão ficando inviáveis para um uso simples, para um uso cotidiano. Apenas grandes corporações estão
1:37:32	conseguindo pagar. Tem um ponto que eu queria mostrar, que eu acabei não esquecendo, que é para mostrar o meu ponto. É o seguinte, quando a gente
1:37:39	entra nas páginas e nas nos lançamentos das empresas, como Google, como Openei
1:37:45	como Antropic, a gente vê a diferença de perspectiva de de apresentação.
1:37:51	Em geral, né? Os vídeos de apresentação da
1:37:56	da Openi são vídeos semelhantes ao do ao da Apple. é aquele vídeo em que ele quer um software que seja lifestyle, ele quer
1:38:04	que seja ali um uma mudança de paradigma. Então, os vídeos de lançamento da OpenI geralmente tem esse
1:38:13	essa cara eh Apple, essa cara de ferramenta que vai e mudar o mundo e que
1:38:19	vai eh ser incorporado ao seu estilo de vida, você vai levar com você no seu bolso. Essa é a visão da da Openi.
1:38:27	Google também trabalha muito, né, na nos lançamentos com esses esses usos assim
1:38:33	cotidianos, usos de vídeo, né, do do do nana banana, desenho animado, né, a
1:38:40	qualidade. Veja como ele ele tem um foco mais de entretenimento, né, mais de uso
1:38:45	eh casual. Quando a gente vai na página da Antropic, no na no perfil da Antropic, é muito diferente. É é algo
1:38:52	que ele tá se comunicando para profissionais, ele tá se comunicando no nível cognitível alto. Eh, ele ele
1:38:59	mostra as ferramentas em ação, ele e veja como isso tudo, ó, isso tudo foram nos últimos dias. Veja como teve muita
1:39:05	mudança nos últimos dias. eh, skills, né, capacidades, connect, né, eh
1:39:13	justamente aquilo que são a a possibilidade de você criar eh eh
1:39:18	ferramentas dentro do Microsoft, eh, do da estação Microsoft, nem precisar
1:39:24	sair do cloud e criar um Word, criar um PowerPoint, eh, o Haiku que foi criado
1:39:30	agora para baratear, né, para criar mais barato, MCP, eh, tudo isso. E se a gente for pros vídeos de apresentação, é, são
1:39:37	todos de alto nível. E lendo a mente de uma de de um Iá, o futuro do do do da eh
1:39:44	dos do código agêntico, eh a aí a eh eh o Cyber Cream, né? Então a
1:39:51	gente tem várias coisas aqui que são técnicas e que são eh tem outras aqui de de apresentação que é construindo eh
1:39:58	fazendo apresentação financeira, né? Como usar o cloud pr pra análise
1:40:03	financeira. É, é, é diferente. É diferente. A gente tem uma ferramenta que não é
1:40:09	que não é para para uso simples, é para para tarefas mais complexas. E aí, portanto, essa ferramenta, ela tem se
1:40:16	tornado hoje a principal ferramenta de trabalho para quem quer entrar nesse mundo agente, né, nesse mundo de seja e
1:40:23	sem codificação, porque aqui você também tem uma uma questão que você tem um nível de complexidade no nível da
1:40:29	programação da do Vibe Code, né, do cloud cloud code e tem o uso plataforma,
1:40:35	que é o que eu quero mostrar aqui, que é o que a gente vai fazer. O o o aopk não
1:40:41	quer que todo mundo vá pro cloud code, ela quer que as pessoas consigam fazer
1:40:47	as tarefas complexas dentro da web, dentro da plataforma web e da plataforma desktop, que tem alguns recursos também
1:40:53	de MCP que são exclusivos para quem tem uso do desktop. Eh, e aí um custo financeiro alto e um
1:41:00	custo de aprendizagem, vários novos conceitos que a gente tem que dominar, né, como workflow, como promptênico que
1:41:08	muda MCP, skills, resources e e também um pouco mais de complexidade pra gente
1:41:13	começar a trabalhar com isso. Só para e também, já que a gente tá aqui, só para
1:41:19	que a gente veja e um exemplo, né, do que é uma skill, né? Eu posso pedir aqui, ó, crie uma apresentação
1:41:28	com dois slides com os propósitos
1:41:35	da ancora em paro, habilidades,
1:41:40	conhecimento e propósito. Ah,
1:41:46	use a skill ancora. E aí eu quero mostrar para vocês o que
1:41:52	que é isso, né? né? O que que é esse modo de estação de trabalho? Claro, foi um prompt bem simples. Eu não dei
1:41:57	conteúdo, é só para ver a demonstração, mas uma vez que eu criei, eu tenho um skill que estabelece a paleta de cores,
1:42:04	o estilo, as formas eh da ancora em paro, a manual de identidade, né, com
1:42:10	outros elementos. Ele lê o arquivo skill que eu criei, desenvolve o código Python para criar o
1:42:18	slide e a partir daí vai criar diretamente esse slide e eu posso dentro
1:42:25	da minha skill colocar imagens, colocar eh as fontes, colocar eh os elementos
1:42:32	visuais, quais são os recursos visuais que eu que eu costumo colocar, né? A skill é um documento que a gente cria e
1:42:40	coloca dentro dele, né? É, é um recurso novo, né? E que permite essa
1:42:45	sofisticação, né, de você personalizar sua interação sem precisar de prompt. O prompt, na verdade, tá dentro da skill
1:42:51	que ele leu, né, da Ancora Imparo e a partir daí criou já a nossa apresentação, né, só para que a gente
1:42:58	veja também, repito, sem nenhum tipo de compromisso com qualidade, porque foi feito aqui meio de de improviso, né, os
1:43:05	três slides, né, vamos ver aqui o que que ele vai fazer em termos para que você veja, né,
1:43:10	o ele ainda não foi. Pronto. Então ele pega as cores, né, da
1:43:17	Ancora Imparo, coloca eh o modelo, coloca os dados que a gente coloca.
1:43:22	Então a gente vê que tem eh claramente aí uma uma
1:43:28	possibilidade de usar isso aqui de um modo muito mais interessante. É uma nova é uma nova ferramenta que você tem que
1:43:35	dominar como fazer um skill, como envelopar, como colocar dentro. Eh, é é um novo prompt de certo modo que você
1:43:41	aprende. Eh, parece complexo, complicado, mas eu digo, é uma questão de costume, de uso.
1:43:47	Uma vez que você aprende, aquilo ali passa a integrar o seu modo de trabalho, a sua forma de trabalhar. Assim como é
1:43:54	complexo começar qualquer ferramenta, né, aprender a tocar violão em complexo no começo, no final você não tá tocando
1:44:00	sem nem saber o que tá fazendo, já entra no fluxo de trabalho. E aí pra gente
1:44:05	concluir, né, nós temos aqui uma síntese de tudo que a gente falou, que eu não tô
1:44:12	dizendo que o cloud vai substituir as outras ferramentas, pelo contrário, não vai, porque o cloud tá caro, né? O cloud
1:44:18	ele vai ser uma ferramenta excepcional para uso apenas para tarefas mais complexas, né? Se você tiver usando a
1:44:25	versão highol e não tiver usando tanto contexto, eh, e não eh se a tarefa
1:44:31	se a tarefa não for importante, né? eh, e longa no no ponto de vista de de
1:44:37	contexto, você não precisa usar o cloud, você vai usar ou as ferramentas gratuitas ou as
1:44:43	outras que todo mundo vai ter que ter, né, para o uso ordinário, você vai ter que usar ali uma ferramenta de imagem,
1:44:48	uma ferramenta de pesquisa, né, uma ferramenta eh mais simples e barata, né, todo mundo
1:44:54	vai usar ali as ferramentas Perplexity, que é gratuito, Gemini, que é gratuito, Notebook LM, que é gratuito. Isso a
1:45:01	gente pode usar para as tarefas profissionais, você tem que ir para tarefa, para ferramentas pagas, né? A
1:45:07	única exceção aí que eu coloco é o notebook LM e o Gemini Pro, que a gente consegue usar de modo gratuito, mas o
1:45:14	chat EPT pago é necessário para tarefas dos profissionais. Eh, se você for pro
1:45:19	chat EPT, ele tem que ser o pago, não dá para usar na versão gratuita. Eh, e dependendo da tarefa, você consegue fazer perplexo também. E dentro do
1:45:27	cloud, se você tiver usando apenas para modo profissional simples, assim, uma análise de processo relatório, tem que
1:45:33	usar necessariamente o Haiku, né? Porque começar, se usar o Sonet ou o Opus,
1:45:39	consumo de tokens vai ser muito rápido, né? E claro, isso muda, viu, pessoal? A questão de custo vai variar, então, eh,
1:45:45	de tempos em tempos e essa questão de quantidade e capacidade muda. Provavelmente vai haver uma mudança, né,
1:45:51	nos próximos meses em relação a isso, né? E aí o que eu tô falando aqui é bem datado. E já para tarefas estratégicas,
1:45:59	por enquanto, outubro de 2025, eu só vejo o Claud Son Opus como passível de
1:46:06	trabalhar nesse mundo agêntico com qualidade. Então, eh eh essa é a lógica
1:46:13	que a gente vê hoje. é um quadro é que tem
1:46:18	é desenhos ainda não tão claros e a dinâmica de desenvolvimento de
1:46:23	ferramentas tá muito rápida. Eh, como eu falei aqui, nas últimas semanas tivemos
1:46:30	todo dia lançamentos do cloud, que são cada um melhor do que o outro, que revoluciona, que a gente vê que ele tá
1:46:36	ali numa perspectiva mesmo frenética de dominar uma área, um setor, mas tá tendo
1:46:41	o seu contrapeso, que é o custo, né? o custo eh de financeiro para poder manter
1:46:46	isso daí. Eh, mas enfim, né? Eu concluo essa essa longa apresentação. Espero que tenha
1:46:52	sido útil para vocês. Eu consegui organizar minhas ideias aqui. Ficou mais claro também para mim, né, esse essa
1:46:59	reflexão em voz alta. Mas eu concluo dizendo e convidando, né, você a fazer parte desse grupo que quer dar um passo.
1:47:06	Se você não domina nada de a, tem zero conhecimento, recomendação, faça curso de escrita
1:47:14	jurídica com A. É um curso que tem esse propósito de colocar você no nível de,
1:47:19	né, de uso profissional, de usar ferramenta com segurança no seu trabalho. Essa é a função principal.
1:47:26	O passo além, quando já está usando de modo profissional, já pretende dominar o modo agênico, dominar engenharia de
1:47:33	contexto, dominar algo mais profundo, fazer fluxo de trabalho mais complexos, aí eh a nossa pós ela ela foca nisso e
1:47:42	vai muito além dos fundamentos, vai muito além das ferramentas, vai muito além da engenharia de prompt, porque
1:47:48	entra também regulação, questões éticas, eh discussões sobre direitos autorais,
1:47:54	eh questões sobre privacidade. Tudo isso a gente foca eh com profundidade com vários professores de extrema qualidade
1:48:01	que trabalham nessa área. Então era isso. Eh, curtam o vídeo, espero que tenham gostado, sigam o nosso canal e a
1:48:09	gente fica por aqui. Até a próxima. Valeu, pessoal. Yeah.
