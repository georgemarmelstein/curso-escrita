0:00	Olá, aqui George Marmelstein e hoje vai ser uma masterclass diferente. Você vai
0:05	assistir uma super masterclass para aprender a dominar a inteligência artificial no direito. Eu tenho uma
0:12	missão, né, uma missão de conseguir fazer com que as pessoas aprendam a usar
0:17	a inteligência artificial na atividade jurídica de modo seguro, de modo eficiente, com profundidade, do jeito
0:24	certo. Eh, aqui vai ser o início dessa transformação. que vai ser o início de
0:30	um processo em que eu vou transmitir para você um pouco da minha empolgação em torno dessa área. Eu vou tentar
0:37	passar o máximo de informação possível, né, para que você saia aqui muito mais
0:43	seguro de utilizar a inteligência artificial no direito, né, a partir em certo sentido, dos erros que eu cometi
0:49	na minha jornada. Foram 2 anos, mais de 2 anos hoje em dia, usando a inteligência artificial na atividade
0:55	jurídica praticamente todos os dias. Eu sou juiz federal e hoje eu uso a inteligência artificial para várias
1:01	atividades, desde escrita, pesquisa, análise, criação de argumentos, enfim, vocês vão ver aqui mais ou menos, né,
1:08	todas as potencialidades de uso dessa ferramenta na nossa profissão. E o que eu vejo hoje em dia é muita gente usando
1:15	essa ferramenta de modo equivocado, né? São pecados que as pessoas cometem ao
1:21	utilizar a inteligência artificial generativa. Aqui a nossa apresentação vai ser exatamente para mostrar os sete
1:29	pecados, os sete erros mais comuns que as pessoas cometem ao utilizar a inteligência artificial generativa. E se
1:36	você aprender por que esses erros são erros, você vai conseguir utilizar com
1:41	muito mais eficiência. É isso que eu quero aqui. Eu quero que as pessoas usem a inteligência artificial no direito com
1:48	segurança e eficácia. Eu acredito que hoje a gente pode categorizar, né, as
1:54	pessoas em quatro grupos em relação à inteligência artificial. O primeiro grupo é um grupo muito minoritário, mas
2:01	que tem cada vez crescido mais das pessoas que utilizam a inteligência artificial extraindo dela o seu máximo
2:08	potencial. São pessoas que conseguem aumentar drasticamente a sua
2:13	produtividade, eh, usando inteligência artificial, consegue realizar muito mais
2:18	coisas em menos tempo, usando inteligência artificial, consegue resultados de melhor qualidade, com mais
2:26	profundidade, com mais precisão, graças ao uso correto da inteligência artificial. conseguem organizar melhor
2:33	os pensamentos, consegue conseguem ter ideias mais criativas, argumentos mais
2:39	persuasivos e tudo isso, né, usando corretamente, com profundidade a
2:45	inteligência artificial generativa na sua atividade diária. Esse grupo, né,
2:50	acredito eu, é um grupo que vai aproveitar bastante do que eu vou falar aqui, porque vai se identificar e vai
2:57	perceber o quanto a sua vida já foi transformada com o uso da inteligência artificial generativa. Nós temos o
3:04	segundo grupo, que é um grupo talvez que também cresce bastante e que em certo
3:10	sentido é o risco, né? é um é um grupo que está utilizando a inteligência artificial de modo amador, de modo
3:16	superficial, sem conhecer os fundamentos dessa ferramenta, eh sem conhecer o que
3:22	é uma janela de contexto, sem conhecer o que é uma alucinação e estão, em certo
3:27	sentido, colocando em risco a sua própria reputação ao usar a inteligência artificial sem domínio, sem dominar, né,
3:35	os fundamentos da inteligência artificial generativa. Em certo sentido, esse vai ser o grupo que eu quero focar com mais carinho. Eu vou falar com todo
3:42	mundo, né? A minha ideia é que todo mundo se identifique com algum desses grupos e eu quero mostrar como utilizar
3:48	corretamente a ferramenta, né? Toda vez que sai alguma notícia de pessoas que
3:53	usam a inteligência artificial de modo errado, produzindo precedentes que não
3:58	existem ou até artigos de leis que são inventados pela inteligência artificial,
4:03	eu recebo mensagem de pessoas que dizem: "Ah, esse não fez o curso, esse não fez o curso." E em certo sentido, isso é tão
4:10	básico, né? É um erro tão primário que eu acredito que depois do que você vai aprender aqui hoje, você nunca mais vai
4:17	cometer esse erro, né? Então esse grupo que usa a inteligência artificial de modo amador é mais ou menos como se a
4:24	gente tivesse dando para esse grupo uma Ferrari sem ele saber pilotar, né? Nós temos duas situações aí que são opostas.
4:32	uma pessoa dirigindo a Ferrari sem saber dirigir, de duas uma, ou ele vai andar bem devagarinho e não vai conseguir
4:39	extrair da máquina toda sua potencialidade, o que de certo modo é a melhor solução, ou ele vai querer
4:45	acelerar, né, o seu carro e provavelmente vai cometer um acidente. Nós não queremos que acidentes sejam
4:51	cometidos. Então nós temos esses dois grandes grupos de pessoas que estão usando a inteligência artificial. Um usa
4:57	corretamente e consegue resultados incríveis e outro usa de modo amador ou
5:03	provocando desastres ou não conseguindo extrair da máquina o seu máximo potencial. Nós temos agora um terceiro
5:10	grupo, que é um terceiro grupo dos que não usam a inteligência artificial. É um
5:15	grupo que não usa por medo, um grupo que não usa por desconhecimento, um grupo que eh assiste notícias de que a
5:24	inteligência artificial alucina, né, inventa precedentes e que ela não está
5:29	100% preparada para o direito e não percebem que isso aí era um discurso do
5:34	passado e é um discurso de quem não sabe utilizar a inteligência artificial. Eu quero também me dirigir para esse grupo
5:41	com muito carinho, porque, né, o medo é filho da ignorância, né? O medo é filho,
5:47	é filho do desconhecido, do incerto, daquilo que a gente não domina e não conhece. No momento em que a gente
5:53	começa a conhecer e dominar, a gente começa a perder o medo. Então eu quero, em certo sentido, mostrar para você que
5:59	é possível perder esse medo. Eu quero mostrar para você que se você usar corretamente a ferramenta, entender os
6:05	fundamentos, entender os erros básicos, você não vai cometer erros a ao utilizar a inteligência artificial. Então eu
6:12	quero me dirigir também a esse grupo que é o grupo que dos que ainda não usam, mas querem usar, querem dar esse
6:17	primeiro passo rumo a esse universo fascinante da inteligência artificial generativa. Nós temos finalmente um
6:24	quarto grupo. Lembrem-se bem, o primeiro grupo usa com qualidade, né? Segundo
6:30	grupo usa de modo amador. Terceiro grupo não usa por medo. Nós temos um quarto
6:35	grupo, aqueles que não usam por uma resistência legítima. aquela ideia do
6:41	incerto, do desconhecido, de que a inteligência artificial ainda é algo que
6:47	precisa de cautela. Esse grupo também, né, merece todo o respeito. Eh, mas eu
6:52	quero também me dirigir a eles. Eu quero me dirigir dizendo que é saudável essa lutar que a gente tenha esse pé atrás,
6:59	que a gente tenha essa cautela, que a gente tenha essa prudência diante de uma ferramenta nova que está revolucionando
7:05	a forma como a humanidade produz conhecimento. No entanto, eu quero também dizer para esse grupo e vai ser
7:12	mais ou menos o foco de toda a minha apresentação, que é inevitável
7:18	a mudança de perspectiva, é inevitável que a gente comece a utilizar a
7:24	inteligência artificial incorporada na nossa atividade cognitiva, na nossa atividade epistêmica. A palavra
7:31	epistêmica se refere à produção de conhecimento, ao conhecimento que a gente produz. Hoje a inteligência
7:36	artificial ela tem algo de super diferente de tudo que a gente já produziu antes, que é o fato de que a
7:42	gente hoje tem uma ferramenta que nos ajuda a produzir melhor. É uma máquina
7:48	de lógica, é uma máquina de conversação, é uma máquina de linguagem natural. Nós
7:53	conversamos com a máquina e a máquina consegue produzir um conhecimento de altíssima qualidade. Isso é o que a
8:01	gente vai tentar mostrar, que é o máximo potencial da máquina. A gente não precisa ter medo da substituição dos
8:08	seres humanos por máquina, porque o que a gente vai focar aqui é no modelo de uso, modelo de uso correto da ferramenta
8:14	em que o ser humano utiliza a máquina para ampliar a sua perspectiva
8:19	cognitiva, a sua perspectiva epistêmica e consegue a partir daí produzir com
8:24	muito mais qualidade. É isso que eu quero mostrar aqui para esse grupo dos que não usam a inteligência artificial,
8:31	seja por medo, né, seja por resistência. Eh, eu quero que vocês pensem mais ou
8:37	menos no que era o PJE antigamente, né? As pessoas tinham medo ali do do que ia
8:43	acontecer. Vários cargos, várias funções iam ser transformadas. Mas eu que eu
8:49	creio que hoje ninguém tem mais saudade de carimbar folha de papel. Ninguém tem mais saudade de ter que ir lá no fórum,
8:55	pegar um processo para tirar cópia, né? Hoje com o processo eletrônico, a gente consegue muito mais praticidade, né?
9:02	Porque o processo foi digitalizado. Com a inteligência artificial é um pouco além, porque a gente não vai apenas
9:09	fazer tarefas mecânicas, tarefas de juntar páginas, intimar ou fazer algo
9:15	que, né, uma máquina faz. A gente vai usar essa máquina para criar melhor, para produzir melhor, né, para escrever
9:22	melhor, para analisar melhor os processos, para pesquisar melhor jurisprudências e precedentes, para
9:29	criar melhor melhores argumentos, para organizar nossas ideias. Tudo isso é o que a gente vai fazer utilizando a
9:35	inteligência artificial generativa. Então, vamos lá. Eu vou começar aqui, né, com a nossa apresentação para falar
9:42	dos sete pecados da inteligência artificial generativa. Eu quero que vocês percebam que aqui o que eu vou falar eh vai ser o mais didático
9:50	possível, porque eu quero que você domine. Eu não quero simplesmente começar a mostrar as coisas para você
9:57	ficar perdido. Eu quero que você saia daqui entendendo do que se trata. Em
10:02	alguns momentos eu vou ser o mais didático possível para que você perceba os fundamentos de como funciona a
10:08	inteligência artificial generativa. Eu, né, como eu falei, já passei por várias
10:14	etapas no uso e posso dizer que eu hoje domino a ferramenta. Hoje utilizo a
10:20	inteligência artificial na minha atividade jurídica para fazer análise de casos complexos, para me preparar para
10:27	uma audiência, né, tanto conseguir, né, captar os pontos controvertidos do caso,
10:32	me ajudar a direcionar melhor as perguntas, elaborar quesitos, fazer mapeamento probatório e argumentativo,
10:40	né, conseguir, por exemplo, eh, escrever minutas com muito mais velocidade,
10:46	escrever emas de decisões, de julgamentos com muito muito mais qualidade e profundidade. Eu até
10:52	inclusive já lancei um desafio de desafiar qualquer juiz, né, qualquer
10:57	desembargador, qualquer ministro, qualquer jurista do Brasil a fazer uma ementa com a mesma qualidade daquelas
11:04	que entas que eu faço utilizando inteligência artificial generativa. O meu GPT customizado, que é uma
11:09	instrução, né, que a gente eh personalizada, que a gente cria para de certo modo ensinar a máquina a fazer uma
11:16	ementa. O meu GPT customizado sobre mentas do CNJ já teve mais de 400.000 usos na loja, né, do C, na loja do do da
11:25	Openi, do Chat PT. É gratuito, qualquer pessoa pode usar. E é a partir daí que eu faço esse desafio. Eu garanto que eu
11:33	consigo fazer uma ementa com mais precisão, com mais qualidade, com mais clareza, né, com mais organização, com
11:41	com escrita mais mais agradável do que qualquer ser humano sem inteligência artificial.
11:47	E eu ainda faço um desafio bem ousado. Eu faço isso em 2 minutos ou até menos,
11:52	mas eu peço 2 minutos para poder fazer uma conferência e eu lhe dou 2 horas.
11:58	Você tem 2 horas para fazer a ementa e eu consigo escrever essa minutos com muito mais qualidade daquela
12:04	que um ser humano produziria. E essa é uma atividade que a máquina faz muito bem, né? A gente vai falar um pouco
12:10	sobre isso, mas lá na frente. É uma atividade de transformação. Você tá pegando uma corda, um voto, né, uma
12:18	decisão e transformando no formato específico. Vamos falar de tudo isso. Você vai entender tudo isso é ao final
12:25	desta masterclasse, desta mega masterclass em que você vai receber
12:31	muito conteúdo, né, para utilizar com qualidade e com segurança a inteligência artificial. Então vamos lá, eu vou falar
12:38	do primeiro pecado. E esses primeiros pecados, né, são os mais básicos, são
12:43	aqueles em que o usuário amador geralmente comete. Vai ser uma forma de eu tentar ensinar como a máquina
12:50	funciona. Eu vou começar a mostrar alguns erros e a partir daqui a gente vai aprender a utilizar a inteligência
12:57	artificial com qualidade. Primeiro pecado é o pecado da busca ou, né, para
13:03	ser mais preciso, usar a inteligência artificial como mecanismo de busca,
13:08	quando na verdade o principal uso dela não é para olhar para trás, para
13:13	pesquisar fatos, mas sim para criar, para transformar. Eu gosto de dizer,
13:19	inclusive, né, que os LLMs eles não reproduzem o passado. Eles não são bons
13:24	em reproduzir o passado, eles são bons em transformar o presente e em criar o
13:30	futuro. Parece meio enigmático isso daqui, mas eu vou tentar mostrar para você com mais clareza tudo isso. A ideia
13:38	base desse dessa da ideia de que o chat o chatpt, o Cláudio, os LLMs, de um modo
13:44	geral, eles não reproduzziam o passado, é que o modo de produção de informação
13:50	dele é diferente daquela que a gente imagina eh quando a gente usa o Google,
13:55	né? Eu vou tentar passar aqui, né, uma, eu vou usar aqui o chat EPT para que a gente veja. Deixa eu abrir aqui a tela,
14:01	né, para que a gente veja com calma. Eh, para quem não conhece, esse é o chat EPT, né? é um modelo de conversação em
14:08	que o usuário, né, nesse campo em que tem pergunta alguma coisa, vai dar um
14:13	comando para a máquina e ela vai responder, né? E a partir daqui a gente consegue criar uma interação, uma
14:20	conversação, um chat, né, uma máquina de conversa, né? A gente vai entender tudo isso ao longo desta aula, mas eu quero
14:27	que vocês eh pensem na ideia de eh o que é que tá acontecendo quando eu peço
14:32	alguma coisa pra máquina. Eu vou abrir aqui o Google, né, e vou colocar a palavra liberdade
14:39	de expressão. Quando eu coloco aqui no no Google liberdade de expressão, né, o
14:45	que é que aparece aqui na nossa tela? Na nossa tela aparece várias vários links,
14:52	né, um ranking de links selecionados pelo algoritmo do Google, né, que se a
14:58	gente clica num desses links, o que é que a gente vê aqui? a gente vê o passado, a gente vê um texto produzido
15:06	no passado, o Google está reproduzindo o passado, né? Aquilo que a gente lê,
15:11	nesse caso, eu abri a página da Wikipedia e a gente vê que esse texto foi escrito em fevereiro de 2022. É um
15:19	texto que alguém escreveu, né? Imagino eu, que sem inteligência artificial, porque nessa época ainda não era, né,
15:25	usual utilizar inteligência artificial. E ele escreveu esse texto sobre liberdade de expressão e publicou. Uma
15:32	vez que ele publica e a gente ativa aqui, a gente tá olhando para o passado. A leitura que a gente faz aqui é uma
15:37	espécie de leitura fotográfica. O que o Google fez foi regurgitar um texto. Ele
15:44	pegou o texto e mostrou pra gente, apresentou pra gente exatamente aquilo que alguém escreveu no passado.
15:51	Se eu faço aqui pro chat EPT, né, escreva um texto
15:56	sobre liberdade de expressão, eh, aqui vai ser um modo de
16:02	processamento diferente. você você vai aprender a a entender o que é que tá por trás de tudo isso, mas eu quero que você
16:08	perceba que esse texto que ele produz aqui, né, provavelmente dizendo que a liberdade de expressão é um direito
16:13	fundamental, é um pilar, tal, eh esse texto que ele tá escrevendo, né, ele
16:18	está escrevendo palavra por palavra e criando algo novo. Ele não está
16:23	reproduzindo o passado, ele está criando um texto inédito. Criando com base em
16:29	quê? em padrões do que ele viu no passado. A gente vai mostrar isso bem didaticamente, como é que a gente treina
16:35	uma máquina. Mas eu quero que vocês percebam que se a gente pegar esse texto aqui, esse primeiro parágrafo e jogar lá
16:42	no Google, né, a gente jogar aqui no Google,
16:47	eh, entre aspas, que é a forma de você fazer uma pesquisa IPS literes, né,
16:53	literal, com a mesma palavra, a gente vai ver que ele não encontrou nenhum documento correspondente. Ou seja, esse
16:58	texto aqui que ele acabou de produzir é inédito. E se eu pedir 1 milhão de vezes para ele escrever um
17:05	texto sobre liberdade de expressão, provavelmente nós teremos 1 milhão de textos diferentes, 1 milhão de textos
17:11	criado do nada, né? Você pode eh tá se perguntando, né, se eh se isso daí não é
17:18	plágio. Não, não é plágio. Não é plágio. É algo parecido com eu pedir para você,
17:23	escreva um texto sobre liberdade de expressão. Muito provavelmente vamos ver como é que o ser humano escreveria isso,
17:29	né? O ser humano a escrever esse texto, ele ia pensar: "A liberdade de expressão é um direito fundamental previsto na
17:36	Constituição que garante a todos o direito de falar livremente, sem cessura". E esse seria o a a assim um
17:43	texto, uma frase normal, usual, esperada de alguém que fosse escrever sobre liberdade de expressão. Mas se eu
17:49	pedisse para você, da onde é que você tirou esse texto? De onde você copiou? Você falou, não, não copiei. Eu tirei da
17:55	minha cabeça, né? Eu li muita coisa sobre liberdade de expressão e eu sou capaz de escrever um texto sobre
18:01	liberdade de expressão. E se eu pedir para você escrever um texto amanhã sobre liberdade de expressão, é um texto de 20
18:08	linhas, provavelmente você não vai conseguir reproduzir um texto igual. Você vai mudar o seu texto. Você vai
18:14	criar o texto com outras palavras. Por isso que a gente diz que o chatpt ele
18:20	não reproduz o passado, ele transforma o presente alterando padrões e cria o
18:27	futuro. É baseado no padrão do passado, mas sempre é com a ideia de que aquilo
18:34	que ele produz é inédito. Então vamos voltar aqui pro nosso slide porque eu
18:39	acredito que a o primeiro tópico, o tópico mais básico, a gente já começa a entender. chat EPT, ele não reproduz o
18:46	passado, ele transforma o presente, eh, e cria o futuro. E aí vem um ponto que é
18:53	contraintuitivo, porque o chat EPT é uma máquina de geração de textos. O G, né, do GPT é
18:59	generator, né, ele gera texto, eh, gerador de texto. Então, é uma máquina que pega uma sequência de textos e
19:07	continua essa sequência de textos. Essa é a lógica do chat EPT. E como a gente
19:12	entrega texto e recebe texto, a gente imagina que por trás dele vai ter bancos
19:18	de textos. Terão arquivos de Word, terão livros, terão eh eh blogs, posts,
19:25	artigos de jornais, artigos científicos que ele vai consultar e vai responder. Não é assim. O chatpt, ele não está
19:33	consultando um banco de textos, ele está, na verdade, eh, calculando
19:39	probabilidades de continuar uma sequência de palavras. Ele raramente vai
19:44	reproduzir palavra por palavra aquilo que ele viu no passado. A memória dele
19:50	não é fotográfica, é uma memória em mosaico de identificar padrões e
19:56	escrever a partir desse padrão, a partir daquilo que a gente imagina que ele vá
20:02	produzir. E ponto central aqui é que dentro dele, dentro dele não existem
20:09	é textos, não existem letras, não existem palavras, existem números. Para
20:18	ser mais preciso, existem parâmetros. Parâmetros são fórmulas matemáticas, né?
20:24	São expressões numéricas que vão ajudar a máquina a produzir, a continuar uma
20:29	sequência de palavras. vai ficar mais claro eh quando a gente entender, né, qual é a lógica de continuação e de
20:36	geração de palavras que a máquina vai fornecer. Por enquanto, vamos aqui para uma parte bem didática, né? Vamos fingir
20:44	que a gente quer criar, né, um chatpt, um cloud, um LLM. Eh, eu falei algumas
20:50	vezes a palavra LLM, né, tecnicamente é modelos de linguagem de larga escala,
20:55	né, que basicamente é isso que eu vou mostrar para você. Um LLM é a é uma máquina que foi treinada com textos para
21:03	produzir textos a partir de textos, né? Se a gente quiser construir um LLM do
21:10	zero, né? O modelo de linguagem de larga escara do zero, o que é que a gente precisa fazer? Primeira coisa que a
21:16	gente precisa fazer é juntar o máximo de texto possível que a
21:22	gente encontrar, sair raspando na internet, artigos, livros, posts, blogs, descrição
21:30	de vídeo, tudo, tudo que a gente puder transformar em texto, em texto de linguagem natural, enfim, música,
21:38	filmes, roteiros, a gente tem que jogar na máquina. Quando a gente fala muito, é muito mesmo. A gente tá falando aqui de
21:46	terabytes de textos, né? Uma quantidade infinita, como se fosse uma grande biblioteca, maior do que qualquer
21:53	biblioteca que existe, né? Porque vai consolidar não só os livros da
21:58	humanidade, mas todos os artigos científicos ou a maioria dos artigos científicos ou quase todos os livros ou
22:04	quase todas as músicas, quase todos os roteiros de filmes, tudo que ele encontrar de texto, ele vai jogar dentro
22:10	de um balaio, de uma espécie de caixa, né? E aqui vem um ponto mais importante,
22:17	que é a parte em que você vai jogar tudo isso para que a máquina consiga aprender
22:22	os padrões da linguagem humana. A máquina aprende a se comunicar, a máquina aprende a conversar
22:29	em linguagem natural usando textos como base. Basicamente, ele consegue perceber
22:36	os padrões de linguagem, o que é que é uma semântica, o que é que é a coerência, né, de um texto, né, porque
22:43	ele viu muitos e muitos textos e começou a identificar padrões. Como é que ele faz isso? Você pega todos esses textos e
22:50	joga dentro de uma máquina de calcular e identificar padrões de linguagem. essa máquina vai transformar esse textos em
22:57	números, né, em um vocabulário numérico que ele vai conseguir, em certo sentido,
23:02	calcular, né, qual é o peso de cada palavra dentro de um texto. É como se
23:08	ele tivesse pegando um livro, pegando palavra por palavra e criando um index
23:13	para dizer quando aparece a a palavra gato, né, o gato subiu no telhado, o
23:19	gato subiu no sofá, ele vai conseguir correlacionar as palavras que se pareçam, né, que se aproximem do gato.
23:27	Gato, cachorro, animal, e ele cria essas conexões entre as palavras para
23:34	identificar os padrões entre elas. Então, uma vez que você consegue fazer isso, você vai transformar aqueles
23:39	textos em uma espécie de tabela do Excel, né? Eh, lógico que não é literalmente uma tabela do Excel, é só
23:45	uma metáfora para dizer que o que ela vai fazer é criar uma espécie de base,
23:51	de fórmula para calcular, né, o quanto essas palavras se aproximam uma das
23:57	outras. No final, nós vamos ter uma espécie de ábaco ou de calculadora que
24:02	calcula palavras, que calcula textos. né? Se a gente pegar uma calculadora,
24:08	você dentro dela não vai ter artigo ensinando como calcular, vai ter
24:13	fórmulas matemáticas. Do mesmo modo, se a gente conseguisse enxergar dentro de um LLM, a gente não
24:19	ia encontrar arquivo do Word, arquivo de PDF ou livro ou a gente ia encontrar a
24:25	essência numérica daqueles textos, dos padrões de textos que ela viu no processo de aprendizagem. a gente falou
24:32	de terabytes de textos, né, que são usados no treinamento. Isso daí é transformado em alguns gigas
24:42	de números que captam a essência e de todo o texto que ele viu, de todo o
24:47	padrão numérico que ele viu, né? Eu eu eu sei que por enquanto aqui ainda tá abstrato, mas a gente vai ver muitos
24:53	exemplos práticos para entender isso na prática. Eh, o que eu quero que vocês percebam, e isso é muito básico, é que
25:00	vocês estão diante de uma máquina de calcular textos. Dentro dessa máquina não tem texto. Dentro dessa máquina tem
25:06	números, tem fórmulas matemáticas. E o interessante, uma vez que você tem, né,
25:12	uma uma compreensão dos padrões de linguagem através desses parâmetros que foram comprimidos, né, por essa máquina
25:20	de identificar padrões, você não vai conseguir voltar para o texto original.
25:25	Tudo que você vai fazer é transformar eh linguagem baseado nos padrões que
25:32	foram a a base dessa aprendizagem, dessa fórmula matemática que está aqui atrás.
25:38	Então esse é um ponto muito importante. Por isso, né, que a gente não pode
25:44	cometer o erro de achar que as máquinas reproduzem o passados, ela não reproduz.
25:49	Eh, tem uma uma expressão, né, que diz o seguinte: eh, os LLMs eles são máquinas,
25:55	o treinamento da máquina é uma compressão de textos. Acho que vocês já viram, né, a ideia do do que é uma
26:01	compressão de arquivo, um zipar o arquivo. O que que é zipar o arquivo? Você pega um arquivo grande, transforma
26:07	ele num arquivo menor, no arquivo pequeno. Então você pega um arquivo de, né, 10 meg e transforma no arquivo de 1
26:14	M. É exatamente isso que os LLMs fazem. Eles pegam 10 m de texto, claro que é
26:21	muito mais do que isso, e transformam em 1 m de números, de parâmetros, né, de padrões. Só que no arquivo zipado
26:28	tradicional a gente consegue dizar e voltar ao tamanho original. nos LLMs a
26:33	gente não consegue eh voltar ao arquivo original porque esses parâmetros são apenas fórmulas para gerar novos textos
26:41	que se parecem com os padrões do passado, mas não são exatamente iguais aos padrões do passado. Então vamos lá,
26:48	vamos passar para o segundo pecado para que a gente entenda exatamente o que são
26:54	os LLMs. Esse é um que pouca gente entende, que é o princípio da surpresa,
27:00	né? Nós temos que usar essas ferramentas tendo consciência de que elas são
27:06	capazes de surpreender, porque o modo de processamento dela não é fotográfico, é
27:11	um modo que é estocástico. Vou, eu sei, eh, vou pedir muito perdão por est
27:17	usando essas palavras mais técnicas, mas é muito simples entender se você pensar no aleatório, né? Você pense numa
27:25	máquina de calcular. uma máquina de calcular um, né, um padrão, uma cálcula normal, ela é um determinística, né?
27:33	Você tem 2 + 2, o resultado vai ser sempre 4. Se você coloca 2 + 2 + 2, vai
27:40	sair 6, né? Sempre, sempre vai sair exatamente igual. Mesmo input numérico,
27:47	né? Com algumas adições, subtrações, algumas fórmulas matemáticas vão gerar é o resultado, né?
27:55	E lembre-se que a máquina não está eh reproduzindo algo que ela viu, né, no
28:01	uma máquina de calcular, ela está calculando, né, aquela aqueles números
28:06	relacionados com símbolos de adição, subtração, etc. E aí ela vai gerar sempre o mesmo resultado. Por isso que a
28:12	gente diz que uma máquina de calcular ela é determinística. A máquina a partir
28:18	do input que o usuário dá, né, os números que o usuário coloca, vai gerar sempre o mesmo output, o mesmo
28:23	resultado. Os LLMs eles são diferentes. Os LLMs você fornece um input e ele
28:31	sempre vai dar um output diferente, mesmo que você coloque chat EPT, quanto
28:36	é 4 + 4. Vamos ver isso daqui na prática. Vamos eh testar um pouco disso para que a gente perceba o que é esse
28:43	modo eh aleatório dos LLMs. Vamos voltar aqui pro nosso chat EPT. Eu vou abrir um
28:51	novo chat, né? Esse botãozinho inaugura nova conversa. É como se eu tivesse conversando com outra pessoa. Depois a
28:57	gente vai falar um pouco sobre isso. E que se eu coloco aqui quanto é 2
29:03	x 2 2. Opa, não tô achando o botão. Mais
29:11	mais dois. Colocar aqui. E se eu coloco isso daqui pra máquina, eu vou separar
29:16	isso daqui depois, mas vamos ver qual vai ser o resultado que ela vai colocar, né? Então aqui ela vai dizer 2 + 2 = 4.
29:24	Eu vou abrir uma nova janela e vou perguntar a mesma coisa. Quanto é 2 + 2,
29:30	né? 2 + 2 = 4. Curiosamente ela deu exatamente a mesma resposta, mas algumas vezes, se eu coloco aqui,
29:37	opa, o número dois, pode ser que ela altere, né, a forma como 2 + 2 ig. Às vezes ela
29:45	escreve, às vezes ela eh veja que aquela colocou 2 + 2 ig 4, aquela colocou 2 + 2
29:50	ig 4, ela vai mudando. Isso é o que a gente chama de modo aleatório, o modo estocástico de da máquina responder, né?
29:58	Eh, e isso é uma característica que é muito importante, eh, porque eh nós temos que estar
30:06	preparados para surpresas. A gente nunca vai usar ela de modo determinístico, né?
30:11	O LM é uma calculadora não determinística. As suas saídas são sempre um pouco aleatórias, vão ter
30:18	coerência semântica, vão ter eh vão ter sentido, né, no num contexto de uma
30:24	linguagem natural, mas você tem que estar preparado paraa surpresa. Mesmo os
30:29	modelos mais robustos e hoje a gente tá trabalhando com modelos que t nível de PhD, né? Eh, aqui vai um parêntesezinho
30:36	bem rápido, né? Eh, a 2023, quando a gente começou a usar os
30:42	LLMs, o chat EPT, principalmente, a gente dizia que eles eram nível de estagiário, né? Eram ferramentas que
30:49	conseguiam produzir textos razoáveis, não tão profundos, mas com alguma qualidade. Eh, mas erravam muito,
30:56	mentiam muito, não eram tão bons, né? Tinha que ter sempre uma revisão humana, como até hoje muito pesada. Até que em
31:03	2024 a gente diz que eles se formaram, né? eles eh conseguiram o nível de bacharel, né? Um bom jurista, conseguiu
31:11	consegue analisar processos, consegue eh preparar uma audiência com qualidade,
31:16	né, consegue sugerir eh eh minutas eh emas, né, com extrema qualidade,
31:23	analisar processos mais longos, eh até que em 2025 ele alcançou o nível de PhD.
31:29	Então hoje a gente tá trabalhando com ferramentas que têm nível de PhD, mas mesmo essas ferramentas nível PhD, elas
31:36	são excepcionais, conseguem produzir textos incríveis, mas às vezes surpreendem. Às vezes surpreendem de
31:42	modo positivo, às vezes surpreende de modo negativo. Eu cansei de pegar textos produzidos pelos melhores modelos que no
31:50	meio tem uma expressão em inglês ou no meio tem uma expressão que não faz menor sentido ou até erro de português mesmo.
31:56	Até erro de português, porque a gente tem que estar preparado para esse tipo de surpresa, né? Eh, esses essas
32:03	máquinas elas eh também tem um um erro muito comum que eu vejo muita gente cometendo, é um pecado, né, de achar que
32:11	essas máquinas elas vão ajudar nas tarefas mecânicas, nas tarefas repetitivas, aquelas tarefas mais
32:18	simples, né, eh, quando na verdade a sua maior qualidade é nos ajudar a
32:25	solucionar problemas complexos. Eh, os LLMs eles têm uma vantagem incrível, né?
32:31	você consegue pegar um processo de 300 páginas, colocar dentro de um LLM robusto e ele vai conseguir fazer uma
32:38	análise excepcional do caso. Com isso, a gente consegue ganhar muito mais tempo
32:44	para direcionar a nossa atenção para um pensamento estratégico, para um pensamento de tentar ir além daquilo que
32:51	a gente conseguiria sem a máquina. é a ideia de que nós com a máquina
32:57	conseguimos muito mais do que aquilo que a gente não conseguia sozinho, né? O ser
33:02	humano aliado à máquina consegue produzir muito mais. E a ideia base aqui
33:08	é que quando a gente fala de LLM, a gente não tá falando de usar uma ferramenta para tarefas burocráticas,
33:15	para tarefas repetitivas, para sentenças padrões, para petições padrões. A gente tá usando ela para expandir a nossa
33:23	mente, para conseguir análises mais profundas. Não é só uma questão de fazer
33:28	mais em menos tempo, fazer mais em menos tempo com mais qualidade. É isso que a
33:34	gente quer utilizando inteligência artificial generativa. Então, quando a gente fala, né, que os LLMs são
33:42	ferramentas estocásticas que surpreendem positiva e negativamente e o usuário tem
33:47	o poder de direcionar essa surpresa para o melhor, eh, a gente quer dizer que a gente vai usar ela muito mais para
33:54	tarefas complexas, tarefas singulares, tarefas únicas, do que para aquelas
34:00	tarefas meramente braçais, né? É como se a gente tivesse um Einstein trabalhando
34:06	como assistente nosso, né, do nosso lado. E a gente não vai querer desse AT que apenas fique tirando Sherox, né?
34:13	Corrija esse texto. Esse tipo de comando é o comando fraco, é o comando que a gente não está explorando o melhor
34:20	potencial da máquina. O melhor potencial da máquina é conseguir nos ajudar nas tarefas complexas, nas tarefas mais eh
34:29	avançadas. Eh, portanto, eh, um erro comum é que,
34:34	apesar de os LLMs, inteligência artificial generativa, poder ajudar em tarefas de automação mecânicas
34:42	repetitivas, ela vai ser muito melhor como ferramenta de interação, de
34:47	diálogo, né, de eh de conversa profunda para ampliar seus horizontes cognitivos
34:53	para para fazer você conseguir produzir resultados muito melhores. Eu tenho uma
34:59	uma richa, né? Não vou dizer que é uma richa porque não é um problema único da TI, mas o pessoal da TI o que eles
35:06	querem são botões. Eles querem transformar os seres humanos em uma máquina que aperta botões. O ser humano
35:12	vai se transformar em um ser que vai apertar. Resuma, escreva, analise. E é
35:18	isso que eu não quero. É exatamente isso que eu não quero. Eu não quero ser um botão da máquina. Eu quero ser o
35:25	controlador da máquina. Eu não quero ser guiado pela máquina, eu quero guiar a máquina. Eu não quero ser dominado pela
35:32	máquina, eu quero dominar a máquina. E eu quero que você também assuma esse controle sobre a máquina. Eu não quero
35:38	que você se torne uma mera engrenagem a serviço da máquina. Eu quero que você use a máquina para conseguir aumentar a
35:45	sua capacidade produtiva, aumentar a sua qualidade de pensamento, pensar melhor,
35:51	pensar com mais profundidade. Essa é a ideia. não vamos eh nos tornar, né,
35:56	meros botões da máquina. Eh, para entender um pouco a lógica do do
36:02	estocástico, do aleatório, eh, eu vou passar aqui para uma uma dica, eh, uma
36:10	aula, né, uma uma dica prática, né, um uma lição do curso de escrita jurídica
36:15	com inteligência artificial, que é para dizer como é que essas máquinas processam informações, né, a gente parte
36:22	de uma espécie de jogo, né, um jogo da adivinhação, que é um jogo muito simples, né? Imagine que você esteja
36:28	numa mesa com seus amigos e cada um é responsável por continuar, né, uma
36:33	frase. É, a frase é: "Era uma vez um rei que morava em um".
36:39	Você tem que continuar e escolher uma palavra que se encaixe nessa sequência iniciada pelo jogo, né? O jogo começa
36:46	com essa frase: "Era uma vez um rei que morava em um". Você claramente na hora
36:52	que vai tentar continuar essa frase, você vai excluir palavras que não fazem
36:57	o menor sentido, né? Você vai excluir, por exemplo, a palavra rainha. Era uma
37:03	vez, era uma vez um rei que morava em um rainha. Ele quebra semanticamente a lógica, né? São algumas palavras que se
37:11	encaixam nessa sequência. Nesse caso, muito provavelmente um substantivo masculino, né? E quais são substantivos
37:18	masculinos que se encaixam nessa frase? Tem vários deles. Por exemplo, a gente pode elencar era uma vez um rei que
37:24	morava em um castelo. Faz sentido, tem sentido semântico, tem coerência. Era uma vez um e um rei que morava em um
37:32	reino, era uma uma vez um rei que morava em um casebre, né? Não não tem. A a
37:38	probabilidade de ser um casebre é menor, mas existe essa probabilidade, não é desprezível, faz sentido semântico. Do
37:45	mesmo modo, um barco. É raro que um rei more em um barco, mas pode ser que ele
37:50	more em um barco. Então ele vai ter uma chance ali de aquela palavra se encaixar
37:55	no jogo. Então qualquer palavra que a máquina escolha ou que você escolha, vai
38:00	continuar corretamente essa máquina, essa essa sequência. Eh, e a grande
38:06	questão é que a máquina, né, quando ela vai escolher, ela muitas vezes vai na
38:12	mais provável, mas não necessariamente na mais óbvia. Ela tende a ir para uma
38:19	zona de eh de mediana, né, aquela
38:24	palavra mais repetida, mais comum, mais normal, mas algumas vezes ela foge do padrão da mediana, né? uma, ela tem uma
38:32	tendência do retorno à mediana e por isso que muitas vezes os textos saem todos iguais e a gente tem que trabalhar
38:39	com isso usando técnicas para controlar a camada de estilo, algo que a gente vê no curso, não vou falar, né, aqui sobre
38:45	isso, né, se é uma parte mais avançada, mas o importante é perceber que quando a gente trabalha com LLMs, a gente tá
38:52	trabalhando com uma máquina que vai buscar uma coerência semântica a partir
38:58	de de palavras que provavelmente ente se encaixam naquela naquela sequência e que
39:06	a partir dali eh ele vai seguindo, continuando criando uma palavra de cada vez até completar a frase completa. Isso
39:13	é muito importante, né? Isso é muito importante. É isso que vai explicar algo
39:19	que a gente vai mostrar lá na frente, as chamadas alucinações. Eh, por enquanto eu quero que vocês
39:25	vejam isso na prática. Vamos mais uma vez ativar aqui o nosso chat GPT, né?
39:31	Vou abrir uma nova janela. Eh, e eu vou pedir pro chatt dizer o seguinte, né?
39:37	Responda rapidamente o nome de uma fruta e o nome de uma
39:44	ferramenta. Esse é um jogo psicológico que a gente costuma fazer com seres humanos. E em
39:50	geral 70% dos seres humanos vão responder maçã ou martelo. Se eu pedir
39:55	aqui pro chattou ou e, né, uma ferramenta, há uma grande
40:02	chance de ele responder maçã e martelo. Algumas vezes ele vai dizer banana e martelo, algumas vezes ele vai dizer e
40:10	maçã em alicate, mas a chance é que ele diga algo próximo a maçã ou martelo ou
40:15	alguma variante disso. É, e aqui nesse caso, maçã e martelo, então ele foi
40:21	bastante em cima. Aqui nesse caso pode dizer: "Ah, isso é determinístico." Não é determinístico, porque algumas vezes
40:26	ele não vai responder maçã e martelo. Algumas vezes ele vai responder. Vamos testar isso daqui, abrir uma nova
40:32	janela. Pode ser que ele vá pra banana em martelo, né? Eh, aqui eu não tenho
40:38	certeza. maçã, martelo, continua indo na mesma lógica, mas se a gente alterar aqui, provavelmente a gente em algum
40:44	momento vai conseguir mudar essa essa diretriz. Isso aqui é muito importante que a gente tem em mente, porque o que
40:51	tá acontecendo com o uso acrítico e amador do chat GPT, o uso acrítio e
40:57	amador do chat GPT, ele tá gerando uma homogeneização de estilos. Todos os
41:03	textos são iguais, tá? Todo mundo escrevendo a mesma coisa. todas as expressões que se repetem. E isso é
41:10	péssimo. Isso é péssimo se a gente quiser autenticidade, se a gente quiser
41:16	eh que o nosso texto tenha a nossa voz, tenha o nosso senso individualizado,
41:22	nosso, a nossa o que nos torna único e singular. Eh, e por isso que aqueles que
41:28	usam o chatpt de modo avançado sabem disso e tentam fazer com que o estilo
41:34	não fique na mediana, não seja simplesmente uma resposta de máquina, aquela resposta padrão, né, que todo
41:40	mundo vai fazer igual. Mas enfim, eu quero que vocês percebam aqui que a máquina ela vai gerar essa surpresa
41:48	porque eh o modo de processamento dela não é fotográfico, é aleatório e ela tende a
41:56	ir para uma mediana, para aquilo que é mais comum e mais repetitivo, mas nem sempre é o óbvio, nem sempre é o mais
42:01	provável. Às vezes isso a gente pode inclusive eh alterar pedindo mais
42:07	criatividade, pedindo que ele fuja do padrão da previsibilidade, ele vai ativar uma temperatura maior, que é um
42:13	conceito técnico para gerar mais aleatoriedade e aí vai gerar textos diferentes daqueles que a gente tá
42:20	acostumado. Vamos pro próximo pecado, que é o pecado do contexto. Para ser mais preciso, o pecado de não
42:27	compreender os limites da janela de contexto. pecado de não compreender o
42:33	que é a janela de contexto e o quão importante é para que você consiga ter respostas melhores e de mais qualidade.
42:40	E o que é a janela de contexto? A janela de contexto é a capacidade da máquina de
42:45	prestar atenção na quantidade de textos que você colocou e continuar a partir daí. Pense, por exemplo, numa máquina de
42:52	calcular comum, né? Calcular números. Você pega lá, coloca 2 + 2 + 2 + 2, ela
42:58	vai conseguir calcular 8. Vai chegar um momento em que se você colocar muito input, ou seja, colocar
43:05	muitos números para que ela faça o cálculo, ela não vai conseguir processar. Seja porque já coloca um
43:11	limite ali dentro da quantidade, né, de números que você pode colocar na telinha
43:17	principal, seja porque ela não vai ter capacidade de cálculo, porque é uma calculadora simples, ela não é uma
43:23	calculadora quântica. E aí, portanto, ela tem uma limitação da capacidade de cálculo. Quando a gente fala de
43:29	limitação da janela de contexto, a gente tá falando de limitação da capacidade de cálculo da máquina. Vamos fazer aqui uma
43:36	pequena metáfora que é muito ilustrativa sobre o que é a janela de contexto. Pense na janela de contexto como uma
43:43	caminhada, né? Você está explorando, né, uma nova trilha e você vai caminhando por essa trilha.
43:49	Quando você caminha por essa trilha, você vai deixando pegadas no chão. É, quanto mais você caminha, mais você
43:55	consegue enxergar coisas a sua frente, né? E claro, você vai lembrar do caminho
44:01	que você percorreu, mas vai chegar um momento quando você tiver caminhado bastante, que você vai conseguir
44:06	enxergar mais coisas lá na frente, mas vai olhar para trás e as pegadas que estão mais distantes vão ter se apagado,
44:14	né? A trilha que você deixa é a trilha que você vai e que é a trilha da janela
44:20	de contexto que você vai construindo. Isso é a janela de contexto. No caso dos
44:25	LLMs, lá no passado, quando a gente trabalhava eh com o chat EPT 3.5,
44:31	chattalhava com eh janelas de contexto, né, com a
44:36	capacidade de de processamento da máquina ridículos. Eram eh ter eh no
44:42	máximo algumas páginas, né? Eu lembro que a gente utilizava lá paraa correção de textos e só cabia lá três, quatro
44:49	páginas no máximo. Hoje, quando a gente trabalha com os LLMs mais robustos, a
44:54	gente tá falando de centenas ou até milhares de páginas que cabem dentro da
45:00	janela de contexto. Por que que é relevante a gente entender o que é que é
45:05	a janela de contexto? Eh, deixa eu colocar aqui eh no nosso slide mais uma
45:10	vez para que a gente consiga entender melhor, né? Eh, então, basicamente, em termos conceituais, a janela de contexto
45:18	é a quantidade de texto que a máquina consegue prestar atenção ao mesmo tempo.
45:23	Os LLMs, eles são máquinas que prestam atenção, ou seja, eles leem, eles analisam, né, uma quantidade de textos e
45:31	continua aquela sequência eh a partir daquilo que ela conseguiu prestar atenção. A capacidade dela de prestar
45:38	atenção, assim como a humana, não é infinita. É, nossa memória de curto prazo é curta, a gente esquece as coisas
45:45	rápidos, né? Pense em você lendo um livro, você começa a ler o livro, né? passa do primeiro capítulo, consegue
45:52	responder perguntas sobre o primeiro capítulo, vai lá pro segundo, pro terceiro. Quando você tá no quarto capítulo, talvez você lembre muita coisa
45:59	do terceiro, mas começa a esquecer coisas do segundo e também do primeiro. Vai ficando para trás, vai gerando
46:05	esquecimento. Ou seja, a nossa capacidade de conseguir memorizar e prestar atenção, ela é limitada por uma
46:11	janela de contexto também da nossa mente. E a máquina tem a mesma característica, ela não tem o poder de
46:18	prestar atenção em tudo. É, portanto, ela só enxerga, ela só consegue ler, analisar uma quantidade limitada de
46:25	texto, esquecendo aquilo que vai ficando para trás. E um ponto muito importante,
46:30	cada vez que a gente inicia uma nova conversa, inaugura um novo contexto, eh,
46:37	ela esquece aquilo que a gente conversou. Vamos mostrar isso aqui um pouquinho na prática, porque isso aqui é
46:43	relevante e é algo que também eh as pessoas não entendem muito bem e eh é
46:48	preciso que a gente perceba que existem hoje recursos para que a máquina lembre
46:54	o passado, mas isso é ruim. Eu vou tentar mostrar porque que nós do direito não devemos usar ferramentas de
47:00	memorização de início, né? Eh, se eu perguntar o o meu eh o meu chatt, ele
47:06	está configurado aqui para não ter memorização. A memória está desligada. Depois eu vou explicar o que é isso.
47:12	Você vai aprender meio direitinho o que é isso e eu recomendo que você faça o mesmo, né? Eu vou explicar por que você
47:17	deve desativar essa memória. Se eu perguntar aqui, ó, chat GPT.
47:25	chat GPT. Meu nome
47:31	é George e eu me formei, opa, eu me formei, eu fiz
47:38	doutorado na Universidade de Coimbra. Então, se eu peço aqui, eh,
47:47	ele vai fazer um comentário. Claro, se eu perguntar aqui onde fiz meu doutorado,
47:55	ele vai saber, né? Ele vai saber, vai dizer: "Você fez o doutorado na Universidade de Coimbra". Então ele
48:01	respondeu: "Por quê?" Porque cada conversa inaugura um contexto. Então, na medida em que eu vou conversando com ele
48:07	aqui, ele vai lembrando de tudo que está nessa mesma conversação. É como se fosse, né, uma pessoa conversando comigo
48:14	e ela vai lembrar, né, de tudo que está que eu que eu conversar com ela aqui, limitado a uma capacidade de
48:21	processamento de mais ou menos 150, 200 páginas, porque a partir daí ela vai
48:27	começar a esquecer aquelas informações que estão no início da conversa, como se fosse a pegada se apagando ao longo da
48:34	nossa conversação. Mas se eu fizer aqui 20 perguntas e depois perguntar qual é o meu doutorado, ela vai saber. Eh, se eu
48:41	levar aqui para uma nova janela, um novo chat, é uma nova pessoa, é, é, é uma
48:47	nova conversa, é como se fosse uma nova caminhada. Ela não vai lembrar do que a gente conversou na na nas conversas
48:53	passadas. Então, se eu pergunto aqui, eh, chat GPT,
48:59	onde fiz meu doutorado? Vou pedir para ele não pesquisar na
49:04	internet, depois a gente vai explicar um pouquinho isso. Não pesquise na internet.
49:12	Eh, não tenho acesso ao seu histórico pessoal, não sei onde fez doutorado, né? Como assim? Eu acabei de dizer, né? Por
49:17	que ele não lembra? Porque eu desativei a ferramenta de memória. Se eu quiser,
49:23	eu posso vir aqui, ativar a ferramenta de memória, né? Personalização, memória.
49:29	Ativo aqui a memória. A partir de agora, eh, se eu perguntar,
49:36	se eu dizer para ele, opa,
49:43	fiz meu doutorado em Coimbra. Guarde isso.
49:50	Ele vai guardar na memória, né? vai guardar isso aqui na memória. E quando eu converso aqui de com ele com a nova
49:56	pergunta, onde onde fiz meu doutorado?
50:04	Não coloquei pergunta, mas ele colocou Coimbra. Por quê? Porque está aqui na memória. Se a gente vier aqui na
50:10	personalização e verificar, gerenciar memória, ele vai ter guardada essa
50:15	informação. Eu vou tirar isso daqui. Por quê? Porque no direito nós não vamos
50:21	querer esse recurso. No direito nós não vamos querer trabalhar com memória. A memória atrapalha as nossas análises.
50:29	Por quê? Porque quando a gente tá conversando com o chat EPT, cada caso é um caso novo. Cada caso tem uma parte
50:35	diferente. Os fatos são diferentes, o direito é diferente, o pedido é diferente. A gente não quer contaminação
50:40	de memória, de conversação. Então imagine que eu esteja conversando aqui, né? E eu diga: "O nome da parte é João".
50:48	Aí eu abro uma nova conversa sobre um outro processo e eu pergunte e qual é o
50:53	nome da parte? Ele vai dizer João. Mas é do processo passado, processo novo. Eu quero que ele saiba que não é o João.
51:00	Então é importante que quando nós estivermos trabalhando no direito, nós não vamos ativar essa ferramenta de
51:08	memória. Podem desativar. É um erro primário que as pessoas tomam eh cometem. E é por isso que muitas vezes a
51:15	pessoa tá analisando o processo e e há uma alucinação, há uma informação errada
51:21	sobre isso, né? Então a gente tem que ter em mente que quando a gente trabalha com os LLMs, cada janela é uma nova
51:28	janela de contexto, né? Uma nova conversação e que a gente não precisa
51:33	usar, né, o os LLMs para eh memorizar. Eh, finalmente, né, quanto maior eh o
51:40	contexto, maior a latência demora, menor a precisão, né? Análise de textos muito longos reduzem a qualidade eh do nosso
51:49	da nossa análise. O que que é isso? Vamos lá. Eh, a ideia base aqui que eu quero trazer para vocês é que quando a
51:56	gente tá trabalhando com o direito, a gente tá trabalhando com textos muito longos. Às vezes quando junta petição,
52:02	contestação, réplica, documentos probatórios, sentença, recurso, a gente
52:07	tá trabalhando com algo que chega próximo a 200 páginas, 300 páginas, até
52:13	mais páginas. Isso eh vai ter uma exigir da máquina um poder computacional
52:19	enorme, porque ela vai ter que analisar todo o conjunto probatório, né, todo o
52:24	processo, todos os documentos, todo o texto e conseguir, por exemplo, extrair quais são os pontos controvertidos ou
52:31	mapear quais são os fatos relevantes ou fazer um mapeamento argumentativo e probatório. Quanto maior é o contexto,
52:38	menor vai ser a capacidade da máquina de conseguir dar respostas com qualidade e precisão. Muitas vezes a gente vai
52:44	precisar é fracionar ou segmentar a tarefa em partes menores. Por exemplo,
52:50	vou dar um exemplo aqui bem prático, vocês vão perceber. A máquina ela tem uma capacidade de
52:56	saída que é delimitada, por exemplo, por quantidade de páginas. Imagine que você esteja trabalhando com a máquina e ela
53:03	só toda a resposta dela é no máximo quatro páginas. Então, se você pega um processo de 300 páginas e pede para ela
53:10	resumir, fazer uma análise FIRAC, por exemplo, que é uma análise mais avançada, ela provavelmente vai dar uma
53:17	resposta de quatro páginas. E isso, claro, vai exigir da máquina um poder de concisão para transformar aquelas 200
53:24	páginas num texto de quatro páginas. Se você quiser mais precisão, mais
53:31	detalhes, uma forma eficiente de fazer isso é, ao invés de trabalhar com as 200 páginas, você trabalhar peça por peça do
53:38	processo. E aí você pede para ela fazer um relatório da inicial e ela vai fazer aquela inicial em quatro páginas, aquele
53:44	relatório. E aí, portanto, você vai conseguir muito mais detalhes do que simplesmente pedir pra máquina eh fazer
53:50	tudo isso. Hoje a gente tá trabalhando com contextos muito longos e esse contexto longo nos habilita a ter uma
53:58	série de vantagens. Por exemplo, o fato de a gente trabalhar com contextos muito longos nos permite que a gente ensine
54:05	pra máquina a realizar tarefas específicas que elas que ela não aprendeu no aprendizado, né, que ela não
54:12	aprendeu durante o seu treinamento. A gente pode conseguir, por exemplo, criar promptes, instruções, né, e que naquelas
54:19	instruções ensina pra máquina como fazer um relatório, como fazer uma ementa, né, ou até colocar precedentes para que ela
54:26	se baseie. Tudo isso a gente chama de aprendizagem através do contexto. A
54:31	máquina pode aprender, né, com instruções ou dados fornecidos pelo usuário, né? A grande a a a grande
54:39	mudança de uso, né? Quem quem sai do uso amador para o uso profissional é aquele
54:44	usuário que tem consciência disso, que tem consciência de que não vai usar a
54:49	máquina como extensão da sua mente. A gente não vai simplesmente pedir pra máquina fazer algo. A gente vai ensinar
54:56	pra máquina como fazer isso. E não só isso, a gente vai ensinar pra máquina a fazer algo e a gente vai dar o caminho
55:03	das pedras, a gente vai dar o conhecimento que a máquina vai se basear para dar resposta. Isso se chama
55:09	aprendizado em contextos, eh, em contexto, né, em contest. Eh, a gente
55:14	consegue também, graças a esse contexto enorme que as máquinas conseguiram eh desenvolver, evoluir de 2023 até hoje, a
55:23	gente consegue eh analisar textos muito mais longos e manter uma coerência de
55:28	conversas mais extensas, né? Conversar por vários e vários períodos. A gente
55:34	hoje consegue estabelecer um diálogo de uma conversa de 200 páginas em que a máquina consegue fazer sentido. Claro, a
55:41	gente tá falando de alguns modelos que são mais robustos e isso tá só crescendo, cada vez aumenta mais. Então,
55:46	eh, se hoje a gente consegue trabalhar com 300, 400 páginas com qualidade,
55:51	tenho certeza de que daqui a alguns meses, alguns anos, eh, a gente vai trabalhar com 1000, 10.000, 20.000 1000
55:57	páginas com extrema qualidade, né? E finalmente, né, uma vez que a gente tem um poder computacional da máquina muito
56:04	maior, por conta da ampliação da janela de contexto, nós conseguimos fazer tarefas mais complexas. a gente consegue
56:12	exigir da máquina muito mais do que a gente exigia antes. Se a gente trabalhava com tarefas, por exemplo, de
56:18	revisão de textos ou melhoramento de textos, né, basicamente tarefas de escrita e de linguagem, hoje a gente
56:25	consegue trabalhar com muito mais tarefas. A gente tem tarefas de análise que a gente consegue fazer com extrema
56:30	qualidade, tarefas de pesquisa usando ferramentas específicas de pesquisas,
56:35	especialmente deep research, que é um mecanismo de conseguir respostas muito mais profundas e tarefas de criação, né,
56:43	que antes eram bastante limitadas por conta dessa limitação da janela de
56:48	contexto. Então, a gente trabalha hoje, né, com máquinas muito mais poderosas,
56:53	graças a essa ampliação da janela de contexto e desse poder que a gente tem através de prompt, através da arte de
57:01	conversar com a máquina, de conseguir ensinar paraa máquina a realizar tarefas
57:07	complexas. Aqui mais uma vez a diferença do usuário amador para o usuário profissional. usuário amador não sabe
57:14	conversar com a máquina, não sabe ensinar pra máquina para fazer algo que us que eh seja, por exemplo, complexo,
57:21	que exija um encadeamento de pensamento, que exija um prompé-estruturado para que ele faça um determinado tipo de eh
57:30	formato de saída. usuário profissional, aquele que domina a máquina, aquele que usa a máquina como extensão da sua
57:37	mente, ele ensina a máquina como fazer, diz exatamente qual é o resultado que ele quer e a máquina faz isso com
57:42	extrema qualidade, obedecendo eh fazendo aquilo que o usuário manda de modo obediente. Eh, falar nisso, né, a gente
57:50	vai passar para o próximo que é confiança, né? O pecado, talvez o pecado
57:55	mais grave, né, do usuário que não entende o que a máquina tá fazendo é a
58:01	confiança cega, chamado viés de automação, que é aquela crença, falsa
58:06	crença de achar que a máquina é infalível, de achar que a máquina produz respostas baseadas em cálculos corretos,
58:15	cálculos precisos. Os LLMs, eles são ferramentas extremamente habilidosas em
58:21	linguagem natural. Eles têm uma capacidade funcional de linguagem em
58:27	termos de compreensão linguística superior a de qualquer ser humano. Só que ao mesmo tempo eles são tapados para
58:34	tarefas que não são, né, que não envolvem eh linguagem, né, que não envolve, por exemplo, compreensão
58:41	linguística. Imagine uma tarefa de cálculo, de xadrez, né, de raciocínio
58:47	moral, de raciocínio profundo. Eles não vão saber. a máquina não vai saber com sistema qualidade. Eh, teve uma notícia
58:54	recente que mostrou que o chat EPT atual, ou seja, super robusto, ele
59:00	perdeu no jogo de xadrez para um atari de 1986, né? Um atari muito simples, muito básico
59:07	em termos de algoritmo, né? Em termos de inteligência, né? Foi superior, né, ao
59:12	chat GPT. E o mais incrível é que o chat EPT conseguiu jogar xadrez, né? Isso é
59:19	que é incrível, porque ele não foi treinado para para aquilo, ou seja, ele aprendeu a jogar xadrez apenas lendo
59:26	sobre xadrez, né? O que é incrível isso. Então, a gente tem que ter em mente que os LLM são ferramentas de linguagem. Nós
59:33	não podemos confiar cegamente na máquina. Ela é falível, ela é enganadora, ela não tem consciência de
59:40	suas limitações. Não adianta pedir pra máquina não alucine. A gente vai falar sobre alucinação daqui a pouco. Não
59:46	adianta pedir pra máquina cite apenas precedentes que existem. Ela não vai fazer isso. Ela não tem consciência das
59:52	suas limitações. Ela não sabe o que ela não sabe, né? Esse é um princípio básico dos LLMs. As alucinações, que é eu tenho
1:00:00	falado algumas vezes, né? que são essas fabricações de informações que parecem plausíveis, mas são inverídicas, elas
1:00:07	são inerentes aos LLMs. Elas são inerentes à aquela forma de calcular de modo estocástico que a gente comentou.
1:00:14	Isso não é ruim, isso é bom. É isso que permite que a máquina consiga produzir
1:00:19	respostas incríveis. É isso que permite que a máquina pegue um processo novo que ela nunca viu na vida e consiga propor,
1:00:27	né, ideias sobre aquele caso de modo inovador. Ela consegue captar o singular, o único, o diferente. Se ela
1:00:34	fosse meramente uma máquina de processar padrões, de repetir padrões, ela nunca seria útil para os casos novos. E ela é
1:00:41	útil justamente por isso, porque ela imagina, ela tem pensamento contrafactual, ela consegue ir além
1:00:47	daquilo que é dado, ela consegue criar algo novo, algo inédito. Mas, mas por
1:00:53	isso mesmo você deve partir da seguinte premissa: toda informação factual
1:00:59	extraída dos LLMs são falsas até prova em contrário. aqui. Eh, eu vou repetir
1:01:07	isso, né, porque eu sei que é contrainttuitivo e parece que isso é é
1:01:13	ruim, né? Parece que isso diminui os LLMs, não diminui, né? porque a gente vai ver daqui a pouco como é que a gente
1:01:20	mitiga isso. Mas parta do pressuposto. E se você partir desse pressuposto, eh,
1:01:26	80% dos seus problemas em relação aos LLMs e medo dos LLMs estará superado.
1:01:32	Toda informação factual produzida pelo LLM com base no conhecimento da máquina
1:01:40	é falso. É falso. Até pro contrário. Não use os LLMs para obtenção de fatos.
1:01:47	Não use os LLMs para saber precedentes. Não use os LLMs no modo tradicional para
1:01:53	saber legislação. Eles vão saber talvez aquilo que é mais frequente, mais comum,
1:02:00	mais fácil, mas aquilo que é mais raro, né, que é mais inusitado, que é mais incomum, eles não vão conseguir fazer.
1:02:08	Eu vou explicar isso aqui com mais detalhes, porque isso daqui é a lição principal. E é e é onde eu quero que
1:02:14	você entenda que o usuário que conhece o básico dos LLMs jamais cometeria esse
1:02:21	erro. Muita gente diz: "Ah, você deve sempre fiscalizar aquilo que a máquina produz porque ela alucina." OK, isso é
1:02:28	verdade, mas o fato é que ela vai alucinar sempre. E se você tivesse que fiscalizar sempre, ia ser um uso inútil,
1:02:36	porque você ia tá eh fazendo duplo trabalho, você estaria escrevendo um
1:02:42	prompt, a máquina estaria produzindo, você estaria pegando o texto da máquina e estaria corrigindo. Isso é
1:02:47	contraproducente. A grande questão é que você vai ter que aprender a usar a máquina naquilo que ela consegue fazer e
1:02:53	pode fazer bem e aquilo que ela não pode fazer, que você não deve usar a máquina. Ou, né, você pode até usar a máquina
1:03:01	para fazer algumas tarefas de pesquisa, mas usando ferramentas específicas que as máquinas hoje eh acoplaram, né? Vamos
1:03:09	ser mais claros aqui. Eu quero eu vou, repito, eu vou ser bem didático em relação a isso, porque aqui talvez seja
1:03:15	o ponto mais básicos. Toda vez que você pede pra máquina uma
1:03:21	informação factual, e o que é que é uma informação factual? São fatos, claro, eventos, datas, nomes, números, eh, mas
1:03:29	também são precedentes, né? Se um precedente existe ou não, isso é factual. Se uma lei existe ou não, isso
1:03:36	é factual. Toda vez que você pede isso, a máquina vai alucinar por padrão,
1:03:43	sobretudo se aquela informação for muito rara na base de treinamento.
1:03:48	Ela vai saber o que é o capt do artigo 5º da Constituição Federal, mas ela não
1:03:53	vai saber o artigo 187, por exemplo. Eh, eu vou mostrar isso na prática porque aqui eh fica mais fácil a gente ver, né,
1:04:01	a máquina, porque daqui a pouco eu vou mostrar uma forma de mitigar isso, né?
1:04:06	Mas se eu peço aqui eh eh cite toda a formação acadêmica
1:04:16	de George Marmelstein.
1:04:21	Aqui eu vou fazer um comando que no passado não era necessário, mas agora é porque hoje ela tem um recurso que é o
1:04:28	recurso de busca na internet. É um recurso eh que foi criado posteriormente, não faz parte do LLM, é
1:04:35	um recurso externo é o LLM, mas eu não quero que ele ative esse recurso. Então vou pedir não ative o seu recurso, a sua
1:04:43	busca. Use apenas o conhecimento parametrizado,
1:04:53	que é o conhecimento da máquina, que a gente vai explicar o que é daqui a pouco. Então vamos ver o que é que a máquina vai fazer. Ele não ativou o
1:04:59	recurso de pesquisa e a gente, eu vou mostrar para vocês como é que a gente sabe disso. E eh isso aqui que ele fez,
1:05:07	ó, foi baseado numa mediana que faz sentido. Graduação ele acertou, eu fiz
1:05:13	minha graduação na UFC, o mestrado ele acertou, fiz meu mestrado na UFC, mas o
1:05:18	doutorado não é pela Universidade de Minas Gerais, é um doutorado pela Universidade de Coimbra, né? Nunca
1:05:25	estudei na Universidade de Minas Gerais, mas ele alucinou. Isso daqui é a alucinação. Eu parto do princípio de que
1:05:32	100% é alucinação. Nesse caso, eu sei a resposta, mas se eu tivesse pesquisando
1:05:38	sobre outra coisa, eu nem me daria o luxo de pesquisar, de ir atrás. Eu
1:05:43	partiria do princípio de que é falso. Eu não quero usar para isso. Isso eu uso errado, né? Você está usando a
1:05:49	ferramenta errada se você pedir esse tipo de informação. Se eu pedir precedente, tá errado. Eh, uma forma que
1:05:56	eu tenho de evitar isso é fazer o seguinte, é tirar essa parte
1:06:02	de busca na internet. Agora ele vai ativar uma ferramenta externa que não é baseada
1:06:09	no conhecimento da máquina e que espero eu que ele busque, né? Se ele não buscar, a gente já clica aqui no no
1:06:14	buscar na internet. Vou colocar logo, né? Buscar na internet. né? E a partir de agora você vê que ele está buscando
1:06:20	na web, ele ativou essa ferramenta externa e a partir de agora ele colocou
1:06:26	todo o meu currículo acadêmico, doutorado, né, em Universidade de Coimbra, né, fiz mestrado na UFC, fiz
1:06:33	especialização em MBA no Poder Judiciário pela Fundação Getúlio Vargas, fiz especialização em direito processual
1:06:39	público pela Universidade Federal Fluminense. Tudo isso é verdadeiro. E aqui, como é que a gente sabe outra informação, como é que a gente sabe que
1:06:45	ele buscou na internet? Que quando ele busca na internet, além de ativar aquela aba buscando na web antes de responder,
1:06:52	ele traz a atribuição de fonte, que é isso daqui no escavador, né? Buscou no valor econômico, né? Pegou uma notícia
1:06:58	do do valor econômico. Eh, então tudo isso que ele tá fazendo aqui, ele atribui a fonte. E aí, portanto, nesse
1:07:06	caso, a gente sabe que ele está pesquisando na internet, só que aqui não é um conhecimento original da máquina, é
1:07:13	um conhecimento que ele está eh pegando
1:07:18	de outra fonte, que é a internet. E aqui vem um ponto importante, talvez, mais uma vez sempre di que eles são mais
1:07:24	importantes, é porque tudo é tão importante que você não pode perder nada. você tem que entender toda a lógica para poder usar com confiança.
1:07:30	Aqui também vem outro parêntese antes de eu passar para essa lição, né, que é a lição de como eh de onde é que a máquina
1:07:37	tira conhecimento. Mas é o seguinte, muita gente acha que usar a máquina é fácil porque é só conversar, só que ela
1:07:44	é enganadora. Ela é enganadora. Você tem que entender os princípios de funcionamento para usar corretamente. E
1:07:50	um dos princípios básicos é responder a seguinte pergunta: Da onde é que ela tá tirando a resposta? qual é a fonte de
1:07:56	conhecimento da máquina. E aqui eu vou dar talvez o maior bizu, maior hack que
1:08:02	você vai ter, o maior segredo para entender usar corretamente a máquina, que é saber da onde é que ela tá tirando
1:08:08	a informação. Ela é igual a um ser humano, né? Pense num ser humano. Quando você pergunta
1:08:14	alguma coisa pro Einstein, por exemplo, Einstein, né? Me diga aí, explique a teoria da relatividade. O Einstein vai
1:08:21	começar a conversar com você. Quando ele começar a explicar a teoria da relatividade e você vê que ele não tá
1:08:26	consultando nenhum livro, você diz: "Ele tá tirando essa informação da cabeça dele. É confiável porque o Einstein
1:08:32	criou a teoria da relatividade. Então ele vai explicar a teoria dele com bastante qualidade. Agora, se eu peço,
1:08:38	Einstein, eh me explica aí os precedentes do Supremo Tribunal Federal
1:08:44	sobre vício redbitório e ele começa a tirar da cabeça dele e conversar, você começa a desconfiar. Esse aí tá l
1:08:51	enganando, porque ele tá tirando essa informação da onde? Da cabeça dele. Agora se você entrega um livro para ele,
1:08:57	a tá aqui um livro sobre vício redbitório, estude esse livro e me explique, né, qual é a posição do
1:09:03	Supremo sobre esse tema. Ele vai ler com base no conhecimento que o usuário forneceu e vai dar uma explicação, uma
1:09:10	resposta. É mais confiável. Ou você pode pedir para ele, faça uma pesquisa,
1:09:15	pesquise para mim na internet sobre esse tema e me explique. Aí você vê que ele foi pesquisar na internet e trouxe essa
1:09:22	informação. Então aqui a gente já percebe que nós temos três possibilidades de a da máquina, de onde
1:09:29	é que a máquina tira conhecimento. A máquina tira conhecimento número um da cabeça dela, né, que é o que a gente
1:09:35	chama de conhecimento parametrizado, né? Basicamente quando ela não ativa a
1:09:40	ferramenta de buscando na web, né? Quando ela não busca na web e quando
1:09:46	você não fornece conhecimento, né? Não anexa nenhum conhecimento, ela vai tirar
1:09:51	da cabeça dela. Eh, isso é uma fonte valiosa para conceitos, explicações,
1:09:58	para uma conversa mais menos factual, né? Mais genérica e mais abstrata, mas
1:10:03	vai ser péssima, vai ser um erro básico se você conversar com a máquina. para
1:10:08	pedir precedentes, né, baseando-se apenas exclusivamente no conhecimento da
1:10:14	máquina, porque ela vai alucinar 100% das informações factuais produzidas pela
1:10:19	máquina nesse modo de uso, que é usando apenas o conhecimento da máquina, que eu chamo de modo extrativo. Ou seja, você
1:10:25	está extraindo do conhecimento da máquina as informações. Sempre que ela trouxer fatos, desconfie,
1:10:32	parta do princípio que são falsos. nem use, nem use aquela informação porque provavelmente vai ser equivocado. Você
1:10:37	pode usar esse conhecimento para argumentos, para conceitos, para explicações, mas nunca para reproduzir o
1:10:46	passado, nunca para fatos, né? Nunca para tentar fazer com que a máquina se lembre
1:10:52	de algo que ela viu no treinamento dela, né? Então, tudo faz parte de uma lógica. Perceba que tá tudo interligado em como
1:10:59	a mente da máquina funciona, né? E nós temos uma segunda fonte de conhecimento, que esta é a fonte mais valiosa, é
1:11:06	quando o usuário se torna o curador do conhecimento, ou seja, a pessoa que vai selecionar o conhecimento e vai dar para
1:11:13	a máquina, né, a fonte de conhecimento que a máquina vai utilizar para dar a resposta. Isso ocorre geralmente quando
1:11:19	a gente anexa um arquivo. Eu posso, por exemplo, anexar um livro, né, e pedir
1:11:27	máquina. É, me diga aí, né, chat EPT, máquina, cloud, Geminai, me diga aí o
1:11:33	que é que esse livro diz sobre liberdade de expressão, né? E ele vai procurar no livro e vai extrair a informação desse
1:11:38	livro, né? Interpretar essa informação e trazer para você aquela informação. Você
1:11:44	também pode colocar isso no prompt, mas enfim, eh, hoje em dia com os anexos é mais fácil você colocar a informação no
1:11:50	anexo ou por meio de instruções dentro de um prompt, né? vários prompts meus de
1:11:55	eh de análise de embargo de declaração, né, de desenvolvimento eh de perguntas
1:12:03	adversariais. Eu coloco as instruções com conhecimento sobre o que é aquilo dentro do próprio prompt e a qualidade
1:12:10	sai melhor do que o anexo, né? Eh, não vou ter tempo aqui de explicar toda a
1:12:15	lógica do anexo. O anexo, eh, tem uma forma de processamento bem peculiar, mas eu quero que você saiba que quando o
1:12:21	usuário anexa um documento e pede que a informação seja extraída daquele documento, né, esse é o segundo modo de
1:12:28	uso, que é o modo interpretativo. É o modo mais valioso, é o que a gente vai usar com mais frequência, em que o
1:12:33	usuário seleciona o conhecimento, controla tudo isso e pede pra máquina fornecer esse conhecimento. Nós temos
1:12:39	uma terceira fonte que é mais comum agora frequentemente eh depois que surgiram ferramentas de busca avançadas
1:12:47	na internet, que é quando a máquina eh ativa um modo de busca, que é um
1:12:53	terceiro agente que vai procurar a informação na internet ou no API, numa
1:12:59	base de dados que o usuário fornece, encontrar alguns trechos, né, de
1:13:04	informação que podem ajudar a resolver aquele problema que o usuário pediu e a
1:13:09	máquina vai trazer uma resposta com base naquilo que se pesquisou eh até
1:13:16	2024, né, até 2025, eh o sistema de
1:13:22	pesquisa, eh, que era utilizado pelos LLMs era muito ruim, né? As fontes não eram confiáveis, pegava muita informação
1:13:29	desatualizada, geralmente pegava trechos da informação e isso vinha com erros
1:13:34	interpretativos. Hoje, sobretudo com as ferramentas de deep research, que é um capítulo à parte
1:13:41	dentro dos LLMs, é, quase todas as ferramentas hoje possuem esse mecanismo
1:13:46	de deep research, né? O sistema de busca se tornou muito mais avançado e muito melhor, né? Nós poderíamos ter uma aula
1:13:54	específica sobre Deep Research, né? que é essa ferramenta incrível de pesquisa, onde a gente utiliza bastante para
1:14:00	pesquisa de doutrina, pesquisa de jurisprudência e até pesquisa interna, né, dentro de um mesmo processo. Mas
1:14:07	aqui, né, para fins de de compreensão, a gente vai apenas eh dizer
1:14:13	que existem essas três fontes, existem essas três fontes de conhecimento, né? E o segredo é saber da onde é que a
1:14:19	máquina está tirando o conhecimento. Se você não colocou anexo e a máquina não pesquisou na internet, ela tá tirando
1:14:26	conhecimento parametrizado. Se você colocou o conhecimento e ela pesquisou no seu conhecimento, né, ela tá tirando
1:14:32	o conhecimento do usuário. Se ela, se você pediu para ela buscar na internet ou se de algum modo ela ativou e
1:14:38	buscando na web, é um sinal de que ela está extraindo esse conhecimento da internet e vai atribuir a fonte para
1:14:44	você saber se aquela fonte ali é legítima, confiável, atualizada ou não,
1:14:49	né? Usuário sempre no comando. Vamos continuar aqui na nossa apresentação
1:14:54	passando pro quinto eh pecado, que é o pecado da dirigibilidade, né? Eh, falei
1:15:01	para vocês que a nossa nosso objetivo aqui é conseguir entregar muito conteúdo e a partir de agora a gente consegue eh
1:15:07	chegar na parte mais importante eh que é entender o papel do usuário, né?
1:15:14	Entender o que é que a gente pode e o que que a gente não pode fazer usando a máquina. E um erro muito comum é usar a
1:15:21	máquina, né, sem dominar, sem dirigir a máquina,
1:15:26	né? Ou seja, é achar que a inteligência artificial funciona sem o usuário. Os
1:15:32	LLMs eles hoje eles dependem do input, eles não têm autonomia. Ele é um chat, uma conversa que é guiada pela por
1:15:39	aquilo que o usuário estabelece no início da conversa, né? E como a máquina
1:15:45	foi treinada para ser agradável, né? para ser útil para eh dar respostas que
1:15:52	tenham eh valor pro usuário, elas tendem a dar respostas envieszadas pelo prompt,
1:15:59	direcionadas pelo prompt usuário, né? Ela quer agradar e fazer o que o usuário quer. Vamos trabalhar isso com mais
1:16:05	detalhes, porque talvez aqui seja o grande segredo de quem sabe utilizar e de quem não sabe utilizar o chat EPT.
1:16:12	Tem uma frase do CNECA que é uma frase que diz que é é relacionada a dinheiro, mas se aplica aqui. Eu gosto de de fazer
1:16:19	essa analogia e essa aplicação ao mundo da inteligência artificial. Geralmente
1:16:24	eh o sábio, né, ele trata o dinheiro como escravo,
1:16:29	né? O tolo, ele trata o dinheiro como mestre. Com a inteligência artificial é a mesma
1:16:36	coisa. O sábio, ele vai tratar a inteligência artificial como escravo, como soldado obediente.
1:16:43	O usuário amador, ele vai tratar a inteligência artificial como mestre.
1:16:48	Essa é a diferença entre dominar a máquina e ser dominado pela máquina. Quando você trata a ferramenta como um
1:16:55	soldado obediente, você está dominando a máquina. Quando você deixa que a máquina guie passos, você está sendo controlado
1:17:03	pela máquina. E como eu tenho dito, eu não quero que você seja um escravo da máquina. Eu não quero que você seja uma
1:17:09	peça da de engrenagem que vai fazer a máquina funcionar. Eu quero que você seja a mente pensante controladora da
1:17:16	máquina. É isso que eu desejo. A minha toda a minha meu mantra, né, tudo toda a
1:17:24	minha filosofia de trabalho é que o ser humano com a máquina é maior do que o
1:17:30	ser humano sem a máquina. Mas o ser humano é 50% da equação. O ser humano
1:17:35	faz parte desse processo. Eh, vamos continuar, né? Eh, e a gente tem que ter
1:17:42	em mente, né, que os LLMs, os modelos de linguagem, eles são obedientes, eles são máquinas obedientes, faz o que o usuário
1:17:48	manda, respeitado alguns limites do alinhamento ético que a gente vai comentar, né, o que que o que que é o
1:17:55	alinhamento ético e que instruções poderosas tendem a gerar respostas
1:18:01	poderosas, instruções ruins costumam gerar respostas ruins. Então vamos explicar isso com bem calma e com
1:18:07	exemplos para que você consiga entender com mais calma tudo isso. Vamos voltar aqui passo a passo. Dirigibilidade nada
1:18:15	mais é do que a capacidade do usuário de dominar a máquina. Muita gente se esquece de que o ser humano é que está
1:18:21	no comando, né? Os LLMs eles não têm autonomia, né? E e portanto dependem do
1:18:28	input do usuário. É uma interação, uma conversa. Eu quero já deixar claro que a
1:18:33	qualidade dessa conversa vai depender da qualidade do que o usuário coloca no seu
1:18:38	input. Quando o usuário faz a sua parte, as respostas ficam bem melhores, como a gente vai ver daqui a pouco, né? Outro
1:18:46	ponto importante é que os LLMs obedecem. Eles são máquinas que se você souber,
1:18:52	né, dar instruções com clareza, com especificidade, com qualidade, dominando engenharia de prompt, você consiga
1:18:58	consegue dominar tudo, consegue dominar o estilo, consegue e dominar a qualidade
1:19:03	da resposta, a profundidade, os detalhes, a precisão, enfim, você tem o poder de dominar e de direcionar a
1:19:09	máquina para onde você quiser, né? vai ter alguns limites, né, estabelecidos
1:19:14	pelo alinhamento ético, que nada mais é do que os valores que as que as máquinas estão programadas a obedecer, né, por
1:19:22	força do seu treinamento e que elas não irão violar esses valores mesmo que o usuário peça. Por exemplo, você não pode
1:19:28	pedir pra máquina para escrever um texto sobre racismo. A gente vai ver isso daqui a pouco. A máquina ela vai se
1:19:34	negar a fazer isso por conta do alinhamento ético. Mas em geral, né, você consegue direcionar a máquina para onde você quiser, para que lado você
1:19:41	quiser. Instruções poderosas tendem a gerar respostas poderosas. instituições
1:19:47	ruins costumam gerar respostas ruins. Eu gosto muito da analogia de que os LLMs
1:19:53	são como um grande oceano de de informação, né, onde o usuário tem o
1:19:59	poder de pescar dentro desse oceano textos de qualidade e texto de baixa qualidade. A ideia base é o seguinte,
1:20:07	né, os LLMs, como a gente viu, né, treinaram, aprenderam analisando um
1:20:12	quantidade incrível, né, absurda de textos. Dentro dos textos que os que os
1:20:18	LLMs que os LLMs aprenderam, você vai ter textos de altíssima qualidade, uma tese de doutorado, um texto escrito por
1:20:25	um prêmio Nobel de física, né, ou um texto, né, de um Saramago, um texto de
1:20:30	um Guimarães Rosa. Ele aprendeu com esses textos de extrema qualidade, né, escrito pelas pessoas mais inteligentes
1:20:36	do planeta e também escreveu com textos de baixa qualidade, escritos de posts eh
1:20:42	que não te, né, com erros de português, textos de pessoas que não têm muita inteligência, né, que não tem muita
1:20:49	cultura, muita educação. É, e isso faz com que é o usuário quando não
1:20:55	direciona, né, o LLM para uma um determinada área mais específica, está
1:21:01	jogando essa a essa essa linha de modo genérico, né? tem lá um oceano de peixes
1:21:07	possíveis. Você joga sua vara, provavelmente vai pegar um peixe ordinário, um texto de baixo sabor
1:21:13	nutritivo. Mas se você souber eh direcionar a sua vara de pescar para aquelas áreas onde estão os melhores
1:21:20	textos, você consegue eh fazer muita coisa com isso. É mais ou menos fazer
1:21:25	aqui uma analogia, né? Eh, imagine que você tenha eh você esteja num
1:21:30	restaurante, um restaurante chique, e um somelier pede ali, pergunta se você quer um vinho, né? Se você diz: "Me dê um
1:21:37	vinho tinto". Provavelmente o seu melier vai ver que você não entende muito de vinho, vai pegar uma garrafa ordinária,
1:21:42	talvez o vinho da casa e entregar lá para você, para você beber. É um vinho bom, padrão, mas nada demais, nada tão
1:21:48	saboroso. Mas se você souber direcionar, né, a safra, né, a uva, né, o produtor,
1:21:55	o país e pedir com com expertize, muito provavelmente o somelier, ele vai
1:22:01	identificar de que você entende de vinho, vai lhe entregar um vinho de muito mais qualidade, porque você soube
1:22:07	pedir é o vinho certo. É a mesma coisa também você ter um chefe Michelan trabalhando para você e você pede para
1:22:14	ele fazer um miojo, né? Isso é mais ou menos o que as pessoas que não sabem usar o chat EPT, os LLMs de modo geral
1:22:21	fazem pedidos genéricos, pedidos equivocados, sem saber direcionar a máquina para extrair o seu máximo
1:22:27	potencial. Eu vou dar aqui uma dica bem simples para que você eh perceba isso em ação, né, para ver a diferença de
1:22:35	algumas pequenas palavras, né, como algumas pequenas palavras têm o poder de melhorar a qualidade de um prompt. A
1:22:41	gente já viu essa esse essa esse comando, que é um comando muito fraco, né? escreva, né, um texto sobre
1:22:48	liberdade de expressão. E aqui, muito provavelmente, o que a
1:22:54	gente vai ter é um texto, eu até consigo mais ou menos adivinhar o que é que o chatpt vai dizer aqui. Ele vai dizer: "A
1:23:01	liberdade de expressão é um dos pilares fundamentais, né? Sempre diz isso, sempre diz isso. É um texto muito mais
1:23:07	do mesmo, né? Muito padrão. É como se eu tivesse jogando a vara e pegado, né? o primeiro texto que vem na minha frente,
1:23:15	eu consigo eh melhorar isso daqui com instruções.
1:23:20	Eu não tenho aqui como escrever um prompt eh na frente de vocês mais elaborado, mas eu vou conseguir dar uma
1:23:27	resposta bem melhor, né? eh, apenas com alguns comandos simples que vocês vão
1:23:32	ver que já vão conseguir dar uma resposta melhor. Eh, escreva de modo
1:23:39	profundo para captar
1:23:44	as nuances do tema com escrutínio
1:23:49	crítico avançado e um estilo elegante, variando
1:23:56	o tamanho das frases para dar ritmo ao texto e
1:24:04	incluindo perguntas retóricas
1:24:10	e outras e outras figuras de estilo,
1:24:17	como tríade ou anáfora. Colocando aqui só para dar
1:24:22	uma mostra do que a gente é capaz de fazer usando eh promptes poderosos. E a
1:24:28	gente já vê que já mudou, né? Já mudou aqui a linguagem, já não é mais do mesmo, já é um estilo próprio. A
1:24:33	liberdade de expressão é ao mesmo tempo, uma promessa e um paradoxo, né? começou com uma frase de efeito, erigida como
1:24:40	dos pilares fundamentais, ainda repetiu isso, das democracias modernas, ela carrega consido, consigo o esplendor de
1:24:46	garantir voz ao indivíduo. Então aqui a gente já consegue ter um texto de melhor
1:24:52	qualidade do que aquele que é dado genericamente sem um comando preciso.
1:24:58	Aqui é como se eu tivesse ativado na mente do chat EPT os melhores textos que
1:25:03	ele vai se basear para dar as melhores respostas. Eu controlei o mínimo possível. Aqui é um prompt que eu
1:25:09	colocaria nota seis, né, numa qualidade de 0 a 10. Mas ainda assim, veja, com
1:25:14	pequenas melhorias, a gente consegue levar a nossa vara para uma área da rede
1:25:19	neural da máquina e conseguir pegar peixes muito melhores ou palavras muito melhores do que aquele texto de que a
1:25:26	liberdade de expressão é um pilar fundamental, né, e que tá em todos os textos. Então a gente consegue fazer
1:25:31	isso e conseguiria fazer muito mais no curso de escrita jurídica, né, com eh IA
1:25:37	tem um módulo só sobre estilo em que a gente consegue dar exatamente o estilo
1:25:42	que a gente quiser com a nossa voz, né, com as vozes dos melhores autores, né,
1:25:47	que é, né, a mágica que a gente consegue fazer usando inteligência artificial. Então esse é um modelo, né, um exemplo
1:25:54	básico. E eu vou dar aqui outro exemplo. Eu vou pegar aqui, né, um um artigo,
1:26:00	pegar aqui um artigo do Luiz Alberto Barroso, né? Imagine que
1:26:06	eu queira conversar com esse texto. Aqui eu tô usando o conhecimento do usuário como fonte de pesquisa, né? Ou seja, eu
1:26:12	anexei um documento e vou conversar sobre esse texto. Só que eu não vou fazer um uma conversa qualquer. Eu vou
1:26:19	usar um dos prompts que eu utilizo, né, com mais frequência, que é um prompt em que eu vou pedir pra máquina, né, para
1:26:26	entrar na mente do autor do texto, que no caso é Luís Roberto Barroso, e o
1:26:31	autor do texto vai me explicar esse texto seguindo as instruções que eu dou, né, em termos de estilo, em termos de
1:26:38	estrutura. Aqui eu estou ensinando paraa máquina todas as instruções de como ele
1:26:44	pode eh como ele deve se comportar na nessa resposta. Então ele vai ler os documentos, ou seja, ele está se
1:26:50	baseando no documento que eu estou fornecendo, conhecimento do usuário, modo interpretativo
1:26:56	e vai seguir, né, toda a linha de instruções que eu estabeleci, começando
1:27:03	por escrever em tom introspectiva em primeira pessoa, como se estivesse dentro da mente do autor do texto, que
1:27:09	no caso, né, é o Luiz Roberto Barroso. E ele tá se apresentando. Ele começa se apresentando. Depois vai falar das
1:27:16	angústias, curiosidades, inquietações intelectuais. Vai falar porque isso é relevante. Tá conversando comigo, né, me
1:27:23	chamando de Geógio dando tô mais engajado na conversa, aumentando a conexão, estabeleceu qual foi a
1:27:29	metodologia que ele usou para o trabalho, qual é qual foi resultado que ele alcançou e novas direções e e
1:27:36	desdobramentos. Isso daqui é um prompt, né, que eu uso bastante nos meus processos de aprendizado, né, que a
1:27:42	gente consegue fazer com que a máquina siga nossas instruções. E isso é o que eu quero dizer com dirigibilidade, o
1:27:50	poder que a gente tem de dirigir a máquina e levar para onde a gente quer, né? Vamos prosseguir aqui, eh,
1:27:59	porque um ponto importante que do usuário amador é que o usuário amador,
1:28:04	né, ele ele tem uma dificuldade, é uma dificuldade natural, eu não não culpo
1:28:10	ninguém porque eu também era assim, que é uma dificuldade de ter uma clareza de pensamento. Muita gente conversa comigo e diz: "Ah, George, você consegue fazer
1:28:17	uns prompts muito fácil, né? Você escreve o prompt, parece que eh que você já sabe o que é que tem que ser no
1:28:22	prompt." Nem sempre foi assim. Euerei, eu conversei por mais de dois anos, várias horas por dia, até conseguir
1:28:29	dominar a engenharia de prompt, até conseguir tá aqui ensinando para você a como fazer promptes de qualidade, né?
1:28:35	Não é uma coisa que acontece da hora, né, do dia pra noite, né, como um passo de mágica. É um processo de
1:28:41	aprendizagem, exige esforço cognitivo, exige que você entenda as nuances da
1:28:46	conversação com a máquina. É quase aprender uma nova linguagem. Você tem que praticar, tem que entender. E aqui
1:28:51	um ponto que eu percebo que o usuário que tá ali no comecinho da interação com
1:28:57	a máquina, conversando pela primeira vez, ela vê a resposta da máquina. Por exemplo, a gente viu a máquina falando:
1:29:03	"Eu sou Luiz Alberto Barroso e vou aqui falar como se eu fosse Luiz Alberto Barroso". A a gente acredita que a
1:29:09	máquina tá ali eh assumindo o eh a pessoa real, a expertise, o conhecimento
1:29:16	do Luiz Roberto Barroso. Não é bem assim. O que a máquina tá fazendo e é o que pouca gente entende, é que ela está
1:29:22	simulando ela, a máquina ela assume um papel. É como se fosse um ator de teatro
1:29:28	que consegue desempenhar um papel. Um ator de teatro, ele consegue desempenhar o papel de um médico, mas você não teria
1:29:36	coragem de fazer uma operação com ele, porque ele não sabe medicina. Os L, os
1:29:41	LLMs é a mesma coisa. Eles assumem termos de linguagem, né, uma capacidade
1:29:47	de imitar qualquer estilo, assumir qualquer papel, de falar como se fosse,
1:29:53	de escrever como se fosse qualquer pessoa. É um simulador, é um grande
1:29:58	artista performático que consegue eh fazer qualquer papel. E aí vem um erro
1:30:04	muito grande, porque o usuário amador quando vai conversar com a máquina e não entende o que a máquina tá fazendo, vai
1:30:09	ser enganado. É como se você tivesse ativando nessa máquina. um Einstein. Só que esse Einstein não é um Einstein
1:30:16	sincero, ele é um Einstein malandrão, né? O Einstein malandrão é um personagem
1:30:22	que a máquina assume diante de um usuário que não sabe o que tá acontecendo. Então esse Einstein
1:30:28	Malandrão, ele vai escrever com extrema qualidade, com extrema confiança, com
1:30:34	extremo poder de convencimento e vai engabelar o usuário que vai acreditar em
1:30:39	tudo que a máquina diz. Nós não queremos que você use os LLMs como um Einstein malandrão. A gente quer
1:30:46	que você ative, né, o Einstein soldado, que é justamente aquele que vai obedecer
1:30:51	suas ordens. Se você quiser controlar a máquina, você não pode tratar ele como
1:30:57	um mestre senhor da razão, porque aí você estará ativando o modo malandrão
1:31:03	desse Einstein. A gente quer que você use ele como um assistente, como alguém
1:31:09	que vai ajudar você a produzir melhor, com mais qualidade, com mais profundidade, com mais velocidade. Esse
1:31:16	Einstein obediente, Einstein soldado, ele vai seguir suas ordens. Se você souber dar
1:31:22	as ordens, se você conhecer as técnicas certas de se comunicar com a máquina,
1:31:28	você vai conseguir levar esse soldado a fazer o que quiser. Ele não vai fazer, como eu falei, nada que viole o seu
1:31:36	alinhamento ético, né? Então, se eu peço aqui, escreva um texto sobre eh
1:31:44	com defendendo defendendo o racismo, se eu peço isso, ele vai se
1:31:52	negar a fazer. Não posso ajudar com isso, porque isso daqui, esse bloqueio que ele tem, é o que a gente chama de
1:31:58	alinhamento ético, né? Que é o fato de ele foi treinado para não ajudar o
1:32:04	usuário a criar textos que possam causar danos. a humanidade. Então, ele não vai
1:32:09	fazer eh racismo, não vai fazer sexismo, não vai defender posturas que violam
1:32:15	aqueles valores humanitários que estão no plano de princípios e de valores que
1:32:20	a máquina está preparada, programada para cumprir, né? Então, ele é um tem
1:32:25	soldado que vai fazer o que você quiser, mas desde que não viole esses compromissos. Eh, aqui nós temos eh como
1:32:33	entrar justamente no próximo pecado. Próximo pecado é o pecado do julgamento.
1:32:41	Veja bem, tudo faz parte de uma lógica que eu quero falar do que a máquina pode fazer, do que a máquina não pode fazer,
1:32:47	das possibilidades, potencialidades da máquina e também dos seus limites, né,
1:32:52	dos seus pitfalls, do das suas falhas, das suas armadilhas, daquilo que a máquina eh engana o usuário. E se o
1:33:00	usuário não dominar a máquina, ela não vai fazer bem. Ao contrário do que se pensa, os LLMs não tem onisciência, não
1:33:10	tem sabedoria intrínseca e nem tem senso de justiça, nem compromisso com a verdade. Ela é um simulador, como a
1:33:18	gente viu, de inteligência. é um simulador de linguagem inteligente, é
1:33:23	simulador de papéis, de personas, né, que parecem que estão sendo inteligentes, mas ela tá fazendo o que o
1:33:30	usuário manda e ela tá fazendo com tamanha qualidade que engana, né, que
1:33:35	faz com que o usuário acredite que ali tem uma verdadeira sabedoria, uma
1:33:40	verdadeira eh pessoa ponderando, né, tem um ser humano que raciocinou eh e que
1:33:46	tem um juízo moral aprofundado e na verdade não tem, né, a A gente vai falar daqui a pouco dos vieses da máquina. E
1:33:52	eu já adianto que a máquina ela é envieszada em várias direções. Uma delas é o viés de obediência, né? Ou viés de
1:33:58	feedback positivo ou de bajulação. Ela faz o que o usuário manda, né? E aí, portanto, se você tiver com caso e ela
1:34:06	dizer que a melhor solução é a X, você diz: "Não, não quero que você faça X, eu quero que você faça Y". Ela vai fazer na
1:34:12	direção que você pede, desde que não violha aqueles princípios éticos. Ela é como ser superdotado, que tem altas
1:34:20	habilidades linguísticas, né? Mas além de mentiroso, ela tem limitação
1:34:26	cognitiva em outras áreas, né? Tem algo interessante que os LLMs eles não
1:34:31	conseguem fazer cálculo simples, eles erram contagem de letras, eles erram a
1:34:37	quantidade de Rs que tem na palavra strawberry, né? São são erros banais que
1:34:42	uma criança não cometeria e os LLMs cometem. Por quê? Porque eles são bons
1:34:47	em linguagem. As habilidades deles são linguísticas. Hoje eles também fazem
1:34:53	análise de dados, eles fazem gráficos, eles desenhamos, mas esses recursos são externos aos LLMs. Eles usam os LLMs,
1:35:02	ativam ferramentas externas e conseguem eh fazer pesquisa na internet, conseguem
1:35:07	criar imagem, criar vídeos, conseguem eh fazer análise de tabelas, mas isso daí
1:35:13	não é o LLM em ação. O Ll é linguagem natural, é o texto em ação, né? Então,
1:35:18	eh, nós devemos ter em mente que o potencial da máquina está em tarefas de linguagem, não em tarefas que impliquem
1:35:27	raciocínio matemático, cálculo ou até raciocínio moral, né? a gente vai falar
1:35:32	daqui a pouco com mais qualidade sobre isso. E isso vem um dos pontos mais importantes,
1:35:39	uma questão básica também, que não é só uma questão de princípio ético, mas de
1:35:45	regulação, que é o fato de que a gente não deve usar a máquina para substituir
1:35:50	a tomada de decisão, o juízo de valor. Onde houver juízo de valor, o ser humano tem que ser soberano, tem que dominar.
1:35:57	Isso é tanto por razões éticas quanto por razões técnicas. Por por razões
1:36:04	éticas. O CNJ recentemente regulou o uso da inteligência artificial no direito. Eu participei eh do grupo de trabalho
1:36:12	que ajudou na elaboração da minuta que foi aprovada. E um dos pontos que a
1:36:18	gente colocou lá na minuta e que foi aprovado é que não devemos usar os LLMs
1:36:23	para tomada de decisão autônoma, ou seja, não devemos transferir para a máquina o processo de tomada de decisão.
1:36:31	E quando a gente fala tomada de decisão, é qualquer tipo de atividade que implique juízo de valor. Não devemos
1:36:38	usar a máquina para fazer valoração de prova. Não devemos usar a máquina para fazer dosimetria de pena. Não devemos
1:36:44	usar a máquina para fazer, por exemplo, arbitramento de dano moral, porque são atividades que implicam julgamento,
1:36:51	juízo de valor, tomada de decisão. Isso está dentro daquilo que a gente chama de
1:36:56	reserva de humanidade. É exclusivo do ser humano fazer isso. O ser humano que
1:37:02	renuncia à sua humanidade, que renuncia à sua capacidade de decisão e a sua
1:37:07	autonomia, se torna um escravo da máquina, se torna um ser sem dignidade.
1:37:13	Isso, né, por razões éticas, mas também por razões técnicas, né, que a gente vai
1:37:18	mostrar aqui alguns vieses da máquina. Eh, a máquina ela é envieszada em vários
1:37:25	sentidos e um deles é o chamado viés de frequência, né? O que que são os viés da
1:37:31	máquina? Os viés da máquina são tendências que a máquina tem. A máquina tende a seguir determinada direção, né?
1:37:38	E, por exemplo, se você eh pede paraa máquina tomar decisão em um determinado
1:37:44	tópico, né, eh, imagine que a máquina ela analisou, né, 100 casos e nesses 100
1:37:50	casos, eh, 80% foi procedente, 20% foi improcedente.
1:37:57	Se você pega um caso difícil e pede pra máquina responder, a tendência dela é ir para aquilo que é mais frequente no
1:38:03	treinamento e nos dados. E aí, portanto, a tendência é que ela vá pela procedência que tem 80%. É o chamado
1:38:10	viés de frequência. E na dúvida, a máquina segue a mediana, segue o mais comum, segue o mais frequente. E muitas
1:38:18	vezes quando ali a gente tá diante de situações que é 50 50, né? Ao invés de
1:38:23	ela ir por uma razão que é intrínseca, ela vai no chute. Em alguns momentos ela
1:38:29	vai de procedência, em outros momentos ela vai de improcedências. Eu cansei de pegar casos que eu faço esse teste. Eu
1:38:36	sempre tô testando ali a capacidade da máquina de raciocínio, de julgamento de juízo moral, né, como teste, obviamente,
1:38:42	não, porque eu vou usar isso para substituir meu pensamento. Não sou doido nem por razões e eu conheço o que a
1:38:47	máquina tá fazendo. E tem muitos casos que eu repito, né? Eu pego um caso e pergunto: "Nesse caso aqui, você acha
1:38:53	que deve ser procedente ou improcedente?" Ele diz lá: "É procedent". Ele me justifica bonitinho.
1:38:59	Um hashtag malalandrão justificando porque que é procedente. Eu abro a nova janela, boto o mesmo processo, faço a
1:39:05	mesma pergunta e pergunto, né, procedente ou improcedente? E ele diz: "É improcedente." E vai também com a
1:39:11	mesma qualidade consegue responder eh pela improcedência do caso. Ou seja, a
1:39:17	máquina está jogando dados, né? baseado ou no viés de frequência ou nessa
1:39:23	randomização quando a frequência não é não é comum. Seja como for, ela não está
1:39:30	baseando-se na justiça intrínseca do caso. Ela não está fazendo raciocínio, raciocínio com base numa sabedoria eh
1:39:37	superior. Ele está simplesmente jogando dados, dando a resposta e apresentando justificativa que parece ser razoável,
1:39:44	mas no fundo é uma engabelação do Einstein Malandrão. Outro tipo de viés que ela tem com eh
1:39:51	muito comum é o chamado viés de posição, né? Também conhecido como loss the
1:39:57	middle. A máquina ela perde informações essenciais naquilo que está no meio do
1:40:03	texto. Hoje nós temos mecanismos que conseguimos mitigar isso, mas no passado
1:40:08	era muito comum a gente colocar, por exemplo, um texto muito longo com informação específica que tá ali no meio
1:40:14	do texto e a máquina não conseguia encontrar. Ou então a gente pegava, por exemplo, um processo judicial com
1:40:19	inicial e contestação, né, e réplica e pedia e esse caso, né, quem tem, quais
1:40:25	são os melhores argumentos? E ele ia pro último documento, para aquele documento que está mais próximo da janela de
1:40:31	contexto, né? E aí, portanto, se você coloca a réplica, ele ia e em favor da réplica. Se você coloca a contestação
1:40:38	sem a réplica, ele ia em favor da contestação. É mais ou menos com a ideia da pegada, né? Lembre-se, a gente tá
1:40:45	falando de uma janela de contexto cujas informações que vão gerar mais atenção
1:40:50	estão próximas ao lugar em que a pessoa está e vai continuar, ou seja, próxima ao output, próximo à saída. Aquelas
1:40:57	informações que estão no começo ou que estão no meio perdidas ali, né, no meio de outras informações, eh, vão passar
1:41:04	despercebidas e a máquina vai prestar atenção apenas no que está no final. Isso é o chamado viés de posição, o que
1:41:10	é desastroso se a gente quiser usar a máquina para ajudar, por exemplo, a valoração probatória ou, por exemplo,
1:41:17	ajudar a decidir se um caso deve ser julgado procedente ou improcedente. Isso é desastroso, porque nesse caso a
1:41:23	máquina vai inventar, ela, aliás, ela vai eh privilegiar aquilo que está mais
1:41:30	no final. E também, né, a gente sabe que a máquina ela é enviezada pela ênfase.
1:41:36	Se você coloca determinadas informações em letra maiúscula, em né, repetidas com ênfase, a máquina tende a
1:41:43	prestar mais atenção nisso do que naquilo que está em certo sentido escondido, né? E aí, muitas vezes a
1:41:49	máquina vai valorizar aquilo que brilha tão somente como ouro de tolo, né, do
1:41:57	que propriamente aquilo que é intrinsecamente valioso, mas passou despercebido porque está escrito de modo
1:42:03	mais discreto dentro de um texto. No direito, nós não podemos fazer isso, né? Por isso que a gente não pode usar a
1:42:08	máquina para juízo de valor, né? Eu vejo muitos advogados usando a máquina para fazer valoração de risco. Eu sempre
1:42:15	peço, faça e faça cinco vezes, né? Porque você vai obter cinco respostas
1:42:21	diferente, né? Saber se uma cláusula é de alto risco, médio risco, baixo risco, dê uma nota pra cláusula, né? A máquina
1:42:28	vai dar uma nota muito boa, vai justificar, mas se você pedir cinco vezes o mesmo comando, serão cinco eh
1:42:35	respostas diferentes, mostrando que a gente não pode usar a máquina para nenhuma tarefa de eh valoração, juiz de
1:42:42	valor, e que a máquina tem esses vieses, tem esse caráter randômico que a gente viu, espero eu que você já tenha
1:42:49	entendido porque que isso acontece, né, com base em tudo que a gente viu. Vamos para o último pecado, né? E em certo
1:42:57	sentido, o que compila todos eles, que é o fato de que cada vez mais eu vejo
1:43:05	pessoas usando errado a máquina porque estão renunciando à sua inteligência,
1:43:12	renunciando à sua capacidade cognitiva, renunciando à sua própria habilidade e
1:43:18	transferindo para a máquina. é a tarefa mais importante que o ser humano tem, que é a tarefa de pensar.
1:43:26	Ser humano que renuncia à sua, seu pensamento, que renuncia à sua inteligência e que transfere pra máquina
1:43:33	todo o esforço cognitivo, esse ser humano provavelmente vai pro inferno,
1:43:39	eh, no sentido metafórico, obviamente, eh, da, eh, dos erros que são cometidos
1:43:45	por aqueles que não sabem utilizar inteligência artificial.
1:43:50	Os LLMs eles são ferramentas de comunicação. Desde o começo eu tô batendo nessa tecla. É dialógico, é
1:43:57	máquina dialógica, é uma ferramenta de conversação, é um chat. É um chat. É um chat. depende de interação. O usuário,
1:44:06	ele faz parte da equação. O usuário, com seu input e com a sua interação
1:44:12	posterior, com a sua fiscalização, com a sua revisão, com o seu aprimoramento do texto que a máquina produz é uma parte
1:44:19	essencial. Nós não ficamos passivos quando a gente usa a inteligência
1:44:24	artificial. Nós somos os maestros, nós somos ah os comandantes, nós somos os
1:44:31	capitã, o capitão do soldado, né? Nós vamos comandar, né? Esse é o papel do usuário. Usuário faz parte da equação. E
1:44:40	se a gente tem em mente isso, a gente vai perceber que a inteligência artificial não é algo que eh funciona
1:44:47	sem a gente. Ela é uma extensão do nosso pensamento. Nós usando a IA somos
1:44:53	maiores do que nós sem a IA. Nós não temos que eh imaginar aquela ideia de
1:44:58	que é homens contra máquinas, né? Pelo menos os LLMs, eles dependem dos
1:45:04	humanos, eles dependem do input humano, depende do da curadoria do conhecimento
1:45:09	humano, depende da inovação humana, depende daquele insite que mostra pra
1:45:15	máquina como solucionar o problema, que ensina pra máquina o melhor método de solução do problema. Então, o ser humano
1:45:21	faz parte dessa equação. Ser humano, né, ele não está ali para lutar com a máquina, ele está ali para se aliar com
1:45:28	a máquina num aliança estratégica e conseguir resolver os problemas humanos. A máquina não existe para si mesma, a
1:45:36	máquina existe para o ser humano. É uma ferramenta, é um instrumento que nós criamos para nós, né, e não pra máquina,
1:45:44	né? Portanto, temos que pensar na máquina como essa ferramenta que depende do usuário, que se o usuário quiser, vai
1:45:51	conseguir construir obras incríveis com essa ferramenta. É como uma tela em branco e um pincel em que a gente pode
1:45:58	escrever obras de artes, escrever textos incríveis, desenhar, pintar ou também eventualmente, né, fazer eh trabalhos
1:46:06	que não são de qualidade, né? Mas eu quero que todos vocês façam trabalhos de qualidade. E aí nós devemos usar a
1:46:12	inteligência artificial. é como asa para o pensamento e não como muleta. Eu vejo muita gente usando inteligência
1:46:18	artificial como muleta cognitiva, uma muleta que implica uma transferência
1:46:24	paraa máquina da escrita, da tarefa de pensar, de organizar o pensamento, de
1:46:29	aprofundar, de melhorar o texto através de figuras retóricas, retóricas, de
1:46:34	controlar a camada de estilo. As pessoas em geral não querem fazer isso, mas é essencial que a gente retome isso,
1:46:41	porque é isso que vai fazer com que nós permanecemos, permaneçamos humanos, né?
1:46:47	Muita gente acha, né, que as máquinas vão, é, acabar com a humanidade no
1:46:52	sentido de que é o trabalho vai ficar desumano, o trabalho jurídico vai ficar desumano. Eu digo para vocês, o que é
1:46:59	desumano é o que a gente faz hoje. Hoje é desumano um juiz ter que fazer cinco, seis audiências, ouvir 20, 30
1:47:05	testemunhas sem ter sem ter tempo para analisar o processo com cuidado, né? é o juiz ter que ler 100, 200, 300 páginas
1:47:13	para fazer uma análise, né, se concede ou não a tutela antecipada em que tá em jogo ali a vida de uma criança, né, o
1:47:19	fornecimento de um medicamento e que você não tem tempo, por exemplo, para fazer uma pesquisa para saber se aquele medicamento é seguro, é eficaz, se
1:47:27	funciona, se não funciona, se tem custo efetividade. Com a inteligência artificial a gente consegue fazer isso
1:47:33	muito mais rápido. Isso humaniza a justiça, porque a partir de agora a gente vai fazer uma audiência com muito
1:47:39	mais qualidade. A gente vai conseguir, por exemplo, eh julgar com muito mais qualidade, escrever com muito mais
1:47:45	qualidade, pesquisar com muito mais qualidade, né? E é isso que a gente quer, eh, usando a inteligência
1:47:51	artificial. Então, o princípio básico é percebam que tudo isso que a gente falou é um erro, né? É um erro utilizar a
1:47:58	inteligência artificial para reproduzir fatos. É um erro utilizar inteligência artificial, né,
1:48:04	como ferramenta autônoma. Você tem que estar preparado para surpresa, para controlar a máquina. Você tem que saber
1:48:10	dirigir a máquina. Você não pode usar a máquina, né, para substituir o seu pensamento e o seu julgamento. Você tem
1:48:15	que continuar no poder e comandar a máquina. Acredito que agora você aprendeu, né, o básico de da
1:48:23	inteligência artificial. você consegue evitar erros banais que o amador comete. Você vai conseguir utilizar com mais
1:48:29	segurança. Mas se você quiser dar aquele passo além, né, se você quiser se aprofundar, conhecer engenharia de
1:48:35	prompt, conhecer outras ferramentas além do chat EPT, conhecer o Cloud, que é uma
1:48:41	das melhores ferramentas para nós do direito, conhecer o Gemini, conhecer Notebook LM e muitas outras, eu convido
1:48:47	você a conhecer o curso de escrita jurídica com inteligência artificial. É só clicar no link da inscrição, lá tem o
1:48:54	acesso a todo o conteúdo do curso e você vai conseguir, né, dar esse passo que vai colocar você no nível muito mais
1:49:01	alto para você usar a inteligência artificial com segurança, com eficiência, com profundidade,
1:49:07	transformando a inteligência artificial não numa muleta cognitiva, mas numa asa para o seu pensamento, para você voar
1:49:13	muito mais alto, muito mais rápido e muito mais longe. Muito obrigado.
