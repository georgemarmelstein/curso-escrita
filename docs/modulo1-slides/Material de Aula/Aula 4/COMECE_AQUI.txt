‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                                                                               ‚ïë
‚ïë               üìö MATERIAL DE AULA 4 - CONHECIMENTO DA M√ÅQUINA                 ‚ïë
‚ïë                                                                               ‚ïë
‚ïë                         üéØ COMECE POR AQUI! üéØ                                ‚ïë
‚ïë                                                                               ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

==============================================================================
                           üìã O QUE VOC√ä TEM AQUI
==============================================================================

‚úÖ 37 PDFs cient√≠ficos organizados em 4 categorias:
   üìä 5 Surveys de 2024-2025 (vis√£o geral completa)
   üî¨ 18 Papers de 2025 (pesquisas mais recentes)
   üîÑ 3 Papers sobre RAG (conhecimento externo)
   üìñ 11 Papers Fundamentais 2019-2024 (base te√≥rica s√≥lida)

‚úÖ Documenta√ß√£o completa:
   üìÑ INDICE_COMPLETO_PDFS.md (descri√ß√£o detalhada de TODOS)
   üìù COMECE_AQUI.txt (este guia r√°pido)

‚úÖ Total: ~700 p√°ginas de conte√∫do cient√≠fico de alt√≠ssima qualidade

==============================================================================
                    üöÄ IN√çCIO R√ÅPIDO - 3 CEN√ÅRIOS
==============================================================================

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ CEN√ÅRIO 1: "Tenho 2 horas e preciso dar aula amanh√£!" ‚è∞                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚Üí LEIA APENAS ESTES 3 PAPERS (90 minutos):

   1. Papers_Fundamentais/2019_LAMA_Language_Models_as_Knowledge_Bases.pdf [30 min]
      ‚Ä¢ O paper MAIS IMPORTANTE sobre knowledge probing
      ‚Ä¢ Introduziu benchmark LAMA
      ‚Ä¢ LEIA: Introdu√ß√£o + M√©todo + Resultados principais
      ‚Ä¢ Voc√™ PRECISA conhecer este paper

   2. Papers_Fundamentais/2022_ROME_Locating_Editing_Factual_Associations.pdf [30 min]
      ‚Ä¢ Localiza onde conhecimento factual √© armazenado
      ‚Ä¢ M√©todo ROME para knowledge editing
      ‚Ä¢ LEIA: Introdu√ß√£o + Localiza√ß√£o + M√©todo ROME
      ‚Ä¢ Essencial para knowledge editing

   3. Papers_Fundamentais/2020_RAG_Original_Paper.pdf [30 min]
      ‚Ä¢ Paper ORIGINAL de RAG
      ‚Ä¢ Conhecimento externo vs param√©trico
      ‚Ä¢ LEIA: Introdu√ß√£o + M√©todo + Experimentos
      ‚Ä¢ Base de RAG, m√©todo principal de conhecimento externo

‚Üí FOLHEIE ESTE (20 minutos):

   4. Surveys_2025/2024_Survey_Knowledge_Editing_LLMs.pdf
      ‚Ä¢ Survey completo de knowledge editing
      ‚Ä¢ Veja tabela com m√©todos (ROME, MEMIT, etc.)
      ‚Ä¢ Use para overview dos m√©todos

‚Üí PREPARE (10 minutos):
   ‚Ä¢ 1 slide explicando 3 tipos de conhecimento
   ‚Ä¢ 1 slide com diagrama de knowledge neurons
   ‚Ä¢ 1 slide explicando ROME method
   ‚Ä¢ 1 slide mostrando RAG pipeline

‚úÖ RESULTADO: Material suficiente para 90 minutos de aula!


‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ CEN√ÅRIO 2: "Tenho 1-2 dias para preparar bem" üìö                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

DIA 1 - MANH√É (3-4 horas): Fundamentos

   1. Papers_Fundamentais/2019_LAMA_Language_Models_as_Knowledge_Bases.pdf [COMPLETO]
   2. Papers_Fundamentais/2021_Knowledge_Neurons_Pretrained_Transformers.pdf [COMPLETO]
   3. Papers_Fundamentais/2022_ROME_Locating_Editing_Factual_Associations.pdf [COMPLETO]
      ‚Ä¢ Entenda localiza√ß√£o de conhecimento

DIA 1 - TARDE (3-4 horas): Knowledge Editing e RAG

   4. Papers_Fundamentais/2022_MEMIT_Mass_Editing_Memory.pdf
      ‚Ä¢ Escalabilidade de knowledge editing

   5. Papers_Fundamentais/2020_RAG_Original_Paper.pdf [COMPLETO]
      ‚Ä¢ Base de conhecimento externo

   6. Papers_Fundamentais/2024_Generalization_vs_Memorization.pdf
      ‚Ä¢ Quando conhecimento √© memorizado vs generalizado

DIA 2 - MANH√É (3-4 horas): Estado da Arte

   7. Surveys_2025/2024_Survey_Knowledge_Editing_LLMs.pdf
      ‚Ä¢ Survey completo de m√©todos

   8. Surveys_2025/2025_Survey_LLM_Inference_External_Knowledge.pdf
      ‚Ä¢ Taxonomia completa de conhecimento externo

   9. Papers_2025/2025_Bridging_External_Parametric_Knowledge.pdf
      ‚Ä¢ Conflitos de conhecimento - tema central!

   10. Papers_2025/2025_Rethinking_Parametric_Knowledge.pdf
       ‚Ä¢ Tr√™s tipos de conhecimento param√©trico

DIA 2 - TARDE (2-3 horas): Surveys e Revis√£o

   11. RAG_Papers/2025_Survey_RAG_Comprehensive.pdf
       ‚Ä¢ Survey completo de RAG

   12. Surveys_2025/2025_Survey_Domain_Specific_Knowledge_Injection.pdf
       ‚Ä¢ Como injetar conhecimento especializado

   13. Revis√£o e prepara√ß√£o de slides

‚úÖ RESULTADO: Aula profunda e muito bem fundamentada!


‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ CEN√ÅRIO 3: "Quero dominar o tema completamente" üéì                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

SEMANA 1: Papers Fundamentais (11 papers)
   ‚Üí Todos os Papers Fundamentais (pasta Papers_Fundamentais/)
   ‚Üí Focus: Base te√≥rica s√≥lida
   ‚Üí Ordem: LAMA ‚Üí Knowledge Neurons ‚Üí ROME ‚Üí MEMIT ‚Üí RAG ‚Üí resto

SEMANA 2: Surveys (5 papers)
   ‚Üí Todos os Surveys (Surveys_2025/)
   ‚Üí Focus: Estado da arte completo
   ‚Üí Ordem: Knowledge Editing ‚Üí External Knowledge ‚Üí Domain Injection

SEMANA 3: Papers de 2025 (18 papers)
   ‚Üí Todos os Papers 2025 (Papers_2025/)
   ‚Üí Focus: T√©cnicas cutting-edge
   ‚Üí Priorize: Parametric knowledge ‚Üí Conflicts ‚Üí KG integration

SEMANA 4: RAG e S√≠ntese (3 papers + s√≠ntese)
   ‚Üí RAG papers (RAG_Papers/)
   ‚Üí S√≠ntese de tudo
   ‚Üí Prepare material did√°tico final

‚úÖ RESULTADO: Voc√™ ser√° um EXPERT no tema!

==============================================================================
                        üéØ ESTRUTURA SUGERIDA DA AULA
==============================================================================

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ PARTE 1: Conceitos Fundamentais [25 min]                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

   ‚Ä¢ O que √© conhecimento em LLMs?
   ‚Ä¢ Tr√™s tipos de conhecimento:
     1. Param√©trico (armazenado nos pesos do modelo)
     2. Contextual (fornecido no prompt)
     3. Externo (RAG, Knowledge Graphs)

   üìö Papers de apoio:
      - LAMA (conceitos fundamentais)
      - Survey External Knowledge (taxonomia)

   üí° Dica: Use diagrama de Venn mostrando interse√ß√£o dos tr√™s tipos


‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ PARTE 2: Conhecimento Param√©trico [30 min] üß†                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

   ‚Ä¢ Como conhecimento √© armazenado nos pesos?
   ‚Ä¢ Knowledge Neurons: neurons espec√≠ficos encodam fatos
   ‚Ä¢ Localiza√ß√£o: MLP layers, middle-to-deep layers
   ‚Ä¢ Tr√™s tipos de conhecimento param√©trico:
     - Prompt-agnostic (sempre respond√≠vel)
     - Prompt-sensitive (depende do prompt)
     - Unanswerable (modelo n√£o sabe)

   ‚Ä¢ Memoriza√ß√£o vs. Generaliza√ß√£o
     - Memoriza√ß√£o: reprodu√ß√£o verbatim
     - Generaliza√ß√£o: aplica√ß√£o a novos casos

   üìö Papers de apoio:
      - LAMA ‚≠ê (benchmark de probing)
      - Knowledge Neurons ‚≠ê (localiza√ß√£o)
      - ROME (onde conhecimento est√°)
      - Rethinking Parametric Knowledge (tr√™s tipos)
      - Generalization vs Memorization

   üí° Dica: Mostre exemplo de LAMA probe: "Paris is the capital of [MASK]"
           Visualize knowledge neurons ativados


‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ PARTE 3: Knowledge Editing [30 min] ‚úèÔ∏è                                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

   ‚Ä¢ Por que editar conhecimento?
     - Atualizar fatos desatualizados
     - Corrigir informa√ß√£o incorreta
     - Remover conhecimento sens√≠vel

   ‚Ä¢ M√©todo ROME (Rank-One Model Editing)
     - Localiza onde fact est√° armazenado
     - Edita weight matrix para mudar fact
     - Mant√©m outros fatos intactos

   ‚Ä¢ M√©todo MEMIT (Mass-Editing Memory)
     - Escala ROME para MILHARES de facts
     - Edi√ß√£o em massa eficiente

   ‚Ä¢ Outros m√©todos: BaFT, GRACE, SERAC, WISE

   ‚Ä¢ Desafios:
     - Locality (n√£o afetar fatos n√£o-relacionados)
     - Generalization (generalizar edi√ß√£o)
     - Scalability (escalar para milhares)

   üìö Papers de apoio:
      - Knowledge Editing Survey ‚≠ê (overview completo)
      - ROME ‚≠ê (m√©todo fundamental)
      - MEMIT (escalabilidade)
      - BaFT (estado-da-arte 2025)

   üí° Dica: Demonstra√ß√£o ao vivo de knowledge editing
           Mostre "antes" e "depois" de editar fact


‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ PARTE 4: Conhecimento Externo (RAG) [25 min] üîÑ                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

   ‚Ä¢ Por que conhecimento externo?
     - Conhecimento param√©trico pode estar desatualizado
     - N√£o escal√°vel adicionar tudo aos pesos
     - Permite uso de conhecimento privado/propriet√°rio

   ‚Ä¢ RAG (Retrieval-Augmented Generation)
     - Retrieve: busca documentos relevantes
     - Augment: adiciona ao contexto
     - Generate: gera resposta com conhecimento externo

   ‚Ä¢ Knowledge Graphs
     - Conhecimento estruturado em triplas (subject, relation, object)
     - Integra√ß√£o com LLMs para reasoning

   ‚Ä¢ Arquiteturas:
     - Retriever-centric
     - Generator-centric
     - Hybrid

   üìö Papers de apoio:
      - RAG Original Paper ‚≠ê (seminal)
      - RAG Comprehensive Survey (estado-da-arte)
      - Knowledge-Oriented RAG Survey
      - Agentic RAG (evolu√ß√µes recentes)
      - Unifying LLMs + KGs

   üí° Dica: Mostre pipeline visual de RAG
           Compare resposta com/sem retrieval


‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ PARTE 5: Knowledge Conflicts [20 min] ‚öîÔ∏è                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

   ‚Ä¢ O que s√£o knowledge conflicts?
     - Conhecimento param√©trico contradiz conhecimento externo
     - Informa√ß√£o no contexto contradiz conhecimento do modelo
     - Como LLM decide em quem confiar?

   ‚Ä¢ Tipos de conflitos:
     - Parametric vs External
     - Context vs Internal
     - Temporal (conhecimento desatualizado)

   ‚Ä¢ M√©todos de resolu√ß√£o:
     - DSSP-RAG: Separa sem√¢ntica shared vs private
     - CK-PLUG: Confidence Gain para detectar conflitos
     - ParamMute: Suprime FFNs com conhecimento conflitante

   ‚Ä¢ Quando confiar em par√¢metros vs contexto?
     - Depende de confiabilidade de cada fonte
     - Timestamp de conhecimento
     - Confidence scores

   üìö Papers de apoio:
      - Bridging External Parametric ‚≠ê (DSSP-RAG)
      - Parameters vs Context ‚≠ê (CK-PLUG)
      - ParamMute (localiza√ß√£o de conflitos)
      - Training Dynamics (como conflitos surgem)

   üí° Dica: Exemplo concreto de conflito
           "Quem √© o presidente dos EUA?"
           Parametric (desatualizado) vs Context (atualizado)


‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ PARTE 6: Knowledge Injection [15 min] üíâ                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

   ‚Ä¢ Como adicionar novo conhecimento?

   ‚Ä¢ Quatro abordagens:
     1. Dynamic injection (durante infer√™ncia)
     2. Static embedding (nos pesos)
     3. Modular adapters (m√≥dulos especializados)
     4. Prompt optimization (via prompts)

   ‚Ä¢ Low-resource scenarios:
     - Poucos milhares de tokens de dados
     - Varia√ß√µes textuais ajudam muito
     - Continued pretraining vs synthetic augmentation

   ‚Ä¢ MEGa: Memory Embedded in Gated LLMs
     - Cada mem√≥ria em gated low-rank weights
     - Adi√ß√£o incremental sem interfer√™ncia

   üìö Papers de apoio:
      - Domain-Specific Knowledge Injection Survey
      - Knowledge Injection Low-Resource
      - MEGa Memory Embedded

   üí° Dica: Compare efetividade das abordagens
           Quando usar cada uma?


‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ PARTE 7: Futuro e Conclus√µes [15 min] üîÆ                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

   ‚Ä¢ Tend√™ncias emergentes:
     - Agentic RAG (agentes aut√¥nomos)
     - Multimodal knowledge (imagens, v√≠deo)
     - Dynamic knowledge graphs
     - Continual learning of knowledge

   ‚Ä¢ Desafios abertos:
     - Conhecimento conflitante em escala
     - Verifica√ß√£o de factualidade
     - Privacy-preserving knowledge
     - Efficient updating sem degrada√ß√£o

   ‚Ä¢ Implica√ß√µes pr√°ticas:
     - Quando usar parametric vs external?
     - Como manter conhecimento atualizado?
     - Trade-offs: custo, lat√™ncia, acur√°cia

   üìö Papers de apoio:
      - LLM Knowledge Graph Construction (tend√™ncias)
      - Agentic RAG (evolu√ß√µes)
      - Knowledge Graphs LLMs Hallucinations

   üí° Dica: Termine com provoca√ß√£o sobre futuro

‚è±Ô∏è TOTAL: ~160 minutos (2h40min) - Ajuste conforme necess√°rio

==============================================================================
                       üìä PAPERS OBRIGAT√ìRIOS POR TEMA
==============================================================================

Se voc√™ s√≥ puder ler POUCOS papers, escolha por tema:

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ TEMA: Conhecimento Param√©trico                                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
   1. LAMA_Language_Models_as_Knowledge_Bases ‚≠ê‚≠ê‚≠ê
   2. Knowledge_Neurons_Pretrained_Transformers ‚≠ê‚≠ê‚≠ê
   3. Rethinking_Parametric_Knowledge ‚≠ê‚≠ê

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ TEMA: Knowledge Editing                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
   1. Survey_Knowledge_Editing_LLMs ‚≠ê‚≠ê‚≠ê
   2. ROME_Locating_Editing_Factual_Associations ‚≠ê‚≠ê‚≠ê
   3. MEMIT_Mass_Editing_Memory ‚≠ê‚≠ê
   4. BaFT_Basis_Level_Knowledge_Editing ‚≠ê‚≠ê

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ TEMA: Conhecimento Externo (RAG)                                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
   1. RAG_Original_Paper ‚≠ê‚≠ê‚≠ê
   2. Survey_RAG_Comprehensive ‚≠ê‚≠ê‚≠ê
   3. Survey_LLM_Inference_External_Knowledge ‚≠ê‚≠ê
   4. Survey_Agentic_RAG ‚≠ê

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ TEMA: Knowledge Conflicts                                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
   1. Bridging_External_Parametric_Knowledge ‚≠ê‚≠ê‚≠ê
   2. Parameters_vs_Context_Knowledge_Reliance ‚≠ê‚≠ê
   3. ParamMute_Knowledge_Critical_FFNs ‚≠ê‚≠ê
   4. Training_Dynamics_Parametric_InContext ‚≠ê

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ TEMA: Memoriza√ß√£o vs Generaliza√ß√£o                                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
   1. Generalization_vs_Memorization ‚≠ê‚≠ê‚≠ê
   2. Quantifying_Memorization_NLMs ‚≠ê‚≠ê
   3. SoK_Memorization_LLMs ‚≠ê‚≠ê

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ TEMA: Knowledge Graphs + LLMs                                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
   1. Unifying_LLMs_Knowledge_Graphs ‚≠ê‚≠ê
   2. LLM_Knowledge_Graph_Construction ‚≠ê‚≠ê
   3. Optimizing_KG_LLM_Interface ‚≠ê

‚≠ê‚≠ê‚≠ê = Leitura essencial
‚≠ê‚≠ê = Leitura recomendada
‚≠ê = Leitura complementar

==============================================================================
                         üí° DICAS PR√ÅTICAS PARA A AULA
==============================================================================

‚úÖ FA√áA:

   ‚Üí Use MUITOS exemplos visuais
     ‚Ä¢ Diagrama de tr√™s tipos de conhecimento
     ‚Ä¢ Knowledge neurons (heatmap)
     ‚Ä¢ ROME editing process (passo-a-passo)
     ‚Ä¢ RAG pipeline (fluxo)
     ‚Ä¢ Knowledge conflict (antes/depois)

   ‚Üí Demonstra√ß√µes pr√°ticas
     ‚Ä¢ LAMA probe: "Paris is the capital of [MASK]"
     ‚Ä¢ Knowledge editing: Mudar fact e verificar
     ‚Ä¢ RAG: Compare com/sem retrieval
     ‚Ä¢ Knowledge conflict: Mostre contradi√ß√£o

   ‚Üí Use met√°foras
     ‚Ä¢ Conhecimento param√©trico = biblioteca pessoal
     ‚Ä¢ Conhecimento externo = Google
     ‚Ä¢ Knowledge editing = corrigir p√°gina de livro
     ‚Ä¢ Knowledge conflict = duas fontes contradizem

   ‚Üí Conecte com aulas anteriores
     ‚Ä¢ Aula 1: LLMs como transformadores (conhecimento transforma input)
     ‚Ä¢ Aula 3: Context window (limita conhecimento contextual)
     ‚Ä¢ Aula 6: Alucina√ß√µes (conhecimento incorreto)

‚ùå EVITE:

   ‚Üí Matem√°tica pesada sem necessidade
     ‚Ä¢ Foque em intui√ß√µes
     ‚Ä¢ Se mostrar equa√ß√£o, explique em portugu√™s

   ‚Üí Excesso de detalhes de implementa√ß√£o
     ‚Ä¢ "O qu√™" e "por qu√™" > "exatamente como"

   ‚Üí Compara√ß√µes injustas
     ‚Ä¢ Parametric e external t√™m trade-offs diferentes
     ‚Ä¢ Contextos de uso s√£o diferentes

==============================================================================
                           üéì EXERC√çCIOS SUGERIDOS
==============================================================================

EXERC√çCIO 1: Knowledge Probing
   ‚Ä¢ Use LAMA-style prompts
   ‚Ä¢ Teste conhecimento factual do modelo
   ‚Ä¢ Discuss√£o: O que modelo sabe vs n√£o sabe?

EXERC√çCIO 2: Knowledge Conflict
   ‚Ä¢ Forne√ßa fato incorreto no contexto
   ‚Ä¢ Veja se modelo confia em parametric ou context
   ‚Ä¢ Discuss√£o: Quando cada abordagem √© melhor?

EXERC√çCIO 3: RAG vs Parametric
   ‚Ä¢ Mesma pergunta com/sem retrieval
   ‚Ä¢ Compare qualidade e fontes
   ‚Ä¢ Discuss√£o: Quando vale overhead de RAG?

EXERC√çCIO 4: Knowledge Editing Simulation
   ‚Ä¢ "Edite" fact via prompt engineering
   ‚Ä¢ Veja limita√ß√µes vs true editing
   ‚Ä¢ Discuss√£o: Quando usar cada approach?

==============================================================================
                          üìà N√öMEROS E M√âTRICAS-CHAVE
==============================================================================

KNOWLEDGE EDITING METHODS:

   ROME (2022):
   - Edita 1 fact por vez
   - Localiza em MLP layers
   - Efficacy: ~90% success rate

   MEMIT (2023):
   - Edita milhares de facts simultaneamente
   - Scales: GPT-J (6B), GPT-NeoX (20B)
   - Orders of magnitude beyond prior work

   BaFT (2025):
   - Basis-level fine-tuning
   - Superior locality-generalization trade-off

MEMORIZATION:

   Facts memorizados: ~30-50% de training data (depende de size)
   Verbatim memorization: Raro, mas ocorre
   Degrada√ß√£o: √Ä medida que model size aumenta, mais memoriza facts

KNOWLEDGE TYPES:

   Parametric knowledge: Bilh√µes de facts encoded em weights
   External knowledge: Ilimitado (dado retrieval capability)
   Context window: Limita conhecimento contextual (128K-2M tokens)

==============================================================================
                             ‚ùì PERGUNTAS FREQUENTES
==============================================================================

P: Preciso ler todos os 37 papers?
R: N√ÉO! M√≠nimo 3-5 papers fundamentais, ideal 10-12 papers.

P: Qual ordem de leitura?
R: Fundamentos primeiro (LAMA, ROME, RAG), depois estado-da-arte.

P: Papers de 2025 s√£o confi√°veis?
R: SIM! ArXiv com autores credenciados. Alguns em review, mas s√≥lidos.

P: Diferen√ßa entre parametric e external knowledge?
R: Parametric = nos pesos do modelo (fixo ap√≥s treino)
   External = buscado em tempo real (sempre atualizado)

P: ROME vs MEMIT vs BaFT?
R: ROME (2022) = 1 fact, fundacional
   MEMIT (2023) = milhares de facts, escal√°vel
   BaFT (2025) = estado-da-arte, melhor trade-off

P: Quando usar RAG vs parametric?
R: RAG: conhecimento atualizado, privado, specific domain
   Parametric: common sense, reasoning geral, offline

==============================================================================
                              ‚úÖ CHECKLIST FINAL
==============================================================================

Antes da aula:

   [ ] Lido ao menos 5 papers (3 se tempo curto)
   [ ] Preparado slides com conceitos principais
   [ ] Coletado diagramas/figuras dos papers
   [ ] Preparado demonstra√ß√£o de LAMA probe
   [ ] Preparado exemplo de knowledge editing
   [ ] Exemplo de RAG funcionando
   [ ] Exemplo de knowledge conflict
   [ ] Listado m√©todos de editing (ROME, MEMIT, etc.)
   [ ] Preparado analogias para conceitos complexos
   [ ] Revisado conex√µes com aulas anteriores

==============================================================================
                            üéØ PR√ìXIMOS PASSOS
==============================================================================

1. Escolha seu cen√°rio (1, 2 ou 3)
2. Abra INDICE_COMPLETO_PDFS.md para detalhes
3. Comece lendo papers na ordem sugerida
4. Fa√ßa anota√ß√µes e marque figuras
5. Prepare slides conforme avan√ßa
6. Teste demonstra√ß√µes pr√°ticas
7. Revise checklist final

==============================================================================

         üí¨ "Knowledge is power, but knowing where it's stored
                    is the key to wielding that power"
                              - Anonymous ML Researcher

==============================================================================

√öltima atualiza√ß√£o: 31/10/2025
Para: George Marmelstein
Aula: 4 - Conhecimento da M√°quina

                              BOA AULA! üöÄ
