# Translation Task

## Instructions
Translate from Brazilian Portuguese to Spanish (Spain/Latin America neutral).
Keep technical terms in their original form when commonly used in Spanish (e.g., LLM, API, RAG).
Maintain HTML formatting exactly as provided.
For Brazilian legal references (e.g., "CNJ", "STF"), keep the abbreviation and add a brief explanation in parentheses on first use.
Adapt cultural references to be understandable for Spanish speakers.

## Source Lesson (Portuguese)

**Lesson 1.7: O Conhecimento da M√°quina**

**Module:** M√≥dulo 1 ‚Äî Fundamentos

**Objective:** Entender de onde os LLMs tiram conhecimento e saber quando usar cada fonte.

**Content:**

                    <div class="block">
                        <h2 class="block-title">As Quatro Fontes de Conhecimento</h2>
                        <p>Os LLMs podem acessar conhecimento de <strong>quatro fontes diferentes</strong>:</p>
                        <div class="table-wrapper">
                            <table>
                                <thead><tr><th>Fonte</th><th>O que √©</th><th>Como funciona</th></tr></thead>
                                <tbody>
                                    <tr><td><strong>Param√©trico</strong></td><td>Pesos e conex√µes da rede neural</td><td>Aprendido durante o treinamento</td></tr>
                                    <tr><td><strong>Do Usu√°rio</strong></td><td>Via prompt ou anexos</td><td>Voc√™ fornece no momento da conversa</td></tr>
                                    <tr><td><strong>De Sistema</strong></td><td>Prompt de sistema, configura√ß√µes</td><td>Definido pelo desenvolvedor</td></tr>
                                    <tr><td><strong>Buscado</strong></td><td>Internet, APIs, ferramentas</td><td>Recuperado em tempo real</td></tr>
                                </tbody>
                            </table>
                        </div>
                        <p>O segredo para usar bem os LLMs √© <strong>saber quando usar cada fonte</strong>.</p>
                    </div>

                    <div class="block">
                        <h2 class="block-title">Conhecimento Param√©trico: O "C√©rebro"</h2>
                        <p>√â o que est√° "na cabe√ßa" do LLM ‚Äî armazenado nos bilh√µes de par√¢metros durante o treinamento.</p>
                        <div class="table-wrapper">
                            <table>
                                <thead><tr><th>Caracter√≠stica</th><th>Implica√ß√£o</th></tr></thead>
                                <tbody>
                                    <tr><td><strong>Probabil√≠stico</strong></td><td>Baseado em frequ√™ncia estat√≠stica, n√£o em certeza</td></tr>
                                    <tr><td><strong>Frequentista</strong></td><td>O que apareceu mais no treino tem mais peso</td></tr>
                                    <tr><td><strong>Est√°tico/Congelado</strong></td><td>N√£o muda ap√≥s o treinamento</td></tr>
                                    <tr><td><strong>Datado (Cutoff)</strong></td><td>Tem uma data limite ‚Äî n√£o sabe eventos posteriores</td></tr>
                                </tbody>
                            </table>
                        </div>
                    </div>

                    <div class="callout callout-warning">
                        <div class="callout-title">üìÖ Data de Corte (Knowledge Cutoff)</div>
                        <p>Todo modelo tem uma <strong>data limite</strong> de conhecimento. Pergunte: <code>Qual sua data de corte?</code></p>
                        <p>Eventos ap√≥s essa data: o modelo <strong>n√£o sabe</strong> (mas pode inventar com confian√ßa).</p>
                    </div>

                    <div class="block">
                        <h2 class="block-title">Quando Usar Cada Fonte?</h2>
                        <div class="table-wrapper">
                            <table>
                                <thead><tr><th>Use o Param√©trico para...</th><th>Use Conhecimento do Usu√°rio para...</th></tr></thead>
                                <tbody>
                                    <tr><td>Explicar conceitos (ex: "O que √© mandado de seguran√ßa?")</td><td>Analisar documentos espec√≠ficos</td></tr>
                                    <tr><td>Conhecimento est√°vel (gram√°tica, l√≥gica, defini√ß√µes)</td><td>Fatos que mudam (leis recentes, pre√ßos)</td></tr>
                                    <tr><td>Criatividade e cen√°rios hipot√©ticos</td><td>Dados espec√≠ficos (n√∫meros de processo, cita√ß√µes)</td></tr>
                                    <tr><td>Informa√ß√µes amplamente documentadas</td><td>Casos concretos e an√°lises precisas</td></tr>
                                </tbody>
                            </table>
                        </div>
                    </div>

                    <div class="block">
                        <h2 class="block-title">Conhecimento do Usu√°rio: Via Prompt vs Via Anexo</h2>
                        <div class="table-wrapper">
                            <table>
                                <thead><tr><th>M√©todo</th><th>Quando usar</th><th>Limite pr√°tico</th></tr></thead>
                                <tbody>
                                    <tr><td><strong>Via Prompt</strong></td><td>Textos curtos, trechos espec√≠ficos</td><td>At√© ~10-20 p√°ginas coladas</td></tr>
                                    <tr><td><strong>Via Anexo</strong></td><td>Documentos completos (PDFs, Word)</td><td>At√© ~150-200 p√°ginas (com degrada√ß√£o)</td></tr>
                                </tbody>
                            </table>
                        </div>
                        <div class="callout callout-info">
                            <div class="callout-title">üí° Contexto Sobrescreve Par√¢metros</div>
                            <p>Se voc√™ fornecer informa√ß√£o que contradiz o conhecimento param√©trico, o modelo tende a <strong>priorizar o que voc√™ forneceu</strong>.</p>
                            <p>Isso √© poderoso: voc√™ pode "ancorar" o modelo em documentos espec√≠ficos para reduzir alucina√ß√µes.</p>
                        </div>
                    </div>

                    <div class="block">
                        <h2 class="block-title">A Regra de Ouro</h2>
                        <p>O conhecimento param√©trico √© excelente para <strong>conceitos e criatividade</strong>, mas falha em <strong>dados factuais espec√≠ficos</strong>.</p>
                        <div class="table-wrapper">
                            <table>
                                <thead><tr><th style="color:var(--accent-success);">‚úì Confi√°vel</th><th style="color:var(--accent-warning);">‚ö†Ô∏è Verificar Sempre</th></tr></thead>
                                <tbody>
                                    <tr><td>Explica√ß√µes conceituais</td><td>N√∫meros de processo, REsp, RE</td></tr>
                                    <tr><td>Compara√ß√µes e analogias</td><td>Datas de julgamento</td></tr>
                                    <tr><td>Cen√°rios hipot√©ticos</td><td>Cita√ß√µes literais</td></tr>
                                    <tr><td>Estruturas e frameworks</td><td>URLs e links</td></tr>
                                </tbody>
                            </table>
                        </div>
                    </div>
                

**Exercise:**
Title: Explorando as Fontes de Conhecimento
Prompt: undefined
Checklist:
- Entendo as 4 fontes de conhecimento dos LLMs
- Sei que conhecimento param√©trico √© bom para conceitos, ruim para fatos
- Sei inserir conhecimento via prompt (colar texto)
- Sei inserir conhecimento via anexo (upload de arquivo)
- Entendo que contexto fornecido pode sobrescrever par√¢metros


**Tip:** Para <strong>tarefas conceituais</strong> (explicar, comparar, criar cen√°rios), use o conhecimento param√©trico. Para <strong>tarefas factuais</strong> (analisar documentos, verificar dados), forne√ßa o material via prompt ou anexo.

**Warning:** <strong>"O modelo disse com confian√ßa, ent√£o deve estar certo."</strong><br>LLMs n√£o calibram confian√ßa com precis√£o. Um modelo pode afirmar um n√∫mero de processo falso com a mesma flu√™ncia de um verdadeiro. <strong>Confian√ßa aparente n√£o indica veracidade.</strong>

## Output Format

Return ONLY a valid JSON object with this exact structure:
{
  "number": "1.7",
  "module": "[translated module name]",
  "title": "[translated title]",
  "objective": "[translated objective]",
  "content": "[translated HTML content - keep all HTML tags]",
  "exercise": {
    "title": "[translated exercise title]",
    "prompt": "[translated prompt]",
    "checklist": ["[translated item 1]", "[translated item 2]", ...],
    "example": "[translated example if present]"
  },
  "tip": "[translated tip if present]",
  "warning": "[translated warning if present]"
}

---

# Translation Task

## Instructions
Translate from Brazilian Portuguese to Spanish (Spain/Latin America neutral).
Keep technical terms in their original form when commonly used in Spanish (e.g., LLM, API, RAG).
Maintain HTML formatting exactly as provided.
For Brazilian legal references (e.g., "CNJ", "STF"), keep the abbreviation and add a brief explanation in parentheses on first use.
Adapt cultural references to be understandable for Spanish speakers.

## Source Lesson (Portuguese)

**Lesson 1.8: Como Treinar um LLM**

**Module:** M√≥dulo 1 ‚Äî Fundamentos

**Objective:** Entender as tr√™s fases de treinamento e como cada uma molda o comportamento do modelo.

**Content:**

                    <div class="block">
                        <h2 class="block-title">O Pipeline de Treinamento</h2>
                        <p>Criar um LLM moderno envolve <strong>tr√™s fases</strong> distintas, cada uma com prop√≥sito espec√≠fico:</p>
                        <div class="code-block">FASE 1: PR√â-TREINAMENTO
Internet (trilh√µes de tokens) ‚Üí [Predizer pr√≥ximo token] ‚Üí Modelo Base
                                                              ‚Üì
FASE 2: FINE-TUNING (SFT)
Exemplos de alta qualidade ‚Üí [Ajuste supervisionado] ‚Üí Modelo Instru√ß√£o
                                                              ‚Üì
FASE 3: ALINHAMENTO (RLHF)
Feedback humano ‚Üí [Reinforcement Learning] ‚Üí Modelo Alinhado</div>
                    </div>
                    <div class="block">
                        <h2 class="block-title">Fase 1: Pr√©-Treinamento</h2>
                        <p>O modelo aprende a <strong>prever o pr√≥ximo token</strong> em um corpus massivo da internet.</p>
                        <div class="table-wrapper">
                            <table>
                                <thead><tr><th>Aspecto</th><th>Detalhes</th></tr></thead>
                                <tbody>
                                    <tr><td><strong>Dados</strong></td><td>Trilh√µes de tokens (internet, livros, c√≥digo, artigos)</td></tr>
                                    <tr><td><strong>Objetivo</strong></td><td>Minimizar erro de predi√ß√£o do pr√≥ximo token</td></tr>
                                    <tr><td><strong>Custo</strong></td><td>Milh√µes de d√≥lares, meses de computa√ß√£o em GPUs</td></tr>
                                    <tr><td><strong>Resultado</strong></td><td>Modelo "base" ‚Äî sabe muito, mas n√£o segue instru√ß√µes bem</td></tr>
                                </tbody>
                            </table>
                        </div>
                        <p>O modelo base √© como um <strong>erudito sem habilidades sociais</strong>: conhecimento vasto, mas n√£o sabe conversar.</p>
                    </div>
                    <div class="block">
                        <h2 class="block-title">Fase 2: Fine-Tuning Supervisionado (SFT)</h2>
                        <p>O modelo aprende o <strong>formato de di√°logo</strong> com exemplos humanos de alta qualidade.</p>
                        <div class="code-block">Exemplo de dado SFT:

Usu√°rio: "Explique o que √© habeas corpus em termos simples."
Assistente: "Habeas corpus √© uma a√ß√£o judicial que protege
a liberdade de ir e vir. Quando algu√©m √© preso ilegalmente,
pode usar esse recurso para ser libertado..."</div>
                        <p>Milhares de exemplos assim ensinam o modelo a:</p>
                        <ul style="margin:16px 0 16px 24px;color:var(--text-secondary);">
                            <li>Responder em formato de conversa</li>
                            <li>Seguir instru√ß√µes</li>
                            <li>Manter tom apropriado</li>
                            <li>Estruturar respostas de forma clara</li>
                        </ul>
                    </div>
                    <div class="block">
                        <h2 class="block-title">Fase 3: RLHF (Reinforcement Learning from Human Feedback)</h2>
                        <p>Humanos <strong>comparam respostas</strong> e indicam qual √© melhor. Isso treina o modelo para gerar respostas preferidas.</p>
                        <div class="code-block">Processo RLHF:

1. Modelo gera duas respostas para mesma pergunta
2. Humano escolhe qual √© melhor (A ou B)
3. Treina um "modelo de recompensa" com essas prefer√™ncias
4. Usa RL para otimizar o modelo principal</div>
                        <div class="callout callout-info">
                            <div class="callout-title">üéØ Por que RLHF importa?</div>
                            <p>RLHF √© o que torna modelos <strong>√∫teis e seguros</strong>. Sem ele, modelos base podem gerar conte√∫do problem√°tico, n√£o seguir instru√ß√µes, ou dar respostas in√∫teis.</p>
                            <p>√â o RLHF que faz Claude recusar pedidos perigosos e tentar ser genuinamente √∫til.</p>
                        </div>
                    </div>
                    <div class="block">
                        <h2 class="block-title">Constitutional AI: A Abordagem da Anthropic</h2>
                        <p>O Claude usa uma varia√ß√£o chamada <strong>Constitutional AI (CAI)</strong>:</p>
                        <ul style="margin:16px 0 16px 24px;color:var(--text-secondary);">
                            <li>Em vez de apenas feedback humano, usa <strong>princ√≠pios √©ticos escritos</strong> (a "constitui√ß√£o")</li>
                            <li>O pr√≥prio modelo avalia e melhora suas respostas seguindo esses princ√≠pios</li>
                            <li>Reduz depend√™ncia de anotadores humanos</li>
                            <li>Permite treinamento mais escal√°vel e consistente</li>
                        </ul>
                    </div>
                    <div class="block">
                        <h2 class="block-title">Vieses de Treino</h2>
                        <p>O treinamento produz comportamentos √∫teis, mas tamb√©m <strong>vieses sistem√°ticos</strong>:</p>
                        <div class="table-wrapper">
                            <table>
                                <thead><tr><th>Vi√©s</th><th>O que √©</th><th>Exemplo</th></tr></thead>
                                <tbody>
                                    <tr><td><strong>Bajulador</strong><br>(Sycophancy)</td><td>Tend√™ncia a concordar com o usu√°rio, mesmo quando est√° errado</td><td>Voc√™ diz "acho que 2+2=5" e o modelo concorda ou hesita em corrigir</td></tr>
                                    <tr><td><strong>Previs√≠vel</strong></td><td>Gravita para respostas comuns e esperadas</td><td>Pede uma fruta ‚Üí banana/ma√ß√£; pede um n√∫mero ‚Üí 7 ou 42</td></tr>
                                    <tr><td><strong>Pasteurizado</strong></td><td>Respostas "seguras", gen√©ricas, evitando controv√©rsias</td><td>Perguntas pol√™micas geram "h√° diversos pontos de vista..."</td></tr>
                                </tbody>
                            </table>
                        </div>
                        <div class="callout callout-warning">
                            <div class="callout-title">üéØ A S√≠ntese</div>
                            <p>Um LLM √© um <strong>preditor de padr√µes lingu√≠sticos</strong> refinado por feedback humano ‚Äî por isso escreve fluentemente e segue instru√ß√µes, mas <strong>n√£o tem sabedoria nem senso de realidade</strong>.</p>
                        </div>
                    </div>
                    <div class="block">
                        <h2 class="block-title">Scaling Laws: Mais √© Melhor</h2>
                        <p>Descoberta importante: performance melhora <strong>previsivelmente</strong> com escala.</p>
                        <div class="table-wrapper">
                            <table>
                                <thead><tr><th>Fator</th><th>Efeito</th></tr></thead>
                                <tbody>
                                    <tr><td><strong>Mais par√¢metros</strong></td><td>Modelo maior ‚Üí melhor performance</td></tr>
                                    <tr><td><strong>Mais dados</strong></td><td>Mais texto de treino ‚Üí melhor generaliza√ß√£o</td></tr>
                                    <tr><td><strong>Mais computa√ß√£o</strong></td><td>Mais treino ‚Üí resultados melhores</td></tr>
                                </tbody>
                            </table>
                        </div>
                        <p>Isso explica a corrida por modelos cada vez maiores ‚Äî e por que treinamento custa centenas de milh√µes de d√≥lares.</p>
                    </div>
                

**Exercise:**
Title: Observando os Efeitos do Treinamento
Prompt: undefined
Checklist:
- Entendo as 3 fases: pr√©-treino, SFT, RLHF
- Sei que pr√©-treino cria conhecimento, SFT ensina formato
- Compreendo que RLHF/CAI torna o modelo √∫til e seguro
- Entendo o conceito de Constitutional AI da Anthropic
- Reconhe√ßo os vieses de treino: bajulador, previs√≠vel, pasteurizado


**Tip:** Quando o modelo recusa algo ou responde de forma inesperada, lembre-se: isso √© <strong>comportamento treinado</strong>. O modelo foi otimizado para ser √∫til E seguro ‚Äî √†s vezes esses objetivos conflitam.

**Warning:** <strong>"Posso 'destreinar' o modelo com meus prompts."</strong><br>N√£o. Seus prompts n√£o modificam os pesos do modelo. Voc√™ pode influenciar o comportamento na conversa atual, mas o treinamento √© fixo. Na pr√≥xima conversa, o modelo volta ao comportamento padr√£o.

## Output Format

Return ONLY a valid JSON object with this exact structure:
{
  "number": "1.8",
  "module": "[translated module name]",
  "title": "[translated title]",
  "objective": "[translated objective]",
  "content": "[translated HTML content - keep all HTML tags]",
  "exercise": {
    "title": "[translated exercise title]",
    "prompt": "[translated prompt]",
    "checklist": ["[translated item 1]", "[translated item 2]", ...],
    "example": "[translated example if present]"
  },
  "tip": "[translated tip if present]",
  "warning": "[translated warning if present]"
}

---

# Translation Task

## Instructions
Translate from Brazilian Portuguese to Spanish (Spain/Latin America neutral).
Keep technical terms in their original form when commonly used in Spanish (e.g., LLM, API, RAG).
Maintain HTML formatting exactly as provided.
For Brazilian legal references (e.g., "CNJ", "STF"), keep the abbreviation and add a brief explanation in parentheses on first use.
Adapt cultural references to be understandable for Spanish speakers.

## Source Lesson (Portuguese)

**Lesson 1.9: Alucina√ß√µes**

**Module:** M√≥dulo 1 ‚Äî Fundamentos

**Objective:** Entender que alucina√ß√µes s√£o inerentes aos LLMs ‚Äî n√£o um bug, mas uma condi√ß√£o essencial para sua efici√™ncia.

**Content:**

                    <div class="block">
                        <h2 class="block-title">O que √© Alucina√ß√£o?</h2>
                        <p>A <strong>alucina√ß√£o</strong> (ou <em>confabula√ß√£o</em>) ocorre quando o modelo produz respostas desconectadas com a realidade, muitas vezes com confian√ßa e apar√™ncia de veracidade.</p>
                        <div class="callout callout-error">
                            <div class="callout-title">‚ö†Ô∏è N√£o √© Bug ‚Äî √â Caracter√≠stica</div>
                            <p>O LLM <strong>n√£o possui inten√ß√£o de mentir</strong> nem senso de realidade. Ele simplesmente n√£o tem um mecanismo intr√≠nseco para distinguir fato de fic√ß√£o.</p>
                            <p>Isso n√£o √© um defeito tempor√°rio, mas uma <strong>caracter√≠stica matematicamente inevit√°vel</strong> de um modelo que preenche lacunas com palpites estat√≠sticos.</p>
                        </div>
                    </div>

                    <div class="block">
                        <h2 class="block-title">Por que LLMs Alucinam?</h2>
                        <div class="callout callout-info">
                            <div class="callout-title">üéì Met√°fora do Concurseiro</div>
                            <p>Imagine um concurseiro que estudou muito, mas n√£o sabe tudo. Na prova, ele <strong>prefere chutar com confian√ßa</strong> a deixar em branco ‚Äî porque foi treinado assim.</p>
                        </div>
                        <h3 style="margin-top:20px;color:var(--text-primary);">Problemas nos Dados de Treinamento</h3>
                        <div class="table-wrapper">
                            <table>
                                <thead><tr><th>Lacunas de Conhecimento</th><th>Dados Problem√°ticos</th></tr></thead>
                                <tbody>
                                    <tr><td>Dados ausentes ou raros</td><td>Dados incorretos ou enviesados</td></tr>
                                    <tr><td>Corte temporal (n√£o sabe eventos recentes)</td><td>Conflitos de informa√ß√£o</td></tr>
                                    <tr><td>Nichos n√£o-representados</td><td>Ambiguidades sem resolu√ß√£o</td></tr>
                                </tbody>
                            </table>
                        </div>
                        <h3 style="margin-top:20px;color:var(--text-primary);">Problemas do Fine-tuning (RLHF)</h3>
                        <div class="table-wrapper">
                            <table>
                                <thead><tr><th>Incentivo Perverso</th><th>Consequ√™ncia</th></tr></thead>
                                <tbody>
                                    <tr><td><strong>Penaliza√ß√£o da abstin√™ncia</strong></td><td>Modelo aprende que "n√£o sei" √© ruim</td></tr>
                                    <tr><td><strong>Recompensa por confian√ßa</strong></td><td>Respostas assertivas ganham mais pontos</td></tr>
                                    <tr><td><strong>Recompensa por verbosidade</strong></td><td>Respostas longas parecem melhores</td></tr>
                                    <tr><td><strong>Imita√ß√£o de padr√µes</strong></td><td>No af√£ de ser √∫til, inventa dados por semelhan√ßa</td></tr>
                                </tbody>
                            </table>
                        </div>
                    </div>

                    <div class="block">
                        <h2 class="block-title">Taxonomia das Alucina√ß√µes</h2>
                        <div class="table-wrapper">
                            <table>
                                <thead><tr><th>Tipo</th><th>O que √©</th><th>Exemplo</th></tr></thead>
                                <tbody>
                                    <tr><td><strong>Falhas de Dirigibilidade</strong></td><td>Desobedi√™ncia ao prompt</td><td>Voc√™ pede tabela, ele d√° texto corrido</td></tr>
                                    <tr><td><strong>Resposta Non Sense</strong></td><td>Quebra de coer√™ncia</td><td>Texto que come√ßa bem e vira nonsense</td></tr>
                                    <tr><td><strong>Falhas de Factualidade</strong></td><td>Confabula√ß√µes</td><td>Citar jurisprud√™ncia que n√£o existe</td></tr>
                                    <tr><td><strong>Misturas Lingu√≠sticas</strong></td><td>Trocas inesperadas de idioma</td><td>Resposta em portugu√™s vira ingl√™s</td></tr>
                                    <tr><td><strong>Falhas Matem√°ticas</strong></td><td>Erros de c√°lculo e l√≥gica</td><td>2+2=5 ou silogismos inv√°lidos</td></tr>
                                    <tr><td><strong>Falhas de Ferramentas</strong></td><td>Erro ao ativar ferramentas</td><td>Diz que buscou mas n√£o buscou</td></tr>
                                </tbody>
                            </table>
                        </div>
                    </div>

                    <div class="block">
                        <h2 class="block-title">O Problema dos Benchmarks</h2>
                        <p>Segundo <a href="https://openai.com/index/why-language-models-hallucinate/" target="_blank" style="color:var(--accent-primary);">pesquisa da OpenAI</a>, as alucina√ß√µes persistem porque os <strong>m√©todos de avalia√ß√£o incentivam chutar</strong>:</p>
                        <div class="callout callout-info">
                            <div class="callout-title">üéØ A Matem√°tica do Chute</div>
                            <p>Se um modelo chuta "10 de setembro" como anivers√°rio de algu√©m, tem <strong>1 chance em 365</strong> de acertar.</p>
                            <p>Se responde "n√£o sei", tem <strong>0% de chance</strong> de pontuar.</p>
                            <p>Ao longo de milhares de perguntas, o modelo que chuta <strong>parece melhor nos rankings</strong> ‚Äî mesmo errando muito.</p>
                        </div>
                        <p><strong>Solu√ß√£o proposta:</strong> Penalizar erros confiantes mais do que incerteza, e dar cr√©dito parcial para express√µes apropriadas de d√∫vida.</p>
                    </div>

                    <div class="block">
                        <h2 class="block-title">Alucina√ß√£o √© Essencial</h2>
                        <div class="callout callout-warning">
                            <div class="callout-title">üí° O Paradoxo</div>
                            <p>As alucina√ß√µes <strong>n√£o s√£o falhas do modelo</strong>, mas uma <strong>condi√ß√£o essencial para sua efici√™ncia</strong>.</p>
                            <p>√â a capacidade de "preencher lacunas criativamente" que torna os LLMs ferramentas poderosas para resolver problemas novos.</p>
                        </div>
                        <p>O mesmo mecanismo que permite ao LLM:</p>
                        <ul style="margin:16px 0 16px 24px;color:var(--text-secondary);">
                            <li>Escrever textos criativos</li>
                            <li>Resolver problemas in√©ditos</li>
                            <li>Fazer analogias inesperadas</li>
                        </ul>
                        <p>...tamb√©m o faz inventar fatos com confian√ßa.</p>
                    </div>

                    <div class="block">
                        <h2 class="block-title">T√©cnicas de Mitiga√ß√£o</h2>
                        <div class="table-wrapper">
                            <table>
                                <thead><tr><th>T√©cnica</th><th>Como funciona</th><th>Efic√°cia</th></tr></thead>
                                <tbody>
                                    <tr><td><strong>RAG / Anexos</strong></td><td>Ancora respostas em documentos fornecidos</td><td style="color:var(--accent-success);">Alta</td></tr>
                                    <tr><td><strong>Busca web</strong></td><td>Verifica em fontes externas</td><td style="color:var(--accent-success);">Alta</td></tr>
                                    <tr><td><strong>"Se n√£o sabe, diga"</strong></td><td>Instrui explicitamente a admitir ignor√¢ncia</td><td style="color:var(--accent-warning);">Moderada</td></tr>
                                    <tr><td><strong>Pedir fontes</strong></td><td>Exigir cita√ß√µes permite verifica√ß√£o</td><td style="color:var(--accent-warning);">Moderada</td></tr>
                                </tbody>
                            </table>
                        </div>
                    </div>

                    <div class="block">
                        <h2 class="block-title">A Regra de Ouro</h2>
                        <div class="callout callout-error">
                            <div class="callout-title">üéØ Pressuposi√ß√£o de Falsidade</div>
                            <p><strong>TODAS</strong> as respostas factuais extra√≠das do conhecimento param√©trico s√£o "palpites" probabil√≠sticos.</p>
                            <p><strong>Parta do pressuposto que s√£o falsos, at√© prova em contr√°rio.</strong></p>
                        </div>
                        <p>Por isso a Resolu√ß√£o 615/2025 do CNJ exige verifica√ß√£o: nunca use output de IA sem conferir em fonte oficial.</p>
                    </div>
                

**Exercise:**
Title: Identificando Alucina√ß√µes
Prompt: undefined
Checklist:
- Entendo que alucina√ß√£o √© caracter√≠stica essencial, n√£o bug
- Conhe√ßo as causas: lacunas de dados + incentivos perversos do RLHF
- Sei identificar os 6 tipos de alucina√ß√£o
- Entendo o paradoxo: alucina√ß√£o √© o que torna LLMs √∫teis
- Aplico a regra: presumir falso at√© provar verdadeiro


**Tip:** <strong>Pressuponha falsidade.</strong> Toda resposta factual do conhecimento param√©trico √© um palpite probabil√≠stico. Trate como suspeito at√© verificar ‚Äî especialmente n√∫meros de processos, datas e cita√ß√µes.

**Warning:** <strong>"O modelo citou jurisprud√™ncia com confian√ßa, ent√£o deve existir."</strong><br><strong>NUNCA.</strong> A confian√ßa aparente n√£o indica veracidade. Um modelo pode inventar um REsp 1.234.567/SP com a mesma flu√™ncia de um que existe. Sempre verifique.

## Output Format

Return ONLY a valid JSON object with this exact structure:
{
  "number": "1.9",
  "module": "[translated module name]",
  "title": "[translated title]",
  "objective": "[translated objective]",
  "content": "[translated HTML content - keep all HTML tags]",
  "exercise": {
    "title": "[translated exercise title]",
    "prompt": "[translated prompt]",
    "checklist": ["[translated item 1]", "[translated item 2]", ...],
    "example": "[translated example if present]"
  },
  "tip": "[translated tip if present]",
  "warning": "[translated warning if present]"
}